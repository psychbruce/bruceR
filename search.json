[{"path":"https://psychbruce.github.io/bruceR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Han-Wu-Shuang Bao. Author, maintainer.","code":""},{"path":"https://psychbruce.github.io/bruceR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bao, H.-W.-S. (2022). bruceR: Broadly useful convenient efficient R functions. R package version 0.8.x. https://CRAN.R-project.org/package=bruceR","code":"@Misc{,   title = {bruceR: Broadly Useful Convenient and Efficient R Functions},   author = {Han-Wu-Shuang Bao},   year = {2022},   url = {https://CRAN.R-project.org/package=bruceR}, }"},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"brucer-","dir":"","previous_headings":"","what":"Broadly Useful Convenient and Efficient R Functions","title":"Broadly Useful Convenient and Efficient R Functions","text":"BRoadly Useful Convenient Efficient R functions thatBRing Users Concise Elegant R data analyses. package includes easy--use functions : Basic R programming (e.g., set working directory path currently opened file; import/export data /files format; print tables Microsoft Word); Multivariate computation (e.g., compute scale sums/means/… reverse scoring); Reliability analyses factor analyses (PCA, EFA, CFA); Descriptive statistics correlation analyses; t-test, multi-factor analysis variance (ANOVA), simple-effect analysis, post-hoc multiple comparison; Tidy report statistical models (R Console Microsoft Word); Mediation moderation analyses (PROCESS); Additional toolbox statistics graphics.","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"Broadly Useful Convenient and Efficient R Functions","text":"Han-Wu-Shuang (Bruce) Bao 包寒吴霜 Email: baohws@foxmail.com Homepage: psychbruce.github.io","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Broadly Useful Convenient and Efficient R Functions","text":"Bao, H.-W.-S. (2022). bruceR: Broadly useful convenient efficient R functions. R package version 0.8.x. https://CRAN.R-project.org/package=bruceR","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"user-guide","dir":"","previous_headings":"","what":"User Guide","title":"Broadly Useful Convenient and Efficient R Functions","text":"NEWS (Changelog) Chinese Documentation bruceR: . Overview Chinese Documentation bruceR: II. FAQ","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"installation","dir":"","previous_headings":"User Guide","what":"Installation","title":"Broadly Useful Convenient and Efficient R Functions","text":"Tips: Good practice: restart RStudio installation. Good practice: update R latest version (v4.0+). Good practice: install Rtools.exe (R package) Windows system. see “want restart R prior install?”, choose “Yes” first time choose “”. see “want install sources package needs compilation?”, just choose “”. fail install, please carefully read warning messages find R package(s) causing failure, manually uninstall reinstall R package(s), retry main installation.","code":"## Method 1: Install from CRAN install.packages(\"bruceR\", dep=TRUE)  # dependencies=TRUE update.packages(ask=FALSE)  ## Method 2: Install from GitHub install.packages(\"devtools\") devtools::install_github(\"psychbruce/bruceR\", force=TRUE) update.packages(ask=FALSE)"},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"package-dependency","dir":"","previous_headings":"User Guide","what":"Package Dependency","title":"Broadly Useful Convenient and Efficient R Functions","text":"bruceR depends many important R packages. Loading bruceR library(bruceR) also load R packages : [Data]: dplyr: Data manipulation processing. tidyr: Data cleaning reshaping. stringr: Toolbox string operation (regular expressions). forcats: Toolbox factor manipulation (categorical variables). data.table: Advanced data.frame higher efficiency. [Stat]: emmeans: Estimates marginal means multiple contrasts. effectsize: Estimates effect sizes standardized parameters. performance: Estimates regression models performance. lmerTest: Tests linear mixed effects models (LMM, also known HLM multilevel models). [Plot]: ggplot2: Data visualization. ggtext: Markdown/HTML rich text format ggplot2 (geoms themes). cowplot: Advanced toolbox ggplot2 (arrange multiple plots add labels). see: Advanced toolbox ggplot2 (geoms, scales, themes, color palettes).","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"main-functions-in-brucer","dir":"","previous_headings":"User Guide","what":"Main Functions in bruceR","title":"Broadly Useful Convenient and Efficient R Functions","text":"Basic R Programming cc() (suggested) set.wd() (alias: set_wd()) (suggested) import(), export() (suggested) pkg_depend(), pkg_install_suggested() formatF(), formatN() print_table() Print(), Glue(), Run() %^% %notin% %allin%, %anyin%, %nonein%, %partin% Multivariate Computation add(), added() (suggested) .sum(), .mean() (suggested) SUM(), MEAN(), STD(), MODE(), COUNT(), CONSEC() RECODE(), RESCALE() LOOKUP() Reliability Factor Analyses Alpha() EFA() / PCA() CFA() Descriptive Statistics Correlation Analyses Describe() Freq() Corr() cor_diff() T-Test, Multi-Factor ANOVA, Simple-Effect Analysis, Post-Hoc Multiple Comparison TTEST() MANOVA() EMMEANS() Tidy Report Regression Models model_summary() (suggested) lavaan_summary() GLM_summary() HLM_summary() HLM_ICC_rWG() regress() Mediation Moderation Analyses PROCESS() (suggested) med_summary() Additional Toolbox Statistics Graphics grand_mean_center() group_mean_center() ccf_plot() granger_test() granger_causality() theme_bruce() show_colors()","code":""},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"function-output","dir":"","previous_headings":"User Guide","what":"Function Output","title":"Broadly Useful Convenient and Efficient R Functions","text":"functions, results can saved Microsoft Word using file argument. Examples:","code":"## Correlation analysis (and descriptive statistics) Corr(airquality, file=\"cor.doc\")  ## Regression analysis lm1 = lm(Temp ~ Month + Day, data=airquality) lm2 = lm(Temp ~ Month + Day + Wind + Solar.R, data=airquality) model_summary(list(lm1, lm2), file=\"reg.doc\") model_summary(list(lm1, lm2), std=TRUE, file=\"reg_std.doc\")"},{"path":"https://psychbruce.github.io/bruceR/index.html","id":"learn-more-from-help-pages","dir":"","previous_headings":"User Guide","what":"Learn More From Help Pages","title":"Broadly Useful Convenient and Efficient R Functions","text":"","code":"library(bruceR)  ## Overview help(\"bruceR\") help(bruceR) ?bruceR  ## See help pages of functions ## (use `?function` or `help(function)`) ?cc ?add ?.mean ?set.wd ?import ?export ?Describe ?Freq ?Corr ?Alpha ?MEAN ?RECODE ?TTEST ?MANOVA ?EMMEANS ?PROCESS ?model_summary ?lavaan_summary ?GLM_summary ?HLM_summary ..."},{"path":"https://psychbruce.github.io/bruceR/reference/Alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","title":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","text":"extension psych::alpha() psych::omega(), reporting (1) scale statistics (Cronbach's \\(\\alpha\\) McDonald's \\(\\omega\\)) (2) item statistics (item-rest correlation [.e., corrected item-total correlation] Cronbach's \\(\\alpha\\) item deleted). Three options specify variables: var + items: common unique parts variable names (suggested). vars: character vector variable names (suggested). varrange: starting stopping positions variables (suggested).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","text":"","code":"Alpha(   data,   var,   items,   vars = NULL,   varrange = NULL,   rev = NULL,   digits = 3,   nsmall = digits )"},{"path":"https://psychbruce.github.io/bruceR/reference/Alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","text":"data Data frame. var [Option 1] common part across variables. e.g., \"RSES\" items [Option 1] unique part across variables. e.g., 1:10 vars [Option 2] character vector specifying variables. e.g., c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\") varrange [Option 3] character string specifying positions (\"starting:stopping\") variables. e.g., \"A1:E5\" rev [Optional] Variables need reversed. can (1) character vector specifying reverse-scoring variables (recommended), (2) numeric vector specifying item number reverse-scoring variables (recommended). digits, nsmall Number decimal places output. Default 3.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","text":"list results obtained psych::alpha() psych::omega().","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/Alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reliability analysis (Cronbach's \\(\\alpha\\) and McDonald's \\(\\omega\\)). — Alpha","text":"","code":"# ?psych::bfi data = psych::bfi Alpha(data, \"E\", 1:5)   # \"E1\" & \"E2\" should be reversed #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 3.791 #> S.D. = 0.542 #> Cronbach’s α = -0.624 #> McDonald’s ω = 0.150 #>  #> Warning: Scale reliability is low. You may check item codings. #> Items E1, E2 correlate negatively with the scale and may be reversed. #> You can specify this argument: rev=c(\"E1\", \"E2\") #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ───────────────────────────────────────────── #>      Mean    S.D. Item-Rest Cor. Cronbach’s α #> ───────────────────────────────────────────── #> E1  2.972 (1.632)         -0.263       -0.270 #> E2  3.144 (1.607)         -0.355       -0.074 #> E3  4.000 (1.352)         -0.002       -0.881 #> E4  4.421 (1.461)         -0.202       -0.423 #> E5  4.418 (1.337)         -0.047       -0.765 #> ───────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>  Alpha(data, \"E\", 1:5, rev=1:2)            # correct #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 4.145 #> S.D. = 1.060 #> Cronbach’s α = 0.761 #> McDonald’s ω = 0.763 #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ─────────────────────────────────────────────────── #>            Mean    S.D. Item-Rest Cor. Cronbach’s α #> ─────────────────────────────────────────────────── #> E1 (rev)  4.028 (1.632)          0.513        0.725 #> E2 (rev)  3.856 (1.607)          0.606        0.688 #> E3        4.000 (1.352)          0.501        0.728 #> E4        4.421 (1.461)          0.578        0.701 #> E5        4.418 (1.337)          0.455        0.742 #> ─────────────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>  Alpha(data, \"E\", 1:5, rev=cc(\"E1, E2\"))   # also correct #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 4.145 #> S.D. = 1.060 #> Cronbach’s α = 0.761 #> McDonald’s ω = 0.763 #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ─────────────────────────────────────────────────── #>            Mean    S.D. Item-Rest Cor. Cronbach’s α #> ─────────────────────────────────────────────────── #> E1 (rev)  4.028 (1.632)          0.513        0.725 #> E2 (rev)  3.856 (1.607)          0.606        0.688 #> E3        4.000 (1.352)          0.501        0.728 #> E4        4.421 (1.461)          0.578        0.701 #> E5        4.418 (1.337)          0.455        0.742 #> ─────────────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>  Alpha(data, vars=cc(\"E1, E2, E3, E4, E5\"), rev=cc(\"E1, E2\")) #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 4.145 #> S.D. = 1.060 #> Cronbach’s α = 0.761 #> McDonald’s ω = 0.763 #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ─────────────────────────────────────────────────── #>            Mean    S.D. Item-Rest Cor. Cronbach’s α #> ─────────────────────────────────────────────────── #> E1 (rev)  4.028 (1.632)          0.513        0.725 #> E2 (rev)  3.856 (1.607)          0.606        0.688 #> E3        4.000 (1.352)          0.501        0.728 #> E4        4.421 (1.461)          0.578        0.701 #> E5        4.418 (1.337)          0.455        0.742 #> ─────────────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>  Alpha(data, varrange=\"E1:E5\", rev=cc(\"E1, E2\")) #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 4.145 #> S.D. = 1.060 #> Cronbach’s α = 0.761 #> McDonald’s ω = 0.763 #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ─────────────────────────────────────────────────── #>            Mean    S.D. Item-Rest Cor. Cronbach’s α #> ─────────────────────────────────────────────────── #> E1 (rev)  4.028 (1.632)          0.513        0.725 #> E2 (rev)  3.856 (1.607)          0.606        0.688 #> E3        4.000 (1.352)          0.501        0.728 #> E4        4.421 (1.461)          0.578        0.701 #> E5        4.418 (1.337)          0.455        0.742 #> ─────────────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>   # using dplyr::select() data %>% select(E1, E2, E3, E4, E5) %>%   Alpha(vars=names(.), rev=cc(\"E1, E2\")) #>  #> Reliability Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Scale Statistics: #> Mean = 4.145 #> S.D. = 1.060 #> Cronbach’s α = 0.761 #> McDonald’s ω = 0.763 #>  #> Item Statistics (Cronbach’s α If Item Deleted): #> ─────────────────────────────────────────────────── #>            Mean    S.D. Item-Rest Cor. Cronbach’s α #> ─────────────────────────────────────────────────── #> E1 (rev)  4.028 (1.632)          0.513        0.725 #> E2 (rev)  3.856 (1.607)          0.606        0.688 #> E3        4.000 (1.352)          0.501        0.728 #> E4        4.421 (1.461)          0.578        0.701 #> E5        4.418 (1.337)          0.455        0.742 #> ─────────────────────────────────────────────────── #> Item-Rest Cor. = Corrected Item-Total Correlation #>"},{"path":"https://psychbruce.github.io/bruceR/reference/CFA.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirmatory Factor Analysis (CFA). — CFA","title":"Confirmatory Factor Analysis (CFA). — CFA","text":"extension lavaan::cfa().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/CFA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirmatory Factor Analysis (CFA). — CFA","text":"","code":"CFA(   data,   model = \"A =~ a[1:5]; B =~ b[c(1,3,5)]; C =~ c1 + c2 + c3\",   estimator = \"ML\",   highorder = \"\",   orthogonal = FALSE,   missing = \"listwise\",   digits = 3,   nsmall = digits,   file = NULL )"},{"path":"https://psychbruce.github.io/bruceR/reference/CFA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confirmatory Factor Analysis (CFA). — CFA","text":"data Data frame. model Model formula. See examples. estimator estimator used (details, see lavaan options). Default \"ML\". Can one following: \"ML\" Maximum Likelihood (can extended   \"MLM\", \"MLMV\", \"MLMVS\", \"MLF\", \"MLR\"   robust standard errors robust test statistics) \"GLS\" Generalized Least Squares \"WLS\" Weighted Least Squares \"ULS\" Unweighted Least Squares \"DWLS\" Diagonally Weighted Least Squares \"DLS\" Distributionally-weighted Least Squares highorder High-order factor. Default \"\". orthogonal Default FALSE. TRUE, covariances among latent variables set zero. missing Default \"listwise\". Alternative \"fiml\" (\"Full Information Maximum Likelihood\"). digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/CFA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confirmatory Factor Analysis (CFA). — CFA","text":"list results returned lavaan::cfa().","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/CFA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confirmatory Factor Analysis (CFA). — CFA","text":"","code":"data.cfa=lavaan::HolzingerSwineford1939 CFA(data.cfa, \"Visual =~ x[1:3]; Textual =~ x[c(4,5,6)]; Speed =~ x7 + x8 + x9\") #>  #> Model Syntax (lavaan): #> Visual =~ x1 + x2 + x3 #> Textual =~ x4 + x5 + x6 #> Speed =~ x7 + x8 + x9 #>  #> Fit Measures (lavaan): #> χ²(24, N = 301) = 85.306, p = 9e-09 *** #> χ²/df = 3.554 #> AIC = 7517.490 (Akaike Information Criterion) #> BIC = 7595.339 (Bayesian Information Criterion) #> CFI = 0.931 (Comparative Fit Index) #> TLI = 0.896 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 0.907 (Normed Fit Index) #> IFI = 0.931 (Incremental Fit Index) #> GFI = 0.943 (Goodness-of-Fit Index) #> AGFI = 0.894 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.092, 90% CI [0.071, 0.114] (Root Mean Square Error of Approximation) #> SRMR = 0.065 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ────────────────────────────────────────────────────────────────────── #>                    Estimate    S.E.      z     p      LLCI  ULCI  Beta #> ────────────────────────────────────────────────────────────────────── #> Latent Variables:                                                      #>   Visual =~ x1        0.900 (0.081) 11.128 <.001 *** 0.741 1.058 0.772 #>   Visual =~ x2        0.498 (0.077)  6.429 <.001 *** 0.346 0.650 0.424 #>   Visual =~ x3        0.656 (0.074)  8.817 <.001 *** 0.510 0.802 0.581 #>   Textual =~ x4       0.990 (0.057) 17.474 <.001 *** 0.879 1.101 0.852 #>   Textual =~ x5       1.102 (0.063) 17.576 <.001 *** 0.979 1.224 0.855 #>   Textual =~ x6       0.917 (0.054) 17.082 <.001 *** 0.811 1.022 0.838 #>   Speed =~ x7         0.619 (0.070)  8.903 <.001 *** 0.483 0.756 0.570 #>   Speed =~ x8         0.731 (0.066) 11.090 <.001 *** 0.602 0.860 0.723 #>   Speed =~ x9         0.670 (0.065) 10.305 <.001 *** 0.543 0.797 0.665 #> ────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  #> Estimator: ML #>  CFA(data.cfa, model=\"     Visual =~ x[1:3]     Textual =~ x[c(4,5,6)]     Speed =~ x7 + x8 + x9     \", highorder=\"Ability\") #>  #> Model Syntax (lavaan): #> Visual =~ x1 + x2 + x3 #> Textual =~ x4 + x5 + x6 #> Speed =~ x7 + x8 + x9 #> Ability =~ Visual + Textual + Speed #> Ability ~~ Ability #>  #> Fit Measures (lavaan): #> χ²(24, N = 301) = 85.306, p = 9e-09 *** #> χ²/df = 3.554 #> AIC = 7517.490 (Akaike Information Criterion) #> BIC = 7595.339 (Bayesian Information Criterion) #> CFI = 0.931 (Comparative Fit Index) #> TLI = 0.896 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 0.907 (Normed Fit Index) #> IFI = 0.931 (Incremental Fit Index) #> GFI = 0.943 (Goodness-of-Fit Index) #> AGFI = 0.894 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.092, 90% CI [0.071, 0.114] (Root Mean Square Error of Approximation) #> SRMR = 0.065 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ─────────────────────────────────────────────────────────────────────────── #>                        Estimate    S.E.      z     p       LLCI  ULCI  Beta #> ─────────────────────────────────────────────────────────────────────────── #> Latent Variables:                                                           #>   Visual =~ x1            0.439 (0.194)  2.257  .024 *    0.058 0.819 0.772 #>   Visual =~ x2            0.243 (0.108)  2.253  .024 *    0.032 0.454 0.424 #>   Visual =~ x3            0.320 (0.138)  2.326  .020 *    0.050 0.589 0.581 #>   Textual =~ x4           0.842 (0.064) 13.251 <.001 ***  0.718 0.967 0.852 #>   Textual =~ x5           0.937 (0.071) 13.293 <.001 ***  0.799 1.076 0.855 #>   Textual =~ x6           0.780 (0.060) 13.084 <.001 ***  0.663 0.897 0.838 #>   Speed =~ x7             0.522 (0.066)  7.908 <.001 ***  0.392 0.651 0.570 #>   Speed =~ x8             0.616 (0.067)  9.129 <.001 ***  0.484 0.748 0.723 #>   Speed =~ x9             0.564 (0.064)  8.808 <.001 ***  0.439 0.690 0.665 #>   Ability =~ Visual       1.791 (0.990)  1.809  .070 .   -0.149 3.732 0.873 #>   Ability =~ Textual      0.617 (0.129)  4.798 <.001 ***  0.365 0.869 0.525 #>   Ability =~ Speed        0.640 (0.143)  4.489 <.001 ***  0.360 0.919 0.539 #> ─────────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  #> Estimator: ML #>   data.bfi = na.omit(psych::bfi) CFA(data.bfi, \"E =~ E[1:5]; A =~ A[1:5]; C =~ C[1:5]; N =~ N[1:5]; O =~ O[1:5]\") #>  #> Model Syntax (lavaan): #> E =~ E1 + E2 + E3 + E4 + E5 #> A =~ A1 + A2 + A3 + A4 + A5 #> C =~ C1 + C2 + C3 + C4 + C5 #> N =~ N1 + N2 + N3 + N4 + N5 #> O =~ O1 + O2 + O3 + O4 + O5 #>  #> Fit Measures (lavaan): #> χ²(265, N = 2236) = 3843.296, p < 1e-99 *** #> χ²/df = 14.503 #> AIC = 182698.556 (Akaike Information Criterion) #> BIC = 183041.303 (Bayesian Information Criterion) #> CFI = 0.780 (Comparative Fit Index) #> TLI = 0.751 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 0.768 (Normed Fit Index) #> IFI = 0.780 (Incremental Fit Index) #> GFI = 0.862 (Goodness-of-Fit Index) #> AGFI = 0.830 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.078, 90% CI [0.076, 0.080] (Root Mean Square Error of Approximation) #> SRMR = 0.076 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ────────────────────────────────────────────────────────────────────────── #>                    Estimate    S.E.       z     p       LLCI   ULCI   Beta #> ────────────────────────────────────────────────────────────────────────── #> Latent Variables:                                                          #>   E =~ E1             0.907 (0.035)  26.094 <.001 ***  0.838  0.975  0.560 #>   E =~ E2             1.114 (0.033)  33.914 <.001 ***  1.049  1.178  0.694 #>   E =~ E3            -0.866 (0.028) -30.936 <.001 *** -0.920 -0.811 -0.645 #>   E =~ E4            -1.027 (0.030) -34.530 <.001 *** -1.085 -0.968 -0.704 #>   E =~ E5            -0.746 (0.029) -26.147 <.001 *** -0.802 -0.691 -0.561 #>   A =~ A1             0.460 (0.032)  14.328 <.001 ***  0.397  0.523  0.330 #>   A =~ A2            -0.734 (0.025) -29.758 <.001 *** -0.782 -0.685 -0.634 #>   A =~ A3            -0.955 (0.027) -35.954 <.001 *** -1.008 -0.903 -0.741 #>   A =~ A4            -0.728 (0.032) -22.664 <.001 *** -0.791 -0.665 -0.503 #>   A =~ A5            -0.852 (0.026) -32.282 <.001 *** -0.903 -0.800 -0.678 #>   C =~ C1             0.652 (0.028)  23.697 <.001 ***  0.598  0.706  0.536 #>   C =~ C2             0.758 (0.029)  25.826 <.001 ***  0.700  0.815  0.578 #>   C =~ C3             0.707 (0.029)  24.376 <.001 ***  0.650  0.764  0.550 #>   C =~ C4            -0.949 (0.030) -32.012 <.001 *** -1.008 -0.891 -0.697 #>   C =~ C5            -1.014 (0.036) -28.108 <.001 *** -1.084 -0.943 -0.622 #>   N =~ N1             1.284 (0.029)  43.743 <.001 ***  1.227  1.342  0.821 #>   N =~ N2             1.222 (0.029)  41.954 <.001 ***  1.165  1.279  0.796 #>   N =~ N3             1.152 (0.031)  36.823 <.001 ***  1.091  1.214  0.722 #>   N =~ N4             0.891 (0.033)  27.399 <.001 ***  0.827  0.955  0.571 #>   N =~ N5             0.825 (0.035)  23.897 <.001 ***  0.757  0.892  0.509 #>   O =~ O1             0.629 (0.027)  23.245 <.001 ***  0.576  0.682  0.562 #>   O =~ O2            -0.666 (0.038) -17.641 <.001 *** -0.740 -0.592 -0.431 #>   O =~ O3             0.861 (0.029)  29.360 <.001 ***  0.804  0.919  0.722 #>   O =~ O4             0.260 (0.029)   8.850 <.001 ***  0.203  0.318  0.221 #>   O =~ O5            -0.633 (0.032) -19.604 <.001 *** -0.696 -0.570 -0.476 #> ────────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  #> Estimator: ML #>"},{"path":"https://psychbruce.github.io/bruceR/reference/Corr.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation analysis. — Corr","title":"Correlation analysis. — Corr","text":"Correlation analysis.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Corr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation analysis. — Corr","text":"","code":"Corr(   data,   method = \"pearson\",   p.adjust = \"none\",   all.as.numeric = TRUE,   digits = 2,   nsmall = digits,   file = NULL,   plot = TRUE,   plot.range = c(-1, 1),   plot.palette = NULL,   plot.color.levels = 201,   plot.file = NULL,   plot.width = 8,   plot.height = 6,   plot.dpi = 500 )"},{"path":"https://psychbruce.github.io/bruceR/reference/Corr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation analysis. — Corr","text":"data Data frame. method \"pearson\" (default), \"spearman\", \"kendall\". p.adjust Adjustment p values multiple tests: \"none\", \"fdr\", \"holm\", \"bonferroni\", ... details, see stats::p.adjust(). ..numeric TRUE (default) FALSE. Transform variables numeric (continuous). digits, nsmall Number decimal places output. Default 2. file File name MS Word (.doc). plot TRUE (default) FALSE. Plot correlation matrix. plot.range Range correlation coefficients plot. Default c(-1, 1). plot.palette Color gradient plot. Default c(\"#B52127\", \"white\", \"#2171B5\"). may also set , e.g., c(\"red\", \"white\", \"blue\"). plot.color.levels Default 201. plot.file NULL (default, plot RStudio) file name (\"xxx.png\"). plot.width Width (\"inch\") saved plot. Default 8. plot.height Height (\"inch\") saved plot. Default 6. plot.dpi DPI (dots per inch) saved plot. Default 500.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Corr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlation analysis. — Corr","text":"Invisibly return correlation results obtained psych::corr.test().","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/Corr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation analysis. — Corr","text":"","code":"Corr(airquality)  #> Correlation matrix is displayed in the RStudio `Plots` Pane. #>  #> Pearson's r and 95% confidence intervals: #> ───────────────────────────────────────────────── #>                    r       [95% CI]     p       N #> ───────────────────────────────────────────────── #> Ozone-Solar.R   0.35 [ 0.17,  0.50] <.001 *** 111 #> Ozone-Wind     -0.60 [-0.71, -0.47] <.001 *** 116 #> Ozone-Temp      0.70 [ 0.59,  0.78] <.001 *** 116 #> Ozone-Month     0.16 [-0.02,  0.34]  .078 .   116 #> Ozone-Day      -0.01 [-0.20,  0.17]  .888     116 #> Solar.R-Wind   -0.06 [-0.22,  0.11]  .496     146 #> Solar.R-Temp    0.28 [ 0.12,  0.42] <.001 *** 146 #> Solar.R-Month  -0.08 [-0.23,  0.09]  .366     146 #> Solar.R-Day    -0.15 [-0.31,  0.01]  .070 .   146 #> Wind-Temp      -0.46 [-0.57, -0.32] <.001 *** 153 #> Wind-Month     -0.18 [-0.33, -0.02]  .027 *   153 #> Wind-Day        0.03 [-0.13,  0.19]  .739     153 #> Temp-Month      0.42 [ 0.28,  0.54] <.001 *** 153 #> Temp-Day       -0.13 [-0.28,  0.03]  .108     153 #> Month-Day      -0.01 [-0.17,  0.15]  .922     153 #> ───────────────────────────────────────────────── #>  Corr(airquality, p.adjust=\"bonferroni\")  #> Correlation matrix is displayed in the RStudio `Plots` Pane. #> p values ABOVE the diagonal are adjusted using the \"bonferroni\" method. #>  #> Pearson's r and 95% confidence intervals: #> p values and 95% CIs are adjusted using the \"bonferroni\" method. #> ───────────────────────────────────────────────── #>                    r       [95% CI]     p       N #> ───────────────────────────────────────────────── #> Ozone-Solar.R   0.35 [ 0.08,  0.57]  .003 **  111 #> Ozone-Wind     -0.60 [-0.75, -0.40] <.001 *** 116 #> Ozone-Temp      0.70 [ 0.53,  0.81] <.001 *** 116 #> Ozone-Month     0.16 [-0.11,  0.42] 1.000     116 #> Ozone-Day      -0.01 [-0.28,  0.26] 1.000     116 #> Solar.R-Wind   -0.06 [-0.29,  0.19] 1.000     146 #> Solar.R-Temp    0.28 [ 0.04,  0.48]  .011 *   146 #> Solar.R-Month  -0.08 [-0.31,  0.17] 1.000     146 #> Solar.R-Day    -0.15 [-0.38,  0.09] 1.000     146 #> Wind-Temp      -0.46 [-0.63, -0.25] <.001 *** 153 #> Wind-Month     -0.18 [-0.40,  0.06]  .412     153 #> Wind-Day        0.03 [-0.21,  0.26] 1.000     153 #> Temp-Month      0.42 [ 0.21,  0.60] <.001 *** 153 #> Temp-Day       -0.13 [-0.35,  0.11] 1.000     153 #> Month-Day      -0.01 [-0.24,  0.23] 1.000     153 #> ───────────────────────────────────────────────── #>   d = as.data.table(psych::bfi) added(d, {   gender = as.factor(gender)   education = as.factor(education)   E = .mean(\"E\", 1:5, rev=c(1,2), range=1:6)   A = .mean(\"A\", 1:5, rev=1, range=1:6)   C = .mean(\"C\", 1:5, rev=c(4,5), range=1:6)   N = .mean(\"N\", 1:5, range=1:6)   O = .mean(\"O\", 1:5, rev=c(2,5), range=1:6) }) #> √ Raw data has already been changed. Please check. Corr(d[, .(age, gender, education, E, A, C, N, O)]) #> NOTE: `gender`, `education` transformed to numeric. #>   #> Correlation matrix is displayed in the RStudio `Plots` Pane. #>  #> Pearson's r and 95% confidence intervals: #> ───────────────────────────────────────────────────── #>                       r       [95% CI]     p        N #> ───────────────────────────────────────────────────── #> age-gender         0.05 [ 0.01,  0.08]  .012 *   2800 #> age-education      0.24 [ 0.21,  0.28] <.001 *** 2577 #> age-E              0.06 [ 0.03,  0.10] <.001 *** 2800 #> age-A              0.19 [ 0.15,  0.22] <.001 *** 2800 #> age-C              0.12 [ 0.08,  0.15] <.001 *** 2800 #> age-N             -0.12 [-0.15, -0.08] <.001 *** 2800 #> age-O              0.08 [ 0.04,  0.12] <.001 *** 2800 #> gender-education   0.01 [-0.03,  0.05]  .695     2577 #> gender-E           0.11 [ 0.07,  0.14] <.001 *** 2800 #> gender-A           0.21 [ 0.17,  0.24] <.001 *** 2800 #> gender-C           0.09 [ 0.06,  0.13] <.001 *** 2800 #> gender-N           0.12 [ 0.09,  0.16] <.001 *** 2800 #> gender-O          -0.06 [-0.10, -0.02]  .002 **  2800 #> education-E        0.01 [-0.03,  0.05]  .697     2577 #> education-A        0.05 [ 0.01,  0.08]  .021 *   2577 #> education-C        0.02 [-0.02,  0.06]  .305     2577 #> education-N       -0.05 [-0.09, -0.01]  .012 *   2577 #> education-O        0.11 [ 0.07,  0.14] <.001 *** 2577 #> E-A                0.46 [ 0.43,  0.49] <.001 *** 2800 #> E-C                0.26 [ 0.23,  0.30] <.001 *** 2800 #> E-N               -0.22 [-0.26, -0.18] <.001 *** 2800 #> E-O                0.21 [ 0.18,  0.25] <.001 *** 2800 #> A-C                0.26 [ 0.22,  0.29] <.001 *** 2800 #> A-N               -0.19 [-0.22, -0.15] <.001 *** 2800 #> A-O                0.15 [ 0.11,  0.18] <.001 *** 2800 #> C-N               -0.23 [-0.27, -0.20] <.001 *** 2800 #> C-O                0.20 [ 0.16,  0.23] <.001 *** 2800 #> N-O               -0.09 [-0.12, -0.05] <.001 *** 2800 #> ───────────────────────────────────────────────────── #>"},{"path":"https://psychbruce.github.io/bruceR/reference/Describe.html","id":null,"dir":"Reference","previous_headings":"","what":"Descriptive statistics. — Describe","title":"Descriptive statistics. — Describe","text":"Descriptive statistics.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Describe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Descriptive statistics. — Describe","text":"","code":"Describe(   data,   all.as.numeric = TRUE,   digits = 2,   nsmall = digits,   file = NULL,   plot = FALSE,   upper.triangle = FALSE,   upper.smooth = \"none\",   plot.file = NULL,   plot.width = 8,   plot.height = 6,   plot.dpi = 500 )"},{"path":"https://psychbruce.github.io/bruceR/reference/Describe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Descriptive statistics. — Describe","text":"data Data frame numeric vector. ..numeric TRUE (default) FALSE. Transform variables numeric (continuous). digits, nsmall Number decimal places output. Default 2. file File name MS Word (.doc). plot TRUE FALSE (default). Visualize descriptive statistics using GGally::ggpairs(). upper.triangle TRUE FALSE (default). Add (scatter) plots upper triangle (time consuming sample size large). upper.smooth \"none\" (default), \"lm\", \"loess\". Add fitting lines scatter plots (). plot.file NULL (default, plot RStudio) file name (\"xxx.png\"). plot.width Width (\"inch\") saved plot. Default 8. plot.height Height (\"inch\") saved plot. Default 6. plot.dpi DPI (dots per inch) saved plot. Default 500.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Describe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Descriptive statistics. — Describe","text":"Invisibly return list consisting (1) data frame descriptive statistics (2) ggplot2 object users set plot=TRUE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/Describe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Descriptive statistics. — Describe","text":"","code":"set.seed(1) Describe(rnorm(1000000), plot=TRUE) #> Descriptive Statistics: #> ────────────────────────────────────────────────────────── #>          N Mean   SD | Median   Min  Max Skewness Kurtosis #> ────────────────────────────────────────────────────────── #>    1000000 0.00 1.00 |   0.00 -4.88 4.65    -0.00    -0.01 #> ────────────────────────────────────────────────────────── #> Registered S3 method overwritten by 'GGally': #>   method from    #>   +.gg   ggplot2   Describe(airquality) #> Descriptive Statistics: #> ────────────────────────────────────────────────────────────────────── #>            N (NA)   Mean    SD | Median   Min    Max Skewness Kurtosis #> ────────────────────────────────────────────────────────────────────── #> Ozone    116   37  42.13 32.99 |  31.50  1.00 168.00     1.21     1.11 #> Solar.R  146    7 185.93 90.06 | 205.00  7.00 334.00    -0.42    -1.00 #> Wind     153        9.96  3.52 |   9.70  1.70  20.70     0.34     0.03 #> Temp     153       77.88  9.47 |  79.00 56.00  97.00    -0.37    -0.46 #> Month    153        6.99  1.42 |   7.00  5.00   9.00    -0.00    -1.32 #> Day      153       15.80  8.86 |  16.00  1.00  31.00     0.00    -1.22 #> ────────────────────────────────────────────────────────────────────── Describe(airquality, plot=TRUE, upper.triangle=TRUE, upper.smooth=\"lm\") #> Descriptive Statistics: #> ────────────────────────────────────────────────────────────────────── #>            N (NA)   Mean    SD | Median   Min    Max Skewness Kurtosis #> ────────────────────────────────────────────────────────────────────── #> Ozone    116   37  42.13 32.99 |  31.50  1.00 168.00     1.21     1.11 #> Solar.R  146    7 185.93 90.06 | 205.00  7.00 334.00    -0.42    -1.00 #> Wind     153        9.96  3.52 |   9.70  1.70  20.70     0.34     0.03 #> Temp     153       77.88  9.47 |  79.00 56.00  97.00    -0.37    -0.46 #> Month    153        6.99  1.42 |   7.00  5.00   9.00    -0.00    -1.32 #> Day      153       15.80  8.86 |  16.00  1.00  31.00     0.00    -1.22 #> ────────────────────────────────────────────────────────────────────── #> Warning: Removed 37 rows containing non-finite values (stat_density). #> Warning: Removed 42 rows containing non-finite values (stat_smooth). #> Warning: Removed 42 rows containing missing values (geom_point). #> Warning: Removed 37 rows containing non-finite values (stat_smooth). #> Warning: Removed 37 rows containing missing values (geom_point). #> Warning: Removed 37 rows containing non-finite values (stat_smooth). #> Warning: Removed 37 rows containing missing values (geom_point). #> Warning: Removed 37 rows containing non-finite values (stat_smooth). #> Warning: Removed 37 rows containing missing values (geom_point). #> Warning: Removed 37 rows containing non-finite values (stat_smooth). #> Warning: Removed 37 rows containing missing values (geom_point). #> Warning: Removed 7 rows containing non-finite values (stat_density). #> Warning: Removed 7 rows containing non-finite values (stat_smooth). #> Warning: Removed 7 rows containing missing values (geom_point). #> Warning: Removed 7 rows containing non-finite values (stat_smooth). #> Warning: Removed 7 rows containing missing values (geom_point). #> Warning: Removed 7 rows containing non-finite values (stat_smooth). #> Warning: Removed 7 rows containing missing values (geom_point). #> Warning: Removed 7 rows containing non-finite values (stat_smooth). #> Warning: Removed 7 rows containing missing values (geom_point).   # ?psych::bfi Describe(psych::bfi[c(\"age\", \"gender\", \"education\")]) #> Descriptive Statistics: #> ────────────────────────────────────────────────────────────────────── #>               N (NA)  Mean    SD | Median  Min   Max Skewness Kurtosis #> ────────────────────────────────────────────────────────────────────── #> age        2800      28.78 11.13 |  26.00 3.00 86.00     1.02     0.56 #> gender     2800       1.67  0.47 |   2.00 1.00  2.00    -0.73    -1.47 #> education  2577  223  3.19  1.11 |   3.00 1.00  5.00    -0.05    -0.32 #> ──────────────────────────────────────────────────────────────────────  d = as.data.table(psych::bfi) added(d, {   gender = as.factor(gender)   education = as.factor(education)   E = .mean(\"E\", 1:5, rev=c(1,2), range=1:6)   A = .mean(\"A\", 1:5, rev=1, range=1:6)   C = .mean(\"C\", 1:5, rev=c(4,5), range=1:6)   N = .mean(\"N\", 1:5, range=1:6)   O = .mean(\"O\", 1:5, rev=c(2,5), range=1:6) }) #> √ Raw data has already been changed. Please check. Describe(d[, .(age, gender, education)], plot=TRUE, all.as.numeric=FALSE) #> Descriptive Statistics: #> ─────────────────────────────────────────────────────────────────────── #>                N (NA)  Mean    SD | Median  Min   Max Skewness Kurtosis #> ─────────────────────────────────────────────────────────────────────── #> age         2800      28.78 11.13 |  26.00 3.00 86.00     1.02     0.56 #> gender*     2800       1.67  0.47 |   2.00 1.00  2.00    -0.73    -1.47 #> education*  2577  223  3.19  1.11 |   3.00 1.00  5.00    -0.05    -0.32 #> ─────────────────────────────────────────────────────────────────────── #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.  Describe(d[, .(age, gender, education, E, A, C, N, O)], plot=TRUE) #> Descriptive Statistics: #> ─────────────────────────────────────────────────────────────────────── #>                N (NA)  Mean    SD | Median  Min   Max Skewness Kurtosis #> ─────────────────────────────────────────────────────────────────────── #> age         2800      28.78 11.13 |  26.00 3.00 86.00     1.02     0.56 #> gender*     2800       1.67  0.47 |   2.00 1.00  2.00    -0.73    -1.47 #> education*  2577  223  3.19  1.11 |   3.00 1.00  5.00    -0.05    -0.32 #> E           2800       4.15  1.06 |   4.20 1.00  6.00    -0.48    -0.21 #> A           2800       4.65  0.90 |   4.80 1.00  6.00    -0.76     0.40 #> C           2800       4.27  0.95 |   4.40 1.00  6.00    -0.40    -0.19 #> N           2800       3.16  1.20 |   3.00 1.00  6.00     0.21    -0.67 #> O           2800       4.59  0.81 |   4.60 1.20  6.00    -0.34    -0.29 #> ─────────────────────────────────────────────────────────────────────── #>  #> NOTE: `gender`, `education` transformed to numeric. #> Warning: Removed 223 rows containing non-finite values (stat_density)."},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"extension psych::principal() psych::fa(), performing either Principal Component Analysis (PCA) Exploratory Factor Analysis (EFA). Three options specify variables: var + items: use common unique parts variable names. vars: directly define character vector variables. varrange: use starting stopping positions variables.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"","code":"EFA(   data,   var,   items,   vars = NULL,   varrange = NULL,   rev = NULL,   method = c(\"pca\", \"pa\", \"ml\", \"minres\", \"uls\", \"ols\", \"wls\", \"gls\", \"alpha\"),   rotation = c(\"none\", \"varimax\", \"oblimin\", \"promax\", \"quartimax\", \"equamax\"),   nfactors = c(\"eigen\", \"parallel\", \"(any number >= 1)\"),   sort.loadings = TRUE,   hide.loadings = 0,   plot.scree = TRUE,   kaiser = TRUE,   max.iter = 25,   min.eigen = 1,   digits = 3,   nsmall = digits,   file = NULL )  PCA(..., method = \"pca\")"},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"data Data frame. var [Option 1] common part across variables. e.g., \"RSES\" items [Option 1] unique part across variables. e.g., 1:10 vars [Option 2] character vector specifying variables. e.g., c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\") varrange [Option 3] character string specifying positions (\"starting:stopping\") variables. e.g., \"A1:E5\" rev [Optional] Variables need reversed. can (1) character vector specifying reverse-scoring variables (recommended), (2) numeric vector specifying item number reverse-scoring variables (recommended). method Extraction method. \"pca\" - Principal Component Analysis (default) \"pa\" - Principal Axis Factor Analysis \"ml\" - Maximum Likelihood Factor Analysis \"minres\" - Minimum Residual Factor Analysis \"uls\" - Unweighted Least Squares Factor Analysis \"ols\" - Ordinary Least Squares Factor Analysis \"wls\" - Weighted Least Squares Factor Analysis \"gls\" - Generalized Least Squares Factor Analysis \"alpha\" - Alpha Factor Analysis (Kaiser & Coffey, 1965) rotation Rotation method. \"none\" - None (suggested) \"varimax\" - Varimax (default) \"oblimin\" - Direct Oblimin \"promax\" - Promax \"quartimax\" - Quartimax \"equamax\" - Equamax nfactors determine number factors/components? \"eigen\" - based eigenvalue (> minimum eigenvalue) (default) \"parallel\" - based parallel analysis (number >= 1) - user-defined fixed number sort.loadings Sort factor/component loadings size? Default TRUE. hide.loadings number (0~1) hiding absolute factor/component loadings value. Default 0 (hide loading). plot.scree Display scree plot? Default TRUE. kaiser Kaiser normalization (SPSS)? Default TRUE. max.iter Maximum number iterations convergence. Default 25 (SPSS). min.eigen Minimum eigenvalue (used nfactors=\"eigen\"). Default 1. digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc). ... Arguments passed PCA() EFA().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"list results: result R object returned psych::principal() psych::fa() result.kaiser R object returned psych::kaiser() () extraction.method Extraction method rotation.method Rotation method eigenvalues data.frame eigenvalues sum squared (SS) loadings loadings data.frame factor/component loadings communalities scree.plot ggplot2 object scree plot","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"EFA: Exploratory Factor Analysis PCA: Principal Component Analysis - wrapper EFA(..., method=\"pca\")","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"Results based varimax rotation method identical SPSS. rotation methods may produce results slightly different SPSS.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/EFA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal Component Analysis (PCA) and Exploratory Factor analysis (EFA). — EFA","text":"","code":"data = psych::bfi EFA(data, \"E\", 1:5)              # var + items #>  #> Principal Component Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Extraction Method: #> - Principal Component Analysis #> Rotation Method: #> - (Only one component was extracted. The solution was not rotated.) #>  #> KMO and Bartlett's Test: #> - Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy: MSA = 0.799 #> - Bartlett's Test of Sphericity: Approx. χ²(10) = 3011.40, p < 1e-99 *** #>  #> Total Variance Explained: #> ────────────────────────────────────────────────────────────────────────────────── #>              Eigenvalue Variance % Cumulative % SS Loading Variance % Cumulative % #> ────────────────────────────────────────────────────────────────────────────────── #> Component 1       2.565     51.298       51.298      2.565     51.298       51.298 #> Component 2       0.768     15.368       66.666                                    #> Component 3       0.643     12.851       79.517                                    #> Component 4       0.561     11.211       90.728                                    #> Component 5       0.464      9.272      100.000                                    #> ────────────────────────────────────────────────────────────────────────────────── #>  #> Component Loadings (Sorted by Size): #> ────────────────────── #>        PC1 Communality #> ────────────────────── #> E2  -0.780       0.608 #> E4   0.758       0.575 #> E1  -0.700       0.490 #> E3   0.691       0.477 #> E5   0.644       0.414 #> ────────────────────── #> Communality = Sum of Squared (SS) Factor Loadings #> (Uniqueness = 1 - Communality) #>   EFA(data, \"E\", 1:5, nfactors=2)  # var + items #>  #> Principal Component Analysis #>  #> Summary: #> Total Items: 5 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2713 (96.9%) #>  #> Extraction Method: #> - Principal Component Analysis #> Rotation Method: #> - Varimax (with Kaiser Normalization) #>  #> KMO and Bartlett's Test: #> - Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy: MSA = 0.799 #> - Bartlett's Test of Sphericity: Approx. χ²(10) = 3011.40, p < 1e-99 *** #>  #> Total Variance Explained: #> ────────────────────────────────────────────────────────────────────────────────── #>              Eigenvalue Variance % Cumulative % SS Loading Variance % Cumulative % #> ────────────────────────────────────────────────────────────────────────────────── #> Component 1       2.565     51.298       51.298      1.884     37.680       37.680 #> Component 2       0.768     15.368       66.666      1.449     28.986       66.666 #> Component 3       0.643     12.851       79.517                                    #> Component 4       0.561     11.211       90.728                                    #> Component 5       0.464      9.272      100.000                                    #> ────────────────────────────────────────────────────────────────────────────────── #>  #> Component Loadings (Rotated) (Sorted by Size): #> ───────────────────────────── #>        RC1    RC2 Communality #> ───────────────────────────── #> E1   0.812 -0.098       0.668 #> E2   0.752 -0.304       0.658 #> E4  -0.736  0.290       0.625 #> E5  -0.145  0.860       0.761 #> E3  -0.312  0.723       0.620 #> ───────────────────────────── #> Communality = Sum of Squared (SS) Factor Loadings #> (Uniqueness = 1 - Communality) #>    EFA(data, varrange=\"A1:O5\",     nfactors=\"parallel\",     hide.loadings=0.45) #>  #> Principal Component Analysis #>  #> Summary: #> Total Items: 25 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2436 (87.0%) #>  #> Extraction Method: #> - Principal Component Analysis #> Rotation Method: #> - Varimax (with Kaiser Normalization) #>  #> KMO and Bartlett's Test: #> - Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy: MSA = 0.849 #> - Bartlett's Test of Sphericity: Approx. χ²(300) = 18146.07, p < 1e-99 *** #>  #> Total Variance Explained: #> ─────────────────────────────────────────────────────────────────────────────────── #>               Eigenvalue Variance % Cumulative % SS Loading Variance % Cumulative % #> ─────────────────────────────────────────────────────────────────────────────────── #> Component 1        5.134     20.537       20.537      3.185     12.738       12.738 #> Component 2        2.752     11.008       31.545      3.100     12.400       25.138 #> Component 3        2.143      8.571       40.116      2.619     10.476       35.615 #> Component 4        1.852      7.409       47.525      2.378      9.512       45.127 #> Component 5        1.548      6.193       53.718      2.148      8.591       53.718 #> Component 6        1.074      4.294       58.012                                    #> Component 7        0.840      3.358       61.370                                    #> Component 8        0.799      3.197       64.567                                    #> Component 9        0.719      2.876       67.443                                    #> Component 10       0.688      2.752       70.195                                    #> Component 11       0.676      2.705       72.901                                    #> Component 12       0.652      2.607       75.508                                    #> Component 13       0.623      2.493       78.001                                    #> Component 14       0.597      2.386       80.387                                    #> Component 15       0.563      2.252       82.640                                    #> Component 16       0.543      2.173       84.813                                    #> Component 17       0.515      2.058       86.871                                    #> Component 18       0.495      1.978       88.849                                    #> Component 19       0.483      1.931       90.779                                    #> Component 20       0.449      1.796       92.575                                    #> Component 21       0.423      1.693       94.269                                    #> Component 22       0.401      1.603       95.871                                    #> Component 23       0.388      1.551       97.422                                    #> Component 24       0.382      1.527       98.950                                    #> Component 25       0.263      1.050      100.000                                    #> ─────────────────────────────────────────────────────────────────────────────────── #>  #> Component Loadings (Rotated) (Sorted by Size): #> ───────────────────────────────────────────────── #>       RC2    RC1    RC3    RC5    RC4 Communality #> ───────────────────────────────────────────────── #> N1  0.806                                   0.710 #> N2  0.794                                   0.670 #> N3  0.794                                   0.636 #> N4  0.649                                   0.587 #> N5  0.631                                   0.482 #> E2        -0.722                            0.608 #> E4         0.700                            0.610 #> E1        -0.679                            0.478 #> E3         0.625                            0.532 #> E5         0.586                            0.506 #> C2                0.738                     0.579 #> C4               -0.692                     0.566 #> C3                0.679                     0.478 #> C1                0.654                     0.483 #> C5               -0.627                     0.532 #> A2                       0.716              0.582 #> A3                       0.689              0.606 #> A1                      -0.638              0.467 #> A5                       0.572              0.542 #> A4                       0.530              0.424 #> O5                             -0.677       0.473 #> O3                              0.640       0.561 #> O2                             -0.606       0.436 #> O1                              0.598       0.444 #> O4                              0.494       0.440 #> ───────────────────────────────────────────────── #> Communality = Sum of Squared (SS) Factor Loadings #> (Uniqueness = 1 - Communality) #>    # the same as above: # using dplyr::select() and dplyr::matches() # to select variables whose names end with numbers # (regexp: \\d matches all numbers, $ matches the end of a string) data %>% select(matches(\"\\\\d$\")) %>%   EFA(vars=names(.),       # all selected variables       method=\"pca\",        # default       rotation=\"varimax\",  # default       nfactors=\"parallel\", # parallel analysis       hide.loadings=0.45)  # hide loadings < 0.45 #>  #> Principal Component Analysis #>  #> Summary: #> Total Items: 25 #> Scale Range: 1 ~ 6 #> Total Cases: 2800 #> Valid Cases: 2436 (87.0%) #>  #> Extraction Method: #> - Principal Component Analysis #> Rotation Method: #> - Varimax (with Kaiser Normalization) #>  #> KMO and Bartlett's Test: #> - Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy: MSA = 0.849 #> - Bartlett's Test of Sphericity: Approx. χ²(300) = 18146.07, p < 1e-99 *** #>  #> Total Variance Explained: #> ─────────────────────────────────────────────────────────────────────────────────── #>               Eigenvalue Variance % Cumulative % SS Loading Variance % Cumulative % #> ─────────────────────────────────────────────────────────────────────────────────── #> Component 1        5.134     20.537       20.537      3.185     12.738       12.738 #> Component 2        2.752     11.008       31.545      3.100     12.400       25.138 #> Component 3        2.143      8.571       40.116      2.619     10.476       35.615 #> Component 4        1.852      7.409       47.525      2.378      9.512       45.127 #> Component 5        1.548      6.193       53.718      2.148      8.591       53.718 #> Component 6        1.074      4.294       58.012                                    #> Component 7        0.840      3.358       61.370                                    #> Component 8        0.799      3.197       64.567                                    #> Component 9        0.719      2.876       67.443                                    #> Component 10       0.688      2.752       70.195                                    #> Component 11       0.676      2.705       72.901                                    #> Component 12       0.652      2.607       75.508                                    #> Component 13       0.623      2.493       78.001                                    #> Component 14       0.597      2.386       80.387                                    #> Component 15       0.563      2.252       82.640                                    #> Component 16       0.543      2.173       84.813                                    #> Component 17       0.515      2.058       86.871                                    #> Component 18       0.495      1.978       88.849                                    #> Component 19       0.483      1.931       90.779                                    #> Component 20       0.449      1.796       92.575                                    #> Component 21       0.423      1.693       94.269                                    #> Component 22       0.401      1.603       95.871                                    #> Component 23       0.388      1.551       97.422                                    #> Component 24       0.382      1.527       98.950                                    #> Component 25       0.263      1.050      100.000                                    #> ─────────────────────────────────────────────────────────────────────────────────── #>  #> Component Loadings (Rotated) (Sorted by Size): #> ───────────────────────────────────────────────── #>       RC2    RC1    RC3    RC5    RC4 Communality #> ───────────────────────────────────────────────── #> N1  0.806                                   0.710 #> N2  0.794                                   0.670 #> N3  0.794                                   0.636 #> N4  0.649                                   0.587 #> N5  0.631                                   0.482 #> E2        -0.722                            0.608 #> E4         0.700                            0.610 #> E1        -0.679                            0.478 #> E3         0.625                            0.532 #> E5         0.586                            0.506 #> C2                0.738                     0.579 #> C4               -0.692                     0.566 #> C3                0.679                     0.478 #> C1                0.654                     0.483 #> C5               -0.627                     0.532 #> A2                       0.716              0.582 #> A3                       0.689              0.606 #> A1                      -0.638              0.467 #> A5                       0.572              0.542 #> A4                       0.530              0.424 #> O5                             -0.677       0.473 #> O3                              0.640       0.561 #> O2                             -0.606       0.436 #> O1                              0.598       0.444 #> O4                              0.494       0.440 #> ───────────────────────────────────────────────── #> Communality = Sum of Squared (SS) Factor Loadings #> (Uniqueness = 1 - Communality) #>"},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"Perform (1) simple-effect (simple-simple-effect) analyses, including simple main effects simple interaction effects, (2) post-hoc multiple comparisons (e.g., pairwise, sequential, polynomial), p values adjusted factors >= 3 levels. function based extends (1) emmeans::joint_tests(), (2) emmeans::emmeans(), (3) emmeans::contrast(). need specify model object, --tested effect(s), moderator(s). Almost results need displayed together, including effect sizes (partial \\(\\eta^2\\) Cohen's d) confidence intervals (CIs). 90% CIs partial \\(\\eta^2\\) 95% CIs Cohen's d reported. default, root mean square error (RMSE) used compute pooled SD Cohen's d. Specifically, uses: square root mean square error (MSE) -subjects designs; square root mean variance paired differences residuals repeated measures within-subjects mixed designs. Disclaimer: substantial disagreement appropriate pooled SD use computing effect size. alternative methods, see emmeans::eff_size() effectsize::t_to_d(). Users take default output right results completely responsible specifying sd.pooled.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"","code":"EMMEANS(   model,   effect = NULL,   by = NULL,   contrast = \"pairwise\",   reverse = TRUE,   p.adjust = \"bonferroni\",   sd.pooled = NULL,   model.type = \"multivariate\",   digits = 3,   nsmall = digits )"},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"model model object returned MANOVA. effect Effect(s) want test. set character string (e.g., \"\"), reports results omnibus test simple main effect. set character vector (e.g., c(\"\", \"B\")), also reports results simple interaction effect. Moderator variable(s). Default NULL. contrast Contrast method multiple comparisons. Default \"pairwise\". Alternatives can \"pairwise\" (\"revpairwise\"), \"seq\" (\"consec\"), \"poly\", \"eff\". details, see ?emmeans::`contrast-methods`. reverse order levels contrasted. Default TRUE (higher level vs. lower level). p.adjust Adjustment method p values multiple comparisons. Default \"bonferroni\". polynomial contrasts, default \"none\". Alternatives can \"none\", \"fdr\", \"hochberg\", \"hommel\", \"holm\", \"tukey\", \"mvt\", \"dunnettx\", \"sidak\", \"scheffe\", \"bonferroni\". details, see stats::p.adjust() emmeans::summary(). sd.pooled default, uses sqrt(MSE) (root mean square error, RMSE) pooled SD compute Cohen's d. Users may specify argument SD reference group, use effectsize::sd_pooled() obtain pooled SD. issue computation method Cohen's d, see Disclaimer . model.type \"multivariate\" returns results pairwise comparisons identical SPSS, uses lm (rather aov) object model emmeans::joint_tests() emmeans::emmeans(). \"univariate\" requires also specifying aov.include=TRUE MANOVA (recommended afex package; details, see afex::aov_ez()). digits, nsmall Number decimal places output. Default 3.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"model object returned MANOVA (recursive use), along list tables: sim (simple effects), emm (estimated marginal means), con (contrasts). EMMEANS(...) appends one list returned object.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"interaction-plot-see-examples-below-","dir":"Reference","previous_headings":"","what":"Interaction Plot (See Examples Below)","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"can save returned object use emmeans::emmip() function create interaction plot (based fitted model formula). See examples usage. Note: emmeans::emmip() returns ggplot object, can modified saved ggplot2 syntax.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"statistical-details","dir":"Reference","previous_headings":"","what":"Statistical Details","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"may confuse statistical terms \"simple effects\", \"post-hoc tests\", \"multiple comparisons\". confusion uncommon. explain terms actually refer . 1. Simple Effect speak \"simple effect\", referring ... simple main effect simple interaction effect (designs 3 factors) simple simple effect (designs 3 factors) interaction effect ANOVA significant,     perform \"simple-effect analysis\".     regression, call \"simple-slope analysis\".     identical statistical principles. two-factors design, test \"simple main effect\".     , different levels factor \"B\", main effects \"\" different.     However, three-factors () design, may also test \"simple interaction effect\" \"simple simple effect\".     , different combinations levels factors \"B\" \"C\", main effects \"\" different. note, simple effects per se never require p-value adjustment, test simple-effect analyses still \"omnibus F-tests\". 2. Post-Hoc Test term \"post-hoc\" means tests performed ANOVA. Given , may (wrongly) regard simple-effect analyses also kind post-hoc tests.     However, two terms distinguished. many situations,     \"post-hoc tests\" refer \"post-hoc comparisons\" using t-tests p-value adjustment techniques.     need post-hoc comparisons factors 3 levels. Post-hoc tests totally independent whether significant interaction effect. deals factors multiple levels.     cases, use pairwise comparisons post-hoc tests. See next part details. 3. Multiple Comparison mentioned , multiple comparisons indeed post-hoc tests relationship simple-effect analyses.     Post-hoc multiple comparisons independent interaction effects simple effects.     Furthermore, simple main effect contains 3 levels, also need multiple comparisons within simple-effect analysis.     situation, also need p-value adjustment methods Bonferroni, Tukey's HSD (honest significant difference), FDR (false discovery rate), forth. Options multiple comparison: \"pairwise\" - Pairwise comparisons (default \"higher level - lower level\") \"seq\" \"consec\" - Consecutive (sequential) comparisons \"poly\" - Polynomial contrasts (linear, quadratic, cubic, quartic, ...) \"eff\" - Effect contrasts (vs. grand mean)","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/EMMEANS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple-effect analysis and post-hoc multiple comparison. — EMMEANS","text":"","code":"#### Between-Subjects Design ####  between.1 #>    A SCORE #> 1  1     3 #> 2  1     6 #> 3  1     4 #> 4  1     3 #> 5  1     5 #> 6  1     7 #> 7  1     5 #> 8  1     2 #> 9  2     4 #> 10 2     6 #> 11 2     4 #> 12 2     2 #> 13 2     4 #> 14 2     5 #> 15 2     3 #> 16 2     3 #> 17 3     8 #> 18 3     9 #> 19 3     8 #> 20 3     7 #> 21 3     5 #> 22 3     6 #> 23 3     7 #> 24 3     6 #> 25 4     9 #> 26 4     8 #> 27 4     8 #> 28 4     7 #> 29 4    12 #> 30 4    13 #> 31 4    12 #> 32 4    11 MANOVA(between.1, dv=\"SCORE\", between=\"A\") %>%   EMMEANS(\"A\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.812   3  28 22.533 <.001 ***   .707 [.526, .798] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       3.235   3  28  .037 *   #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────── #>  Effect df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────── #>       A   3  28 22.533 <.001 ***   .707 [.526, .798] #> ──────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> Mean: \"A\"         190.125  3      63.375 22.533 <.001 *** #> Residuals          78.750 28       2.812                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────── #>  \"A\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────── #>   A1  4.375 [3.160,  5.590] (0.593) #>   A2  3.875 [2.660,  5.090] (0.593) #>   A3  7.000 [5.785,  8.215] (0.593) #>   A4 10.000 [8.785, 11.215] (0.593) #> ─────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────── #>  Contrast Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────── #>   A2 - A1   -0.500 (0.839) 28 -0.596 1.000      -0.298 [-1.718, 1.121] #>   A3 - A1    2.625 (0.839) 28  3.130  .024 *     1.565 [ 0.146, 2.985] #>   A3 - A2    3.125 (0.839) 28  3.727  .005 **    1.863 [ 0.444, 3.283] #>   A4 - A1    5.625 (0.839) 28  6.708 <.001 ***   3.354 [ 1.935, 4.774] #>   A4 - A2    6.125 (0.839) 28  7.304 <.001 ***   3.652 [ 2.233, 5.072] #>   A4 - A3    3.000 (0.839) 28  3.578  .008 **    1.789 [ 0.369, 3.208] #> ────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.677 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  MANOVA(between.1, dv=\"SCORE\", between=\"A\") %>%   EMMEANS(\"A\", p.adjust=\"tukey\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.812   3  28 22.533 <.001 ***   .707 [.526, .798] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       3.235   3  28  .037 *   #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────── #>  Effect df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────── #>       A   3  28 22.533 <.001 ***   .707 [.526, .798] #> ──────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> Mean: \"A\"         190.125  3      63.375 22.533 <.001 *** #> Residuals          78.750 28       2.812                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────── #>  \"A\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────── #>   A1  4.375 [3.160,  5.590] (0.593) #>   A2  3.875 [2.660,  5.090] (0.593) #>   A3  7.000 [5.785,  8.215] (0.593) #>   A4 10.000 [8.785, 11.215] (0.593) #> ─────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────── #>  Contrast Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────── #>   A2 - A1   -0.500 (0.839) 28 -0.596  .932      -0.298 [-1.663, 1.067] #>   A3 - A1    2.625 (0.839) 28  3.130  .020 *     1.565 [ 0.200, 2.930] #>   A3 - A2    3.125 (0.839) 28  3.727  .005 **    1.863 [ 0.498, 3.229] #>   A4 - A1    5.625 (0.839) 28  6.708 <.001 ***   3.354 [ 1.989, 4.719] #>   A4 - A2    6.125 (0.839) 28  7.304 <.001 ***   3.652 [ 2.287, 5.017] #>   A4 - A3    3.000 (0.839) 28  3.578  .007 **    1.789 [ 0.424, 3.154] #> ────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.677 #> P-value adjustment: Tukey method for comparing a family of 4 estimates. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  MANOVA(between.1, dv=\"SCORE\", between=\"A\") %>%   EMMEANS(\"A\", contrast=\"seq\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.812   3  28 22.533 <.001 ***   .707 [.526, .798] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       3.235   3  28  .037 *   #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────── #>  Effect df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────── #>       A   3  28 22.533 <.001 ***   .707 [.526, .798] #> ──────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> Mean: \"A\"         190.125  3      63.375 22.533 <.001 *** #> Residuals          78.750 28       2.812                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────── #>  \"A\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────── #>   A1  4.375 [3.160,  5.590] (0.593) #>   A2  3.875 [2.660,  5.090] (0.593) #>   A3  7.000 [5.785,  8.215] (0.593) #>   A4 10.000 [8.785, 11.215] (0.593) #> ─────────────────────────────────── #>  #> Consecutive (Sequential) Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────── #>  Contrast Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────── #>   A2 - A1   -0.500 (0.839) 28 -0.596 1.000      -0.298 [-1.571, 0.975] #>   A3 - A2    3.125 (0.839) 28  3.727  .003 **    1.863 [ 0.590, 3.137] #>   A4 - A3    3.000 (0.839) 28  3.578  .004 **    1.789 [ 0.516, 3.062] #> ────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.677 #> P-value adjustment: Bonferroni method for 3 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  MANOVA(between.1, dv=\"SCORE\", between=\"A\") %>%   EMMEANS(\"A\", contrast=\"poly\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.812   3  28 22.533 <.001 ***   .707 [.526, .798] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       3.235   3  28  .037 *   #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────── #>  Effect df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────── #>       A   3  28 22.533 <.001 ***   .707 [.526, .798] #> ──────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> Mean: \"A\"         190.125  3      63.375 22.533 <.001 *** #> Residuals          78.750 28       2.812                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────── #>  \"A\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────── #>   A1  4.375 [3.160,  5.590] (0.593) #>   A2  3.875 [2.660,  5.090] (0.593) #>   A3  7.000 [5.785,  8.215] (0.593) #>   A4 10.000 [8.785, 11.215] (0.593) #> ─────────────────────────────────── #>  #> Polynomial Contrasts of \"A\": #> ─────────────────────────────────────────────── #>   Contrast Estimate    S.E. df      t     p     #> ─────────────────────────────────────────────── #>  linear      20.000 (2.652) 28  7.542 <.001 *** #>  quadratic    3.500 (1.186) 28  2.951  .006 **  #>  cubic       -3.750 (2.652) 28 -1.414  .168     #> ─────────────────────────────────────────────── #>  #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>   between.2 #>    A B SCORE #> 1  1 1     3 #> 2  1 1     6 #> 3  1 1     4 #> 4  1 1     3 #> 5  1 2     4 #> 6  1 2     6 #> 7  1 2     4 #> 8  1 2     2 #> 9  1 3     5 #> 10 1 3     7 #> 11 1 3     5 #> 12 1 3     2 #> 13 2 1     4 #> 14 2 1     5 #> 15 2 1     3 #> 16 2 1     3 #> 17 2 2     8 #> 18 2 2     9 #> 19 2 2     8 #> 20 2 2     7 #> 21 2 3    12 #> 22 2 3    13 #> 23 2 3    12 #> 24 2 3    11 MANOVA(between.2, dv=\"SCORE\", between=c(\"A\", \"B\")) %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(\"B\", by=\"A\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 24 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────────── #> A      80.667 1.861   1  18 43.343 <.001 ***   .707 [.482, .817] .707 #> B      40.542 1.861   2  18 21.784 <.001 ***   .708 [.470, .815] .708 #> A * B  28.292 1.861   2  18 15.201 <.001 ***   .628 [.347, .763] .628 #> ───────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.605   5  18  .697     #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>       A  B1   1  18  0.067  .798       .004 [.000, .137] #>       A  B2   1  18 17.194 <.001 ***   .489 [.198, .674] #>       A  B3   1  18 56.485 <.001 ***   .758 [.564, .849] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> B1: \"A\"             0.125  1       0.125  0.067  .798     #> B2: \"A\"            32.000  1      32.000 17.194 <.001 *** #> B3: \"A\"           105.125  1     105.125 56.485 <.001 *** #> Residuals          33.500 18       1.861                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 2.567,  5.433] (0.682) #>   A2  B1  3.750 [ 2.317,  5.183] (0.682) #>   A1  B2  4.000 [ 2.567,  5.433] (0.682) #>   A2  B2  8.000 [ 6.567,  9.433] (0.682) #>   A1  B3  4.750 [ 3.317,  6.183] (0.682) #>   A2  B3 12.000 [10.567, 13.433] (0.682) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1   -0.250 (0.965) 18 -0.259  .798      -0.183 [-1.669, 1.302] #>   A2 - A1  B2    4.000 (0.965) 18  4.147 <.001 ***   2.932 [ 1.446, 4.418] #>   A2 - A1  B3    7.250 (0.965) 18  7.516 <.001 ***   5.314 [ 3.829, 6.800] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.364 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"B\") ------ #>  #> Joint Tests of \"B\": #> ──────────────────────────────────────────────────────── #>  Effect \"A\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>       B  A1   2  18  0.403  .674       .043 [.000, .205] #>       B  A2   2  18 36.582 <.001 ***   .803 [.631, .876] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"B\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> A1: \"B\"             1.500  2       0.750  0.403  .674     #> A2: \"B\"           136.167  2      68.083 36.582 <.001 *** #> Residuals          33.500 18       1.861                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"B\": #> ──────────────────────────────────────── #>  \"B\" \"A\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   B1  A1  4.000 [ 2.567,  5.433] (0.682) #>   B2  A1  4.000 [ 2.567,  5.433] (0.682) #>   B3  A1  4.750 [ 3.317,  6.183] (0.682) #>   B1  A2  3.750 [ 2.317,  5.183] (0.682) #>   B2  A2  8.000 [ 6.567,  9.433] (0.682) #>   B3  A2 12.000 [10.567, 13.433] (0.682) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"B\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"A\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   B2 - B1  A1   -0.000 (0.965) 18 -0.000 1.000      -0.000 [-1.866, 1.866] #>   B3 - B1  A1    0.750 (0.965) 18  0.777 1.000       0.550 [-1.316, 2.416] #>   B3 - B2  A1    0.750 (0.965) 18  0.777 1.000       0.550 [-1.316, 2.416] #>   B2 - B1  A2    4.250 (0.965) 18  4.406  .001 **    3.115 [ 1.249, 4.981] #>   B3 - B1  A2    8.250 (0.965) 18  8.552 <.001 ***   6.047 [ 4.181, 7.914] #>   B3 - B2  A2    4.000 (0.965) 18  4.147  .002 **    2.932 [ 1.066, 4.798] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.364 #> P-value adjustment: Bonferroni method for 3 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  ## How to create an interaction plot using `emmeans::emmip()`? ## See help page: ?emmeans::emmip() m = MANOVA(between.2, dv=\"SCORE\", between=c(\"A\", \"B\")) #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 24 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────────── #> A      80.667 1.861   1  18 43.343 <.001 ***   .707 [.482, .817] .707 #> B      40.542 1.861   2  18 21.784 <.001 ***   .708 [.470, .815] .708 #> A * B  28.292 1.861   2  18 15.201 <.001 ***   .628 [.347, .763] .628 #> ───────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.605   5  18  .697     #> ─────────────────────────────────────── #>  emmip(m, ~ A | B, CIs=TRUE)  emmip(m, ~ B | A, CIs=TRUE)  emmip(m, B ~ A, CIs=TRUE)  emmip(m, A ~ B, CIs=TRUE)   between.3 #>    A B C SCORE #> 1  1 1 1     3 #> 2  1 1 1     6 #> 3  1 1 1     4 #> 4  1 1 1     3 #> 5  1 1 2     5 #> 6  1 1 2     7 #> 7  1 1 2     5 #> 8  1 1 2     2 #> 9  1 2 1     4 #> 10 1 2 1     6 #> 11 1 2 1     4 #> 12 1 2 1     2 #> 13 1 2 2     4 #> 14 1 2 2     5 #> 15 1 2 2     3 #> 16 1 2 2     3 #> 17 2 1 1     8 #> 18 2 1 1     9 #> 19 2 1 1     8 #> 20 2 1 1     7 #> 21 2 1 2     5 #> 22 2 1 2     6 #> 23 2 1 2     7 #> 24 2 1 2     6 #> 25 2 2 1     9 #> 26 2 2 1     8 #> 27 2 2 1     8 #> 28 2 2 1     7 #> 29 2 2 2    12 #> 30 2 2 2    13 #> 31 2 2 2    12 #> 32 2 2 2    11 MANOVA(between.3, dv=\"SCORE\", between=c(\"A\", \"B\", \"C\")) %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(c(\"A\", \"B\"), by=\"C\") %>%   EMMEANS(\"A\", by=c(\"B\", \"C\")) #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B, C #> Within-subjects factor(s):  – #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 1.563   1  24 98.000 <.001 ***   .803 [.670, .870] .803 #> B           12.500 1.563   1  24  8.000  .009 **    .250 [.042, .466] .250 #> C            3.125 1.563   1  24  2.000  .170       .077 [.000, .283] .077 #> A * B       24.500 1.563   1  24 15.680 <.001 ***   .395 [.147, .585] .395 #> A * C        1.125 1.563   1  24  0.720  .405       .029 [.000, .206] .029 #> B * C       12.500 1.563   1  24  8.000  .009 **    .250 [.042, .466] .250 #> A * B * C   24.500 1.563   1  24 15.680 <.001 ***   .395 [.147, .585] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.668   7  24  .697     #> ─────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      B1   1  24 17.640 <.001 ***   .424 [.173, .607] #>   A      B2   1  24 96.040 <.001 ***   .800 [.665, .868] #>   C      B1   1  24  1.000  .327       .040 [.000, .226] #>   C      B2   1  24  9.000  .006 **    .273 [.055, .486] #>   A * C  B1   1  24  4.840  .038 *     .168 [.006, .388] #>   A * C  B2   1  24 11.560  .002 **    .325 [.090, .530] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ───────────────────────────────────────────────────────── #>            Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────── #> B1: \"A\"            27.562  1      27.562 17.640 <.001 *** #> B2: \"A\"           150.062  1     150.062 96.040 <.001 *** #> Residuals          37.500 24       1.563                  #> ───────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────────── #>  \"A\" \"B\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────────── #>   A1  B1  4.375 [3.463,  5.287] (0.442) #>   A2  B1  7.000 [6.088,  7.912] (0.442) #>   A1  B2  3.875 [2.963,  4.787] (0.442) #>   A2  B2 10.000 [9.088, 10.912] (0.442) #> ─────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ───────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df     t     p     Cohen’s d [95% CI of d] #> ───────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1    2.625 (0.625) 24 4.200 <.001 ***    2.100 [1.068, 3.132] #>   A2 - A1  B2    6.125 (0.625) 24 9.800 <.001 ***    4.900 [3.868, 5.932] #> ───────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.250 #> Results are averaged over the levels of: C #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\" & \"B\") ------ #>  #> Joint Tests of \"A\" & \"B\": #> ──────────────────────────────────────────────────────── #>  Effect \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      C1   1  24 40.960 <.001 ***   .631 [.414, .754] #>   A      C2   1  24 57.760 <.001 ***   .706 [.521, .806] #>   B      C1   1  24  0.000 1.000       .000 [.000, .000] #>   B      C2   1  24 16.000 <.001 ***   .400 [.151, .589] #>   A * B  C1   1  24  0.000 1.000       .000 [.000, .000] #>   A * B  C2   1  24 31.360 <.001 ***   .566 [.331, .710] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\" & \"B\": #> ───────────────────────────────────────────────────────────── #>                Sum of Squares df Mean Square      F     p     #> ───────────────────────────────────────────────────────────── #> C1: \"A\" & \"B\"           0.000  1       0.000  0.000 1.000     #> C2: \"A\" & \"B\"          49.000  1      49.000 31.360 <.001 *** #> Residuals              37.500 24       1.563                  #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\" & \"B\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 2.710,  5.290] (0.625) #>   A2  B1  8.000 [ 6.710,  9.290] (0.625) #>   A1  B2  4.000 [ 2.710,  5.290] (0.625) #>   A2  B2  8.000 [ 6.710,  9.290] (0.625) #>   A1  B1  4.750 [ 3.460,  6.040] (0.625) #>   A2  B1  6.000 [ 4.710,  7.290] (0.625) #>   A1  B2  3.750 [ 2.460,  5.040] (0.625) #>   A2  B2 12.000 [10.710, 13.290] (0.625) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────────────────── #>       Contrast \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ─────────────────────────────────────────────────────────────────────────────── #>  A2 B1 - A1 B1  C1    4.000 (0.884) 24  4.525 <.001 ***  3.200 [ 1.167,  5.233] #>  A1 B2 - A1 B1  C1   -0.000 (0.884) 24 -0.000 1.000     -0.000 [-2.033,  2.033] #>  A1 B2 - A2 B1  C1   -4.000 (0.884) 24 -4.525 <.001 *** -3.200 [-5.233, -1.167] #>  A2 B2 - A1 B1  C1    4.000 (0.884) 24  4.525 <.001 ***  3.200 [ 1.167,  5.233] #>  A2 B2 - A2 B1  C1   -0.000 (0.884) 24 -0.000 1.000     -0.000 [-2.033,  2.033] #>  A2 B2 - A1 B2  C1    4.000 (0.884) 24  4.525 <.001 ***  3.200 [ 1.167,  5.233] #>  A2 B1 - A1 B1  C2    1.250 (0.884) 24  1.414 1.000      1.000 [-1.033,  3.033] #>  A1 B2 - A1 B1  C2   -1.000 (0.884) 24 -1.131 1.000     -0.800 [-2.833,  1.233] #>  A1 B2 - A2 B1  C2   -2.250 (0.884) 24 -2.546  .107     -1.800 [-3.833,  0.233] #>  A2 B2 - A1 B1  C2    7.250 (0.884) 24  8.202 <.001 ***  5.800 [ 3.767,  7.833] #>  A2 B2 - A2 B1  C2    6.000 (0.884) 24  6.788 <.001 ***  4.800 [ 2.767,  6.833] #>  A2 B2 - A1 B2  C2    8.250 (0.884) 24  9.334 <.001 ***  6.600 [ 4.567,  8.633] #> ─────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.250 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────────── #>  Effect \"B\" \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────────── #>       A  B1  C1   1  24 20.480 <.001 ***   .460 [.210, .634] #>       A  B2  C1   1  24 20.480 <.001 ***   .460 [.210, .634] #>       A  B1  C2   1  24  2.000  .170       .077 [.000, .283] #>       A  B2  C2   1  24 87.120 <.001 ***   .784 [.639, .858] #> ──────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"A\": #> ──────────────────────────────────────────────────────────── #>               Sum of Squares df Mean Square      F     p     #> ──────────────────────────────────────────────────────────── #> B1 & C1: \"A\"          32.000  1      32.000 20.480 <.001 *** #> B2 & C1: \"A\"          32.000  1      32.000 20.480 <.001 *** #> B1 & C2: \"A\"           3.125  1       3.125  2.000  .170     #> B2 & C2: \"A\"         136.125  1     136.125 87.120 <.001 *** #> Residuals             37.500 24       1.563                  #> ──────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────────── #>  \"A\" \"B\" \"C\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────────── #>   A1  B1  C1  4.000 [ 2.710,  5.290] (0.625) #>   A2  B1  C1  8.000 [ 6.710,  9.290] (0.625) #>   A1  B2  C1  4.000 [ 2.710,  5.290] (0.625) #>   A2  B2  C1  8.000 [ 6.710,  9.290] (0.625) #>   A1  B1  C2  4.750 [ 3.460,  6.040] (0.625) #>   A2  B1  C2  6.000 [ 4.710,  7.290] (0.625) #>   A1  B2  C2  3.750 [ 2.460,  5.040] (0.625) #>   A2  B2  C2 12.000 [10.710, 13.290] (0.625) #> ──────────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ───────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" \"C\" Estimate    S.E. df     t     p     Cohen’s d [95% CI of d] #> ───────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1  C1    4.000 (0.884) 24 4.525 <.001 ***   3.200 [ 1.741, 4.659] #>   A2 - A1  B2  C1    4.000 (0.884) 24 4.525 <.001 ***   3.200 [ 1.741, 4.659] #>   A2 - A1  B1  C2    1.250 (0.884) 24 1.414  .170       1.000 [-0.459, 2.459] #>   A2 - A1  B2  C2    8.250 (0.884) 24 9.334 <.001 ***   6.600 [ 5.141, 8.059] #> ───────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.250 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  ## Just to name a few... ## You may test other combinations...   #### Within-Subjects Design ####  within.1 #>   ID A1 A2 A3 A4 #> 1 S1  3  4  8  9 #> 2 S2  6  6  9  8 #> 3 S3  4  4  8  8 #> 4 S4  3  2  7  7 #> 5 S5  5  4  5 12 #> 6 S6  7  5  6 13 #> 7 S7  5  3  7 12 #> 8 S8  2  3  6 11 MANOVA(within.1, dvs=\"A1:A4\", dvs.pattern=\"A(.)\",        within=\"A\") %>%   EMMEANS(\"A\") #>  #> Note: #> dvs=\"A1:A4\" is matched to variables: #> A1, A2, A3, A4 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      A1, A2, A3, A4 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.518   3  21 25.170 <.001 ***   .782 [.609, .858] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────── #>    Mauchly's W     p     #> ──────────────────────── #> A       0.1899  .095 .   #> ──────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────── #>  Effect df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────── #>       A   3   7 47.960 <.001 ***   .954 [.848, .977] #> ──────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ─────────────────────────────────────────────────────────────── #>            Pillai’s trace Hypoth. df Error df Exact F     p     #> ─────────────────────────────────────────────────────────────── #> Mean: \"A\"           0.954      3.000    5.000  34.257 <.001 *** #> ─────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────── #>  \"A\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────── #>   A1  4.375 [2.966,  5.784] (0.596) #>   A2  3.875 [2.833,  4.917] (0.441) #>   A3  7.000 [5.905,  8.095] (0.463) #>   A4 10.000 [8.104, 11.896] (0.802) #> ─────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────── #>  Contrast Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────── #>   A2 - A1   -0.500 (0.423)  7 -1.183 1.000      -0.223 [-0.907, 0.462] #>   A3 - A1    2.625 (0.754)  7  3.479  .062 .     1.170 [-0.053, 2.392] #>   A3 - A2    3.125 (0.515)  7  6.063  .003 **    1.393 [ 0.558, 2.228] #>   A4 - A1    5.625 (0.778)  7  7.232  .001 **    2.507 [ 1.247, 3.767] #>   A4 - A2    6.125 (0.875)  7  7.000  .001 **    2.729 [ 1.312, 4.147] #>   A4 - A3    3.000 (1.180)  7  2.542  .231       1.337 [-0.575, 3.249] #> ────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 2.244 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>   within.2 #>   ID A1B1 A1B2 A1B3 A2B1 A2B2 A2B3 #> 1 S1    3    4    5    4    8   12 #> 2 S2    6    6    7    5    9   13 #> 3 S3    4    4    5    3    8   12 #> 4 S4    3    2    2    3    7   11 MANOVA(within.2, dvs=\"A1B1:A2B3\", dvs.pattern=\"A(.)B(.)\",        within=c(\"A\", \"B\")) %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(\"B\", by=\"A\")  # singular error matrix #>  #> Note: #> dvs=\"A1B1:A2B3\" is matched to variables: #> A1B1, A1B2, A1B3, A2B1, A2B2, A2B3 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 4 #>  #> ANOVA Table: #> Dependent variable(s):      A1B1, A1B2, A1B3, A2B1, A2B2, A2B3 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A, B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2       F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────── #> A      80.667 1.111   1   3  72.600  .003 **    .960 [.699, .985] .707 #> B      40.542 0.264   2   6 153.632 <.001 ***   .981 [.930, .991] .708 #> A * B  28.292 0.236   2   6 119.824 <.001 ***   .976 [.911, .988] .628 #> ────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────── #>        Mauchly's W     p     #> ──────────────────────────── #> B           0.0665  .066 .   #> A * B       0.2491  .249     #> ──────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ───────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────── #>       A  B1   1   3   0.273  .638       .083 [.000, .597] #>       A  B2   1   3  96.000  .002 **    .970 [.763, .988] #>       A  B3   1   3 132.789  .001 **    .978 [.823, .992] #> ───────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> B1: \"A\"           0.083      1.000    3.000   0.273  .638     #> B2: \"A\"           0.970      1.000    3.000  96.000  .002 **  #> B3: \"A\"           0.978      1.000    3.000 132.789  .001 **  #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 1.750,  6.250] (0.707) #>   A2  B1  3.750 [ 2.227,  5.273] (0.479) #>   A1  B2  4.000 [ 1.402,  6.598] (0.816) #>   A2  B2  8.000 [ 6.701,  9.299] (0.408) #>   A1  B3  4.750 [ 1.470,  8.030] (1.031) #>   A2  B3 12.000 [10.701, 13.299] (0.408) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1   -0.250 (0.479)  3 -0.522  .638     -0.272 [-1.930,  1.386] #>   A2 - A1  B2    4.000 (0.408)  3  9.798  .002 **   4.353 [ 2.939,  5.767] #>   A2 - A1  B3    7.250 (0.629)  3 11.523  .001 **   7.890 [ 5.711, 10.068] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.919 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"B\") ------ #>  #> Error in solve.default(zcov, z) :  #>   system is computationally singular: reciprocal condition number = 2.23113e-17 #> Warning: Some CIs could not be estimated due to non-finite F, df, or df_error values. #> Joint Tests of \"B\": #> ───────────────────────────────────────────────────────── #>  Effect \"A\" df1 df2      F     p      η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────── #>       B  A1   2   3 13.500  .032 *   .900 [.219, .962]    #>       B  A2   2                         NA [   NA,    NA] #> ───────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Estimated Marginal Means of \"B\": #> ──────────────────────────────────────── #>  \"B\" \"A\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   B1  A1  4.000 [ 1.750,  6.250] (0.707) #>   B2  A1  4.000 [ 1.402,  6.598] (0.816) #>   B3  A1  4.750 [ 1.470,  8.030] (1.031) #>   B1  A2  3.750 [ 2.227,  5.273] (0.479) #>   B2  A2  8.000 [ 6.701,  9.299] (0.408) #>   B3  A2 12.000 [10.701, 13.299] (0.408) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"B\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"A\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   B2 - B1  A1    0.000 (0.408)  3  0.000 1.000      0.000 [-2.158,  2.158] #>   B3 - B1  A1    0.750 (0.629)  3  1.192  .957      0.816 [-2.509,  4.141] #>   B3 - B2  A1    0.750 (0.250)  3  3.000  .173      0.816 [-0.505,  2.137] #>   B2 - B1  A2    4.250 (0.250)  3 17.000  .001 **   4.625 [ 3.304,  5.946] #>   B3 - B1  A2    8.250 (0.250)  3 33.000 <.001 ***  8.978 [ 7.656, 10.299] #>   B3 - B2  A2    4.000 (0.000)  3    Inf <.001 ***  4.353 [ 4.353,  4.353] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.919 #> P-value adjustment: Bonferroni method for 3 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  # ::::::::::::::::::::::::::::::::::::::: # This would produce a WARNING because of # the linear dependence of A2B2 and A2B3. # See: Corr(within.2[c(\"A2B2\", \"A2B3\")])  within.3 #>   ID A1B1C1 A1B1C2 A1B2C1 A1B2C2 A2B1C1 A2B1C2 A2B2C1 A2B2C2 #> 1 S1      3      5      4      4      8      5      9     12 #> 2 S2      6      7      6      5      9      6      8     13 #> 3 S3      4      5      4      3      8      7      8     12 #> 4 S4      3      2      2      3      7      6      7     11 MANOVA(within.3, dvs=\"A1B1C1:A2B2C2\", dvs.pattern=\"A(.)B(.)C(.)\",        within=c(\"A\", \"B\", \"C\")) %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(c(\"A\", \"B\"), by=\"C\") %>%   EMMEANS(\"A\", by=c(\"B\", \"C\")) #>  #> Note: #> dvs=\"A1B1C1:A2B2C2\" is matched to variables: #> A1B1C1, A1B1C2, A1B2C1, A1B2C2, A2B1C1, A2B1C2, A2B2C1, A2B2C2 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 4 #>  #> ANOVA Table: #> Dependent variable(s):      A1B1C1, A1B1C2, A1B2C1, A1B2C2, A2B1C1, A2B1C2, A2B2C1, A2B2C2 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A, B, C #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 1.875   1   3 81.667  .003 **    .965 [.727, .986] .803 #> B           12.500 0.583   1   3 21.429  .019 *     .877 [.279, .954] .250 #> C            3.125 0.042   1   3 75.000  .003 **    .962 [.707, .985] .077 #> A * B       24.500 0.250   1   3 98.000  .002 **    .970 [.768, .989] .395 #> A * C        1.125 0.708   1   3  1.588  .297       .346 [.000, .543] .029 #> B * C       12.500 0.417   1   3 30.000  .012 *     .909 [.411, .965] .250 #> A * B * C   24.500 1.083   1   3 22.615  .018 *     .883 [.300, .956] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ───────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────── #>   C      B1   1   3   6.818  .080 .     .694 [.000, .886] #>   C      B2   1   3  61.364  .004 **    .953 [.653, .982] #>   A      B1   1   3  17.640  .025 *     .855 [.202, .945] #>   A      B2   1   3 266.778 <.001 ***   .989 [.908, .996] #>   C * A  B1   1   3   6.153  .089 .     .672 [.000, .877] #>   C * A  B2   1   3  32.111  .011 *     .915 [.436, .968] #> ───────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> B1: \"A\"           0.855      1.000    3.000  17.640  .025 *   #> B2: \"A\"           0.989      1.000    3.000 266.778 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────────── #>  \"A\" \"B\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────────── #>   A1  B1  4.375 [1.746,  7.004] (0.826) #>   A2  B1  7.000 [6.081,  7.919] (0.289) #>   A1  B2  3.875 [1.886,  5.864] (0.625) #>   A2  B2 10.000 [8.875, 11.125] (0.354) #> ─────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1    2.625 (0.625)  3  4.200  .025 *      2.205 [0.534, 3.877] #>   A2 - A1  B2    6.125 (0.375)  3 16.333 <.001 ***    5.146 [4.143, 6.149] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.190 #> Results are averaged over the levels of: C #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\" & \"B\") ------ #>  #> Joint Tests of \"A\" & \"B\": #> ──────────────────────────────────────────────────────── #>  Effect \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   B      C1   1   3  0.000 1.000       .000 [.000, .000] #>   B      C2   1   3 50.000  .006 **    .943 [.610, .978] #>   A      C1   1   3 54.857  .005 **    .948 [.620, .980] #>   A      C2   1   3 63.706  .004 **    .955 [.664, .983] #>   B * A  C1   1   3  0.000 1.000       .000 [.000, .000] #>   B * A  C2   1   3 42.000  .007 **    .933 [.534, .975] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────── #>                Pillai’s trace Hypoth. df Error df Exact F     p     #> ─────────────────────────────────────────────────────────────────── #> C1: \"A\" & \"B\"           0.000      1.000    3.000   0.000 1.000     #> C2: \"A\" & \"B\"           0.933      1.000    3.000  42.000  .007 **  #> ─────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\" & \"B\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 1.750,  6.250] (0.707) #>   A2  B1  8.000 [ 6.701,  9.299] (0.408) #>   A1  B2  4.000 [ 1.402,  6.598] (0.816) #>   A2  B2  8.000 [ 6.701,  9.299] (0.408) #>   A1  B1  4.750 [ 1.470,  8.030] (1.031) #>   A2  B1  6.000 [ 4.701,  7.299] (0.408) #>   A1  B2  3.750 [ 2.227,  5.273] (0.479) #>   A2  B2 12.000 [10.701, 13.299] (0.408) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────────────────── #>       Contrast \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ─────────────────────────────────────────────────────────────────────────────── #>  A2 B1 - A1 B1  C1    4.000 (0.408)  3  9.798  .014 *    3.361 [ 1.223,  5.498] #>  A1 B2 - A1 B1  C1    0.000 (0.408)  3  0.000 1.000      0.000 [-2.137,  2.137] #>  A1 B2 - A2 B1  C1   -4.000 (0.408)  3 -9.798  .014 *   -3.361 [-5.498, -1.223] #>  A2 B2 - A1 B1  C1    4.000 (0.816)  3  4.899  .098 .    3.361 [-0.914,  7.635] #>  A2 B2 - A2 B1  C1    0.000 (0.408)  3  0.000 1.000      0.000 [-2.137,  2.137] #>  A2 B2 - A1 B2  C1    4.000 (0.707)  3  5.657  .066 .    3.361 [-0.341,  7.063] #>  A2 B1 - A1 B1  C2    1.250 (1.109)  3  1.127 1.000      1.050 [-4.754,  6.855] #>  A1 B2 - A1 B1  C2   -1.000 (0.707)  3 -1.414 1.000     -0.840 [-4.542,  2.862] #>  A1 B2 - A2 B1  C2   -2.250 (0.750)  3 -3.000  .346     -1.890 [-5.817,  2.036] #>  A2 B2 - A1 B1  C2    7.250 (0.629)  3 11.523  .008 **   6.091 [ 2.797,  9.385] #>  A2 B2 - A2 B1  C2    6.000 (0.577)  3 10.392  .011 *    5.041 [ 2.018,  8.064] #>  A2 B2 - A1 B2  C2    8.250 (0.250)  3 33.000 <.001 ***  6.931 [ 5.623,  8.240] #> ─────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.190 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ────────────────────────────────────────────────────────────── #>  Effect \"B\" \"C\" df1 df2        F     p     η²p [90% CI of η²p] #> ────────────────────────────────────────────────────────────── #>       A  B1  C1   1   3   96.000  .002 **    .970 [.763, .988] #>       A  B2  C1   1   3   32.000  .011 *     .914 [.435, .967] #>       A  B1  C2   1   3    1.271  .342       .298 [.000, .729] #>       A  B2  C2   1   3 1089.000 <.001 ***   .997 [.977, .999] #> ────────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ─────────────────────────────────────────────────────────────────── #>               Pillai’s trace Hypoth. df Error df  Exact F     p     #> ─────────────────────────────────────────────────────────────────── #> B1 & C1: \"A\"           0.970      1.000    3.000   96.000  .002 **  #> B2 & C1: \"A\"           0.914      1.000    3.000   32.000  .011 *   #> B1 & C2: \"A\"           0.298      1.000    3.000    1.271  .342     #> B2 & C2: \"A\"           0.997      1.000    3.000 1089.000 <.001 *** #> ─────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────────── #>  \"A\" \"B\" \"C\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────────── #>   A1  B1  C1  4.000 [ 1.750,  6.250] (0.707) #>   A2  B1  C1  8.000 [ 6.701,  9.299] (0.408) #>   A1  B2  C1  4.000 [ 1.402,  6.598] (0.816) #>   A2  B2  C1  8.000 [ 6.701,  9.299] (0.408) #>   A1  B1  C2  4.750 [ 1.470,  8.030] (1.031) #>   A2  B1  C2  6.000 [ 4.701,  7.299] (0.408) #>   A1  B2  C2  3.750 [ 2.227,  5.273] (0.479) #>   A2  B2  C2 12.000 [10.701, 13.299] (0.408) #> ──────────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1  C1    4.000 (0.408)  3  9.798  .002 **    3.361 [ 2.269, 4.452] #>   A2 - A1  B2  C1    4.000 (0.707)  3  5.657  .011 *     3.361 [ 1.470, 5.251] #>   A2 - A1  B1  C2    1.250 (1.109)  3  1.127  .342       1.050 [-1.914, 4.015] #>   A2 - A1  B2  C2    8.250 (0.250)  3 33.000 <.001 ***   6.931 [ 6.263, 7.600] #> ────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 1.190 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  ## Just to name a few... ## You may test other combinations...   #### Mixed Design ####  mixed.2_1b1w #>   A B1 B2 B3 #> 1 1  3  4  5 #> 2 1  6  6  7 #> 3 1  4  4  5 #> 4 1  3  2  2 #> 5 2  4  8 12 #> 6 2  5  9 13 #> 7 2  3  8 12 #> 8 2  3  7 11 MANOVA(mixed.2_1b1w, dvs=\"B1:B3\", dvs.pattern=\"B(.)\",        between=\"A\", within=\"B\", sph.correction=\"GG\") %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(\"B\", by=\"A\") #>  #> Note: #> dvs=\"B1:B3\" is matched to variables: #> B1, B2, B3 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      B1, B2, B3 #> Between-subjects factor(s): A #> Within-subjects factor(s):  B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>            MS   MSE   df1   df2       F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A      80.667 5.083 1.000 6.000  15.869  .007 **    .726 [.248, .871] .707 #> B      74.702 0.461 1.085 6.513 162.167 <.001 ***   .964 [.880, .983] .708 #> A * B  52.130 0.461 1.085 6.513 113.167 <.001 ***   .950 [.833, .976] .628 #> ────────────────────────────────────────────────────────────────────────── #> Sphericity correction method: GG (Greenhouse-Geisser) #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────── #>         Levene’s F df1 df2     p     #> ──────────────────────────────────── #> DV: B1       0.300   1   6  .604     #> DV: B2       0.600   1   6  .468     #> DV: B3       1.485   1   6  .269     #> ──────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────── #>        Mauchly's W     p     #> ──────────────────────────── #> B           0.1574  .010 **  #> A * B       0.1574  .010 **  #> ──────────────────────────── #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>       A  B1   1   6  0.086  .780       .014 [.000, .337] #>       A  B2   1   6 19.200  .005 **    .762 [.314, .888] #>       A  B3   1   6 42.763 <.001 ***   .877 [.593, .942] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> B1: \"A\"           0.014      1.000    6.000   0.086  .780     #> B2: \"A\"           0.762      1.000    6.000  19.200  .005 **  #> B3: \"A\"           0.877      1.000    6.000  42.763 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 2.523,  5.477] (0.604) #>   A2  B1  3.750 [ 2.273,  5.227] (0.604) #>   A1  B2  4.000 [ 2.421,  5.579] (0.645) #>   A2  B2  8.000 [ 6.421,  9.579] (0.645) #>   A1  B3  4.750 [ 2.832,  6.668] (0.784) #>   A2  B3 12.000 [10.082, 13.918] (0.784) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1   -0.250 (0.854)  6 -0.293  .780     -0.382 [-3.574,  2.810] #>   A2 - A1  B2    4.000 (0.913)  6  4.382  .005 **   6.110 [ 2.698,  9.522] #>   A2 - A1  B3    7.250 (1.109)  6  6.539 <.001 *** 11.075 [ 6.931, 15.218] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.655 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"B\") ------ #>  #> Joint Tests of \"B\": #> ───────────────────────────────────────────────────────── #>  Effect \"A\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────── #>       B  A1   2   6  17.471  .003 **    .853 [.492, .930] #>       B  A2   2   6 265.941 <.001 ***   .989 [.959, .995] #> ───────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"B\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> A1: \"B\"           0.853      2.000    5.000  14.559  .008 **  #> A2: \"B\"           0.989      2.000    5.000 221.618 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"B\": #> ──────────────────────────────────────── #>  \"B\" \"A\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   B1  A1  4.000 [ 2.523,  5.477] (0.604) #>   B2  A1  4.000 [ 2.421,  5.579] (0.645) #>   B3  A1  4.750 [ 2.832,  6.668] (0.784) #>   B1  A2  3.750 [ 2.273,  5.227] (0.604) #>   B2  A2  8.000 [ 6.421,  9.579] (0.645) #>   B3  A2 12.000 [10.082, 13.918] (0.784) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"B\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"A\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   B2 - B1  A1   -0.000 (0.339)  6 -0.000 1.000     -0.000 [-1.700,  1.700] #>   B3 - B1  A1    0.750 (0.479)  6  1.567  .505      1.146 [-1.258,  3.550] #>   B3 - B2  A1    0.750 (0.177)  6  4.243  .016 *    1.146 [ 0.258,  2.033] #>   B2 - B1  A2    4.250 (0.339)  6 12.555 <.001 ***  6.492 [ 4.792,  8.192] #>   B3 - B1  A2    8.250 (0.479)  6 17.234 <.001 *** 12.602 [10.198, 15.006] #>   B3 - B2  A2    4.000 (0.177)  6 22.627 <.001 ***  6.110 [ 5.222,  6.998] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.655 #> P-value adjustment: Bonferroni method for 3 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>   mixed.3_1b2w #>   A B1C1 B1C2 B2C1 B2C2 #> 1 1    3    5    4    4 #> 2 1    6    7    6    5 #> 3 1    4    5    4    3 #> 4 1    3    2    2    3 #> 5 2    8    5    9   12 #> 6 2    9    6    8   13 #> 7 2    8    7    8   12 #> 8 2    7    6    7   11 MANOVA(mixed.3_1b2w, dvs=\"B1C1:B2C2\", dvs.pattern=\"B(.)C(.)\",        between=\"A\", within=c(\"B\", \"C\")) %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(c(\"A\", \"B\"), by=\"C\") %>%   EMMEANS(\"A\", by=c(\"B\", \"C\")) #>  #> Note: #> dvs=\"B1C1:B2C2\" is matched to variables: #> B1C1, B1C2, B2C1, B2C2 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      B1C1, B1C2, B2C1, B2C2 #> Between-subjects factor(s): A #> Within-subjects factor(s):  B, C #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 4.708   1   6 32.522  .001 **    .844 [.503, .926] .803 #> B           12.500 0.417   1   6 30.000  .002 **    .833 [.475, .921] .250 #> A * B       24.500 0.417   1   6 58.800 <.001 ***   .907 [.684, .956] .395 #> C            3.125 0.375   1   6  8.333  .028 *     .581 [.064, .801] .077 #> A * C        1.125 0.375   1   6  3.000  .134       .333 [.000, .671] .029 #> B * C       12.500 0.750   1   6 16.667  .006 **    .735 [.264, .875] .250 #> A * B * C   24.500 0.750   1   6 32.667  .001 **    .845 [.505, .927] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ────────────────────────────────────── #>           Levene’s F df1 df2     p     #> ────────────────────────────────────── #> DV: B1C1       1.000   1   6  .356     #> DV: B1C2       1.485   1   6  .269     #> DV: B2C1       0.600   1   6  .468     #> DV: B2C2       0.500   1   6  .506     #> ────────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      B1   1   6  9.000  .024 *     .600 [.082, .810] #>   A      B2   1   6 72.758 <.001 ***   .924 [.736, .964] #>   C      B1   1   6  2.143  .194       .263 [.000, .629] #>   C      B2   1   6 35.526 <.001 ***   .856 [.533, .932] #>   A * C  B1   1   6 10.371  .018 *     .633 [.117, .827] #>   A * C  B2   1   6 45.632 <.001 ***   .884 [.613, .945] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> B1: \"A\"           0.600      1.000    6.000   9.000  .024 *   #> B2: \"A\"           0.924      1.000    6.000  72.758 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────────── #>  \"A\" \"B\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────────── #>   A1  B1  4.375 [2.861,  5.889] (0.619) #>   A2  B1  7.000 [5.486,  8.514] (0.619) #>   A1  B2  3.875 [2.633,  5.117] (0.508) #>   A2  B2 10.000 [8.758, 11.242] (0.508) #> ─────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ───────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df     t     p     Cohen’s d [95% CI of d] #> ───────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1    2.625 (0.875)  6 3.000  .024 *      2.797 [0.516, 5.078] #>   A2 - A1  B2    6.125 (0.718)  6 8.530 <.001 ***    6.526 [4.654, 8.398] #> ───────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.939 #> Results are averaged over the levels of: C #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\" & \"B\") ------ #>  #> Joint Tests of \"A\" & \"B\": #> ──────────────────────────────────────────────────────── #>  Effect \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      C1   1   6 24.000  .003 **    .800 [.395, .906] #>   A      C2   1   6 37.345 <.001 ***   .862 [.550, .935] #>   B      C1   1   6  0.000 1.000       .000 [.000, .000] #>   B      C2   1   6 30.000  .002 **    .833 [.475, .921] #>   A * B  C1   1   6  0.000 1.000       .000 [.000, .000] #>   A * B  C2   1   6 58.800 <.001 ***   .907 [.684, .956] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────── #>                Pillai’s trace Hypoth. df Error df Exact F     p     #> ─────────────────────────────────────────────────────────────────── #> C1: \"A\" & \"B\"           0.000      1.000    6.000   0.000 1.000     #> C2: \"A\" & \"B\"           0.907      1.000    6.000  58.800 <.001 *** #> ─────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\" & \"B\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 2.587,  5.413] (0.577) #>   A2  B1  8.000 [ 6.587,  9.413] (0.577) #>   A1  B2  4.000 [ 2.421,  5.579] (0.645) #>   A2  B2  8.000 [ 6.421,  9.579] (0.645) #>   A1  B1  4.750 [ 2.832,  6.668] (0.784) #>   A2  B1  6.000 [ 4.082,  7.918] (0.784) #>   A1  B2  3.750 [ 2.661,  4.839] (0.445) #>   A2  B2 12.000 [10.911, 13.089] (0.445) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────────────────── #>       Contrast \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ─────────────────────────────────────────────────────────────────────────────── #>  A2 B1 - A1 B1  C1    4.000 (0.816)  6  4.899  .016 *    4.262 [ 0.901,  7.622] #>  A1 B2 - A1 B1  C1    0.000 (0.408)  6  0.000 1.000      0.000 [-1.680,  1.680] #>  A1 B2 - A2 B1  C1   -4.000 (0.866)  6 -4.619  .022 *   -4.262 [-7.826, -0.697] #>  A2 B2 - A1 B1  C1    4.000 (0.866)  6  4.619  .022 *    4.262 [ 0.697,  7.826] #>  A2 B2 - A2 B1  C1    0.000 (0.408)  6  0.000 1.000      0.000 [-1.680,  1.680] #>  A2 B2 - A1 B2  C1    4.000 (0.913)  6  4.382  .028 *    4.262 [ 0.505,  8.019] #>  A2 B1 - A1 B1  C2    1.250 (1.109)  6  1.127 1.000      1.332 [-3.231,  5.895] #>  A1 B2 - A1 B1  C2   -1.000 (0.645)  6 -1.549 1.000     -1.065 [-3.722,  1.591] #>  A1 B2 - A2 B1  C2   -2.250 (0.901)  6 -2.496  .281     -2.397 [-6.107,  1.313] #>  A2 B2 - A1 B1  C2    7.250 (0.901)  6  8.043  .001 **   7.724 [ 4.014, 11.434] #>  A2 B2 - A2 B1  C2    6.000 (0.645)  6  9.295 <.001 ***  6.393 [ 3.736,  9.049] #>  A2 B2 - A1 B2  C2    8.250 (0.629)  6 13.113 <.001 ***  8.790 [ 6.200, 11.379] #> ─────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.939 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>  Effect \"B\" \"C\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────────── #>       A  B1  C1   1   6  24.000  .003 **    .800 [.395, .906] #>       A  B2  C1   1   6  19.200  .005 **    .762 [.314, .888] #>       A  B1  C2   1   6   1.271  .303       .175 [.000, .568] #>       A  B2  C2   1   6 171.947 <.001 ***   .966 [.879, .984] #> ───────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ────────────────────────────────────────────────────────────────── #>               Pillai’s trace Hypoth. df Error df Exact F     p     #> ────────────────────────────────────────────────────────────────── #> B1 & C1: \"A\"           0.800      1.000    6.000  24.000  .003 **  #> B2 & C1: \"A\"           0.762      1.000    6.000  19.200  .005 **  #> B1 & C2: \"A\"           0.175      1.000    6.000   1.271  .303     #> B2 & C2: \"A\"           0.966      1.000    6.000 171.947 <.001 *** #> ────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ──────────────────────────────────────────── #>  \"A\" \"B\" \"C\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────────── #>   A1  B1  C1  4.000 [ 2.587,  5.413] (0.577) #>   A2  B1  C1  8.000 [ 6.587,  9.413] (0.577) #>   A1  B2  C1  4.000 [ 2.421,  5.579] (0.645) #>   A2  B2  C1  8.000 [ 6.421,  9.579] (0.645) #>   A1  B1  C2  4.750 [ 2.832,  6.668] (0.784) #>   A2  B1  C2  6.000 [ 4.082,  7.918] (0.784) #>   A1  B2  C2  3.750 [ 2.661,  4.839] (0.445) #>   A2  B2  C2 12.000 [10.911, 13.089] (0.445) #> ──────────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1  C1    4.000 (0.816)  6  4.899  .003 **   4.262 [ 2.133,  6.390] #>   A2 - A1  B2  C1    4.000 (0.913)  6  4.382  .005 **   4.262 [ 1.882,  6.642] #>   A2 - A1  B1  C2    1.250 (1.109)  6  1.127  .303      1.332 [-1.559,  4.222] #>   A2 - A1  B2  C2    8.250 (0.629)  6 13.113 <.001 ***  8.790 [ 7.150, 10.430] #> ────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.939 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  ## Just to name a few... ## You may test other combinations...  mixed.3_2b1w #>    A C B1 B2 #> 1  1 1  3  4 #> 2  1 1  6  6 #> 3  1 1  4  4 #> 4  1 1  3  2 #> 5  1 2  5  4 #> 6  1 2  7  5 #> 7  1 2  5  3 #> 8  1 2  2  3 #> 9  2 1  8  9 #> 10 2 1  9  8 #> 11 2 1  8  8 #> 12 2 1  7  7 #> 13 2 2  5 12 #> 14 2 2  6 13 #> 15 2 2  7 12 #> 16 2 2  6 11 MANOVA(mixed.3_2b1w, dvs=\"B1:B2\", dvs.pattern=\"B(.)\",        between=c(\"A\", \"C\"), within=\"B\") %>%   EMMEANS(\"A\", by=\"B\") %>%   EMMEANS(\"A\", by=\"C\") %>%   EMMEANS(c(\"A\", \"B\"), by=\"C\") %>%   EMMEANS(\"B\", by=c(\"A\", \"C\")) #>  #> Note: #> dvs=\"B1:B2\" is matched to variables: #> B1, B2 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"C\" \"B\"   Mean    S.D. n #> ───────────────────────────── #>   A1  C1  B1  4.000 (1.414) 4 #>   A1  C1  B2  4.000 (1.633) 4 #>   A1  C2  B1  4.750 (2.062) 4 #>   A1  C2  B2  3.750 (0.957) 4 #>   A2  C1  B1  8.000 (0.816) 4 #>   A2  C1  B2  8.000 (0.816) 4 #>   A2  C2  B1  6.000 (0.816) 4 #>   A2  C2  B2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 16 #>  #> ANOVA Table: #> Dependent variable(s):      B1, B2 #> Between-subjects factor(s): A, C #> Within-subjects factor(s):  B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 2.542   1  12 60.246 <.001 ***   .834 [.639, .906] .803 #> C            3.125 2.542   1  12  1.230  .289       .093 [.000, .390] .077 #> A * C        1.125 2.542   1  12  0.443  .518       .036 [.000, .305] .029 #> B           12.500 0.583   1  12 21.429 <.001 ***   .641 [.308, .795] .250 #> A * B       24.500 0.583   1  12 42.000 <.001 ***   .778 [.532, .874] .395 #> C * B       12.500 0.583   1  12 21.429 <.001 ***   .641 [.308, .795] .250 #> A * C * B   24.500 0.583   1  12 42.000 <.001 ***   .778 [.532, .874] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────── #>         Levene’s F df1 df2     p     #> ──────────────────────────────────── #> DV: B1       0.946   3  12  .449     #> DV: B2       0.423   3  12  .740     #> ──────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ───────────────────────────────────────────────────────── #>  Effect \"B\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────── #>   A      B1   1  12  14.538  .002 **    .548 [.190, .739] #>   A      B2   1  12 122.085 <.001 ***   .911 [.799, .949] #>   C      B1   1  12   0.824  .382       .064 [.000, .353] #>   C      B2   1  12  11.441  .005 **    .488 [.129, .702] #>   A * C  B1   1  12   3.989  .069 .     .249 [.000, .537] #>   A * C  B2   1  12  14.695  .002 **    .550 [.193, .741] #> ───────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> B1: \"A\"           0.548      1.000   12.000  14.538  .002 **  #> B2: \"A\"           0.911      1.000   12.000 122.085 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ─────────────────────────────────────── #>  \"A\" \"B\"  Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────────── #>   A1  B1  4.375 [3.314,  5.436] (0.487) #>   A2  B1  7.000 [5.939,  8.061] (0.487) #>   A1  B2  3.875 [3.021,  4.729] (0.392) #>   A2  B2 10.000 [9.146, 10.854] (0.392) #> ─────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ────────────────────────────────────────────────────────────────────────── #>  Contrast \"B\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────── #>   A2 - A1  B1    2.625 (0.688) 12  3.813  .002 **     2.717 [1.164, 4.270] #>   A2 - A1  B2    6.125 (0.554) 12 11.049 <.001 ***    6.340 [5.090, 7.590] #> ────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.966 #> Results are averaged over the levels of: C #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\") ------ #>  #> Joint Tests of \"A\": #> ──────────────────────────────────────────────────────── #>  Effect \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      C1   1  12 25.180 <.001 ***   .677 [.361, .816] #>   A      C2   1  12 35.508 <.001 ***   .747 [.477, .856] #>   B      C1   1  12  0.000 1.000       .000 [.000, .000] #>   B      C2   1  12 42.857 <.001 ***   .781 [.538, .876] #>   A * B  C1   1  12  0.000 1.000       .000 [.000, .000] #>   A * B  C2   1  12 84.000 <.001 ***   .875 [.724, .929] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\": #> ───────────────────────────────────────────────────────────── #>          Pillai’s trace Hypoth. df Error df Exact F     p     #> ───────────────────────────────────────────────────────────── #> C1: \"A\"           0.677      1.000   12.000  25.180 <.001 *** #> C2: \"A\"           0.747      1.000   12.000  35.508 <.001 *** #> ───────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\": #> ────────────────────────────────────── #>  \"A\" \"C\" Mean [95% CI of Mean]    S.E. #> ────────────────────────────────────── #>   A1  C1 4.000 [2.772,  5.228] (0.564) #>   A2  C1 8.000 [6.772,  9.228] (0.564) #>   A1  C2 4.250 [3.022,  5.478] (0.564) #>   A2  C2 9.000 [7.772, 10.228] (0.564) #> ────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\": #> ───────────────────────────────────────────────────────────────────────── #>  Contrast \"C\" Estimate    S.E. df     t     p     Cohen’s d [95% CI of d] #> ───────────────────────────────────────────────────────────────────────── #>   A2 - A1  C1    4.000 (0.797) 12 5.018 <.001 ***    4.140 [2.343, 5.938] #>   A2 - A1  C2    4.750 (0.797) 12 5.959 <.001 ***    4.917 [3.119, 6.714] #> ───────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.966 #> Results are averaged over the levels of: B #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"A\" & \"B\") ------ #>  #> Joint Tests of \"A\" & \"B\": #> ──────────────────────────────────────────────────────── #>  Effect \"C\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────── #>   A      C1   1  12 25.180 <.001 ***   .677 [.361, .816] #>   A      C2   1  12 35.508 <.001 ***   .747 [.477, .856] #>   B      C1   1  12  0.000 1.000       .000 [.000, .000] #>   B      C2   1  12 42.857 <.001 ***   .781 [.538, .876] #>   A * B  C1   1  12  0.000 1.000       .000 [.000, .000] #>   A * B  C2   1  12 84.000 <.001 ***   .875 [.724, .929] #> ──────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────── #>                Pillai’s trace Hypoth. df Error df Exact F     p     #> ─────────────────────────────────────────────────────────────────── #> C1: \"A\" & \"B\"           0.000      1.000   12.000   0.000 1.000     #> C2: \"A\" & \"B\"           0.875      1.000   12.000  84.000 <.001 *** #> ─────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"A\" & \"B\": #> ──────────────────────────────────────── #>  \"A\" \"B\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   A1  B1  4.000 [ 2.500,  5.500] (0.688) #>   A2  B1  8.000 [ 6.500,  9.500] (0.688) #>   A1  B2  4.000 [ 2.792,  5.208] (0.554) #>   A2  B2  8.000 [ 6.792,  9.208] (0.554) #>   A1  B1  4.750 [ 3.250,  6.250] (0.688) #>   A2  B1  6.000 [ 4.500,  7.500] (0.688) #>   A1  B2  3.750 [ 2.542,  4.958] (0.554) #>   A2  B2 12.000 [10.792, 13.208] (0.554) #> ──────────────────────────────────────── #>  #> Pairwise Comparisons of \"A\" & \"B\": #> ─────────────────────────────────────────────────────────────────────────────── #>       Contrast \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ─────────────────────────────────────────────────────────────────────────────── #>  A2 B1 - A1 B1  C1    4.000 (0.974) 12  4.108  .009 **   4.140 [ 0.963,  7.318] #>  A1 B2 - A1 B1  C1   -0.000 (0.540) 12 -0.000 1.000     -0.000 [-1.762,  1.762] #>  A1 B2 - A2 B1  C1   -4.000 (0.884) 12 -4.525  .004 **  -4.140 [-7.025, -1.256] #>  A2 B2 - A1 B1  C1    4.000 (0.884) 12  4.525  .004 **   4.140 [ 1.256,  7.025] #>  A2 B2 - A2 B1  C1    0.000 (0.540) 12  0.000 1.000      0.000 [-1.762,  1.762] #>  A2 B2 - A1 B2  C1    4.000 (0.784) 12  5.102  .002 **   4.140 [ 1.582,  6.699] #>  A2 B1 - A1 B1  C2    1.250 (0.974) 12  1.284 1.000      1.294 [-1.883,  4.471] #>  A1 B2 - A1 B1  C2   -1.000 (0.540) 12 -1.852  .533     -1.035 [-2.798,  0.727] #>  A1 B2 - A2 B1  C2   -2.250 (0.884) 12 -2.546  .154     -2.329 [-5.213,  0.555] #>  A2 B2 - A1 B1  C2    7.250 (0.884) 12  8.202 <.001 ***  7.504 [ 4.620, 10.389] #>  A2 B2 - A2 B1  C2    6.000 (0.540) 12 11.110 <.001 ***  6.211 [ 4.448,  7.973] #>  A2 B2 - A1 B2  C2    8.250 (0.784) 12 10.524 <.001 ***  8.540 [ 5.981, 11.098] #> ─────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.966 #> P-value adjustment: Bonferroni method for 6 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"B\") ------ #>  #> Joint Tests of \"B\": #> ───────────────────────────────────────────────────────────── #>  Effect \"A\" \"C\" df1 df2       F     p     η²p [90% CI of η²p] #> ───────────────────────────────────────────────────────────── #>       B  A1  C1   1  12   0.000 1.000       .000 [.000, .000] #>       B  A2  C1   1  12   0.000 1.000       .000 [.000, .000] #>       B  A1  C2   1  12   3.429  .089 .     .222 [.000, .515] #>       B  A2  C2   1  12 123.429 <.001 ***   .911 [.801, .950] #> ───────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Multivariate Tests of \"B\": #> ────────────────────────────────────────────────────────────────── #>               Pillai’s trace Hypoth. df Error df Exact F     p     #> ────────────────────────────────────────────────────────────────── #> A1 & C1: \"B\"           0.000      1.000   12.000   0.000 1.000     #> A2 & C1: \"B\"           0.000      1.000   12.000   0.000 1.000     #> A1 & C2: \"B\"           0.222      1.000   12.000   3.429  .089 .   #> A2 & C2: \"B\"           0.911      1.000   12.000 123.429 <.001 *** #> ────────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"B\": #> ──────────────────────────────────────────── #>  \"B\" \"A\" \"C\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────────── #>   B1  A1  C1  4.000 [ 2.500,  5.500] (0.688) #>   B2  A1  C1  4.000 [ 2.792,  5.208] (0.554) #>   B1  A2  C1  8.000 [ 6.500,  9.500] (0.688) #>   B2  A2  C1  8.000 [ 6.792,  9.208] (0.554) #>   B1  A1  C2  4.750 [ 3.250,  6.250] (0.688) #>   B2  A1  C2  3.750 [ 2.542,  4.958] (0.554) #>   B1  A2  C2  6.000 [ 4.500,  7.500] (0.688) #>   B2  A2  C2 12.000 [10.792, 13.208] (0.554) #> ──────────────────────────────────────────── #>  #> Pairwise Comparisons of \"B\": #> ────────────────────────────────────────────────────────────────────────────── #>  Contrast \"A\" \"C\" Estimate    S.E. df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────────── #>   B2 - B1  A1  C1   -0.000 (0.540) 12 -0.000 1.000      -0.000 [-1.218, 1.218] #>   B2 - B1  A2  C1    0.000 (0.540) 12  0.000 1.000       0.000 [-1.218, 1.218] #>   B2 - B1  A1  C2   -1.000 (0.540) 12 -1.852  .089 .    -1.035 [-2.253, 0.183] #>   B2 - B1  A2  C2    6.000 (0.540) 12 11.110 <.001 ***   6.211 [ 4.993, 7.429] #> ────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 0.966 #> No need to adjust p values. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  ## Just to name a few... ## You may test other combinations...   #### Other Examples ####  air = airquality air$Day.1or2 = ifelse(air$Day %% 2 == 1, 1, 2) %>%   factor(levels=1:2, labels=c(\"odd\", \"even\")) MANOVA(air, dv=\"Temp\", between=c(\"Month\", \"Day.1or2\"),        covariate=c(\"Solar.R\", \"Wind\")) %>%   EMMEANS(\"Month\", contrast=\"seq\") %>%   EMMEANS(\"Month\", by=\"Day.1or2\", contrast=\"poly\") #> Warning: Numerical variables NOT centered on 0 (i.e., likely bogus results): NA, Wind #> Warning: Missing values for following ID(s): #> 5, 6, 11, 27, 96, 97, 98 #> Removing those cases from the analysis. #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────────────────── #>  \"Month\" \"Day.1or2\"   Mean    S.D.  n #> ───────────────────────────────────── #>   Month5       odd  66.077 (7.297) 13 #>   Month5       even 65.714 (6.390) 14 #>   Month6       odd  78.600 (6.905) 15 #>   Month6       even 79.600 (6.479) 15 #>   Month7       odd  83.375 (4.064) 16 #>   Month7       even 84.467 (4.642) 15 #>   Month8       odd  83.667 (6.102) 15 #>   Month8       even 83.846 (7.978) 13 #>   Month9       odd  76.733 (9.177) 15 #>   Month9       even 77.067 (7.769) 15 #> ───────────────────────────────────── #> Total sample size: N = 153 (7 missing observations deleted) #>  #> ANOVA Table: #> Dependent variable(s):      Temp #> Between-subjects factor(s): Month, Day.1or2 #> Within-subjects factor(s):  – #> Covariate(s):               Solar.R, Wind #> ─────────────────────────────────────────────────────────────────────────────────── #>                         MS    MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ─────────────────────────────────────────────────────────────────────────────────── #> Month             1059.183 35.312   4 134 29.995 <.001 ***   .472 [.366, .550] .472 #> Day.1or2             6.804 35.312   1 134  0.193  .661       .001 [.000, .030] .001 #> Solar.R            612.990 35.312   1 134 17.359 <.001 ***   .115 [.043, .204] .115 #> Wind               880.158 35.312   1 134 24.925 <.001 ***   .157 [.074, .251] .157 #> Month * Day.1or2     7.174 35.312   4 134  0.203  .936       .006 [.000, .004] .006 #> ─────────────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ────────────────────────────────────── #>           Levene’s F df1 df2     p     #> ────────────────────────────────────── #> DV: Temp       1.573   9 143  .129     #> ────────────────────────────────────── #>  #> ------ EMMEANS (effect = \"Month\") ------ #>  #> Joint Tests of \"Month\": #> ────────────────────────────────────────────────────────────── #>            Effect df1 df2      F     p     η²p [90% CI of η²p] #> ────────────────────────────────────────────────────────────── #>  Month              4 134 29.995 <.001 ***   .472 [.366, .550] #>  Day.1or2           1 134  0.193  .661       .001 [.000, .030] #>  Solar.R            1 134 17.359 <.001 ***   .115 [.043, .204] #>  Wind               1 134 24.925 <.001 ***   .157 [.074, .251] #>  Month * Day.1or2   4 134  0.203  .936       .006 [.000, .004] #> ────────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"Month\": #> ────────────────────────────────────────────────────────────── #>                Sum of Squares  df Mean Square      F     p     #> ────────────────────────────────────────────────────────────── #> Mean: \"Month\"        4236.730   4    1059.183 29.995 <.001 *** #> Residuals            4731.762 134      35.312                  #> ────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"Month\": #> ──────────────────────────────────────── #>  \"Month\"   Mean [95% CI of Mean]    S.E. #> ──────────────────────────────────────── #>   Month5 67.277 [64.959, 69.596] (1.172) #>   Month6 79.196 [77.048, 81.343] (1.086) #>   Month7 82.412 [80.252, 84.573] (1.092) #>   Month8 83.450 [81.201, 85.698] (1.137) #>   Month9 77.465 [75.309, 79.621] (1.090) #> ──────────────────────────────────────── #>  #> Consecutive (Sequential) Comparisons of \"Month\": #> ────────────────────────────────────────────────────────────────────────────── #>         Contrast Estimate    S.E.  df      t     p     Cohen’s d [95% CI of d] #> ────────────────────────────────────────────────────────────────────────────── #>  Month6 - Month5   11.918 (1.592) 134  7.486 <.001 ***  2.006 [ 1.327,  2.684] #>  Month7 - Month6    3.217 (1.541) 134  2.087  .155      0.541 [-0.115,  1.198] #>  Month8 - Month7    1.038 (1.573) 134  0.660 1.000      0.175 [-0.496,  0.845] #>  Month9 - Month8   -5.985 (1.571) 134 -3.808 <.001 *** -1.007 [-1.677, -0.338] #> ────────────────────────────────────────────────────────────────────────────── #> Pooled SD for computing Cohen’s d: 5.942 #> Results are averaged over the levels of: Day.1or2 #> P-value adjustment: Bonferroni method for 4 tests. #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>  #> ------ EMMEANS (effect = \"Month\") ------ #>  #> Joint Tests of \"Month\": #> ──────────────────────────────────────────────────────────────── #>   Effect \"Day.1or2\" df1 df2      F     p     η²p [90% CI of η²p] #> ──────────────────────────────────────────────────────────────── #>  Month         odd    4 134 13.278 <.001 ***   .284 [.169, .371] #>  Month         even   4 134 18.140 <.001 ***   .351 [.236, .437] #>  Solar.R       odd    1 134 17.359 <.001 ***   .115 [.043, .204] #>  Solar.R       even   1 134 17.359 <.001 ***   .115 [.043, .204] #>  Wind          odd    1 134 24.925 <.001 ***   .157 [.074, .251] #>  Wind          even   1 134 24.925 <.001 ***   .157 [.074, .251] #> ──────────────────────────────────────────────────────────────── #> Note. Simple effects of repeated measures with 3 or more levels #> are different from the results obtained with SPSS MANOVA syntax. #>  #> Univariate Tests of \"Month\": #> ────────────────────────────────────────────────────────────── #>                Sum of Squares  df Mean Square      F     p     #> ────────────────────────────────────────────────────────────── #>  odd: \"Month\"        1875.512   4     468.878 13.278 <.001 *** #> even: \"Month\"        2562.180   4     640.545 18.140 <.001 *** #> Residuals            4731.762 134      35.312                  #> ────────────────────────────────────────────────────────────── #> Note. Identical to the results obtained with SPSS GLM EMMEANS syntax. #>  #> Estimated Marginal Means of \"Month\": #> ─────────────────────────────────────────────────── #>  \"Month\" \"Day.1or2\"   Mean [95% CI of Mean]    S.E. #> ─────────────────────────────────────────────────── #>   Month5       odd  67.644 [64.342, 70.946] (1.669) #>   Month6       odd  79.321 [76.275, 82.367] (1.540) #>   Month7       odd  81.991 [79.019, 84.962] (1.503) #>   Month8       odd  82.494 [79.416, 85.573] (1.557) #>   Month9       odd  77.268 [74.229, 80.307] (1.536) #>   Month5       even 66.910 [63.732, 70.089] (1.607) #>   Month6       even 79.070 [76.032, 82.109] (1.536) #>   Month7       even 82.834 [79.746, 85.922] (1.561) #>   Month8       even 84.405 [81.135, 87.676] (1.654) #>   Month9       even 77.663 [74.613, 80.713] (1.542) #> ─────────────────────────────────────────────────── #>  #> Polynomial Contrasts of \"Month\": #> ──────────────────────────────────────────────────────────── #>   Contrast \"Day.1or2\" Estimate     S.E.  df      t     p     #> ──────────────────────────────────────────────────────────── #>  linear          odd    22.420 ( 5.061) 134  4.430 <.001 *** #>  quadratic       odd   -35.973 ( 5.946) 134 -6.050 <.001 *** #>  cubic           odd     3.277 ( 4.925) 134  0.665  .507     #>  quartic         odd   -10.405 (12.661) 134 -0.822  .413     #>  linear          even   26.840 ( 5.008) 134  5.359 <.001 *** #>  quadratic       even  -39.997 ( 5.922) 134 -6.754 <.001 *** #>  cubic           even    0.082 ( 5.034) 134  0.016  .987     #>  quartic         even  -12.327 (13.192) 134 -0.934  .352     #> ──────────────────────────────────────────────────────────── #>  #>  #> Disclaimer: #> By default, pooled SD is Root Mean Square Error (RMSE). #> There is much disagreement on how to compute Cohen’s d. #> You are completely responsible for setting `sd.pooled`. #> You might also use `effectsize::t_to_d()` to compute d. #>"},{"path":"https://psychbruce.github.io/bruceR/reference/Freq.html","id":null,"dir":"Reference","previous_headings":"","what":"Frequency statistics. — Freq","title":"Frequency statistics. — Freq","text":"Frequency statistics.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Freq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frequency statistics. — Freq","text":"","code":"Freq(x, varname, labels, sort = \"\", digits = 1, nsmall = digits, file = NULL)"},{"path":"https://psychbruce.github.io/bruceR/reference/Freq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frequency statistics. — Freq","text":"x vector values (data frame). varname [Optional] Variable name, x data frame. labels [Optional] vector re-defining labels values. sort \"\" (default, sorted order variable values/labels), \"-\" (decreasing N), \"+\" (increasing N). digits, nsmall Number decimal places output. Default 1. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Freq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frequency statistics. — Freq","text":"data frame frequency statistics.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Freq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frequency statistics. — Freq","text":"","code":"data = psych::bfi  ## Input `data$variable` Freq(data$education) #> Frequency Statistics: #> ─────────────── #>          N    % #> ─────────────── #> 1      224  8.0 #> 2      292 10.4 #> 3     1249 44.6 #> 4      394 14.1 #> 5      418 14.9 #> (NA)   223  8.0 #> ─────────────── #> Total N = 2,800 #> Valid N = 2,577 Freq(data$gender, labels=c(\"Male\", \"Female\")) #> Frequency Statistics: #> ───────────────── #>            N    % #> ───────────────── #> Male     919 32.8 #> Female  1881 67.2 #> ───────────────── #> Total N = 2,800 Freq(data$age) #> Frequency Statistics: #> ─────────── #>       N   % #> ─────────── #> 3     1 0.0 #> 9     1 0.0 #> 11    3 0.1 #> 12   28 1.0 #> 13    7 0.2 #> 14   21 0.8 #> 15   26 0.9 #> 16   61 2.2 #> 17  100 3.6 #> 18  124 4.4 #> 19  190 6.8 #> 20  212 7.6 #> 21  144 5.1 #> 22  122 4.4 #> 23  138 4.9 #> 24  105 3.8 #> 25  113 4.0 #> 26   99 3.5 #> 27   97 3.5 #> 28   86 3.1 #> 29   78 2.8 #> 30   65 2.3 #> 31   73 2.6 #> 32   66 2.4 #> 33   50 1.8 #> 34   52 1.9 #> 35   52 1.9 #> 36   50 1.8 #> 37   36 1.3 #> 38   52 1.9 #> 39   50 1.8 #> 40   56 2.0 #> 41   32 1.1 #> 42   30 1.1 #> 43   37 1.3 #> 44   25 0.9 #> 45   28 1.0 #> 46   25 0.9 #> 47   21 0.8 #> 48   30 1.1 #> 49   16 0.6 #> 50   34 1.2 #> 51   24 0.9 #> 52   26 0.9 #> 53   17 0.6 #> 54   14 0.5 #> 55   17 0.6 #> 56   17 0.6 #> 57    9 0.3 #> 58    7 0.2 #> 59    5 0.2 #> 60    6 0.2 #> 61    4 0.1 #> 62    4 0.1 #> 63    3 0.1 #> 64    1 0.0 #> 65    1 0.0 #> 66    1 0.0 #> 67    3 0.1 #> 68    1 0.0 #> 70    1 0.0 #> 72    1 0.0 #> 74    1 0.0 #> 86    1 0.0 #> ─────────── #> Total N = 2,800  ## Input one data frame and one variable name Freq(data, \"education\") #> Frequency Statistics: #> ─────────────── #>          N    % #> ─────────────── #> 1      224  8.0 #> 2      292 10.4 #> 3     1249 44.6 #> 4      394 14.1 #> 5      418 14.9 #> (NA)   223  8.0 #> ─────────────── #> Total N = 2,800 #> Valid N = 2,577 Freq(data, \"gender\", labels=c(\"Male\", \"Female\")) #> Frequency Statistics: #> ───────────────── #>            N    % #> ───────────────── #> Male     919 32.8 #> Female  1881 67.2 #> ───────────────── #> Total N = 2,800 Freq(data, \"age\") #> Frequency Statistics: #> ─────────── #>       N   % #> ─────────── #> 3     1 0.0 #> 9     1 0.0 #> 11    3 0.1 #> 12   28 1.0 #> 13    7 0.2 #> 14   21 0.8 #> 15   26 0.9 #> 16   61 2.2 #> 17  100 3.6 #> 18  124 4.4 #> 19  190 6.8 #> 20  212 7.6 #> 21  144 5.1 #> 22  122 4.4 #> 23  138 4.9 #> 24  105 3.8 #> 25  113 4.0 #> 26   99 3.5 #> 27   97 3.5 #> 28   86 3.1 #> 29   78 2.8 #> 30   65 2.3 #> 31   73 2.6 #> 32   66 2.4 #> 33   50 1.8 #> 34   52 1.9 #> 35   52 1.9 #> 36   50 1.8 #> 37   36 1.3 #> 38   52 1.9 #> 39   50 1.8 #> 40   56 2.0 #> 41   32 1.1 #> 42   30 1.1 #> 43   37 1.3 #> 44   25 0.9 #> 45   28 1.0 #> 46   25 0.9 #> 47   21 0.8 #> 48   30 1.1 #> 49   16 0.6 #> 50   34 1.2 #> 51   24 0.9 #> 52   26 0.9 #> 53   17 0.6 #> 54   14 0.5 #> 55   17 0.6 #> 56   17 0.6 #> 57    9 0.3 #> 58    7 0.2 #> 59    5 0.2 #> 60    6 0.2 #> 61    4 0.1 #> 62    4 0.1 #> 63    3 0.1 #> 64    1 0.0 #> 65    1 0.0 #> 66    1 0.0 #> 67    3 0.1 #> 68    1 0.0 #> 70    1 0.0 #> 72    1 0.0 #> 74    1 0.0 #> 86    1 0.0 #> ─────────── #> Total N = 2,800"},{"path":"https://psychbruce.github.io/bruceR/reference/GLM_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of GLM (lm and glm models). — GLM_summary","title":"Tidy report of GLM (lm and glm models). — GLM_summary","text":"NOTE: model_summary preferred.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/GLM_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of GLM (lm and glm models). — GLM_summary","text":"","code":"GLM_summary(   model,   robust = FALSE,   cluster = NULL,   digits = 3,   nsmall = digits,   ... )"},{"path":"https://psychbruce.github.io/bruceR/reference/GLM_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of GLM (lm and glm models). — GLM_summary","text":"model model fitted lm glm function. robust [lm glm] FALSE (default), TRUE (default \"HC1\"), \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". add table heteroskedasticity-robust standard errors (aka. Huber-White standard errors). details, see ?sandwich::vcovHC ?jtools::summ.lm. *** \"HC1\" default Stata, whereas \"HC3\" default suggested sandwich package. cluster [lm glm] Cluster-robust standard errors computed cluster set name input data's cluster variable vector clusters. digits, nsmall Number decimal places output. Default 3. ... arguments. may re-define formula, data, family.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/GLM_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of GLM (lm and glm models). — GLM_summary","text":"return value.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/GLM_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of GLM (lm and glm models). — GLM_summary","text":"","code":"## Example 1: OLS regression lm = lm(Temp ~ Month + Day + Wind + Solar.R, data=airquality) GLM_summary(lm) #>  #> General Linear Model (OLS Regression) #>  #> Model Fit: #> F(4, 141) = 22.22, p = 3e-14 *** #> R² = 0.38659 (Adjusted R² = 0.36919) #>  #> Unstandardized Coefficients: #> Outcome Variable: Temp #> N = 146 (7 missing cases deleted) #> ─────────────────────────────────────────────────────────────────── #>                   b    S.E.      t     p        [95% CI of b]   VIF #> ─────────────────────────────────────────────────────────────────── #> (Intercept)  68.770 (4.391) 15.662 <.001 *** [60.089, 77.450]       #> Month         2.225 (0.441)  5.047 <.001 *** [ 1.353,  3.096] 1.035 #> Day          -0.084 (0.070) -1.194  .234     [-0.222,  0.055] 1.024 #> Wind         -1.003 (0.176) -5.695 <.001 *** [-1.352, -0.655] 1.032 #> Solar.R       0.027 (0.007)  3.991 <.001 *** [ 0.014,  0.041] 1.034 #> ─────────────────────────────────────────────────────────────────── #>  #> Standardized Coefficients (β): #> Outcome Variable: Temp #> N = 146 (7 missing cases deleted) #> ──────────────────────────────────────────────────────────────────────────── #>               β    S.E.      t     p        [95% CI of β] r(partial) r(part) #> ──────────────────────────────────────────────────────────────────────────── #> Month     0.339 (0.067)  5.047 <.001 *** [ 0.206,  0.471]      0.391   0.333 #> Day      -0.080 (0.067) -1.194  .234     [-0.212,  0.052]     -0.100  -0.079 #> Wind     -0.382 (0.067) -5.695 <.001 *** [-0.514, -0.249]     -0.432  -0.376 #> Solar.R   0.268 (0.067)  3.991 <.001 *** [ 0.135,  0.400]      0.319   0.263 #> ──────────────────────────────────────────────────────────────────────────── #>  GLM_summary(lm, robust=\"HC1\") #>  #> General Linear Model (OLS Regression) #>  #> Model Fit: #> F(4, 141) = 22.22, p = 3e-14 *** #> R² = 0.38659 (Adjusted R² = 0.36919) #>  #> Unstandardized Coefficients: #> Outcome Variable: Temp #> N = 146 (7 missing cases deleted) #> ─────────────────────────────────────────────────────────────────── #>                   b    S.E.      t     p        [95% CI of b]   VIF #> ─────────────────────────────────────────────────────────────────── #> (Intercept)  68.770 (4.391) 15.662 <.001 *** [60.089, 77.450]       #> Month         2.225 (0.441)  5.047 <.001 *** [ 1.353,  3.096] 1.035 #> Day          -0.084 (0.070) -1.194  .234     [-0.222,  0.055] 1.024 #> Wind         -1.003 (0.176) -5.695 <.001 *** [-1.352, -0.655] 1.032 #> Solar.R       0.027 (0.007)  3.991 <.001 *** [ 0.014,  0.041] 1.034 #> ─────────────────────────────────────────────────────────────────── #>  #> Heteroskedasticity-Robust Standard Errors: #> ───────────────────────────────────────────────────────────── #>                   b    S.E.      t     p        [95% CI of b] #> ───────────────────────────────────────────────────────────── #> (Intercept)  68.770 (4.550) 15.113 <.001 *** [59.774, 77.766] #> Month         2.225 (0.488)  4.557 <.001 *** [ 1.260,  3.190] #> Day          -0.084 (0.068) -1.231  .220     [-0.218,  0.051] #> Wind         -1.003 (0.152) -6.604 <.001 *** [-1.304, -0.703] #> Solar.R       0.027 (0.007)  4.089 <.001 *** [ 0.014,  0.041] #> ───────────────────────────────────────────────────────────── #> Robust S.E.: type = HC1. #>  #> Standardized Coefficients (β): #> Outcome Variable: Temp #> N = 146 (7 missing cases deleted) #> ──────────────────────────────────────────────────────────────────────────── #>               β    S.E.      t     p        [95% CI of β] r(partial) r(part) #> ──────────────────────────────────────────────────────────────────────────── #> Month     0.339 (0.067)  5.047 <.001 *** [ 0.206,  0.471]      0.391   0.333 #> Day      -0.080 (0.067) -1.194  .234     [-0.212,  0.052]     -0.100  -0.079 #> Wind     -0.382 (0.067) -5.695 <.001 *** [-0.514, -0.249]     -0.432  -0.376 #> Solar.R   0.268 (0.067)  3.991 <.001 *** [ 0.135,  0.400]      0.319   0.263 #> ──────────────────────────────────────────────────────────────────────────── #>  # Stata's default is \"HC1\" # R package <sandwich>'s default is \"HC3\"  ## Example 2: Logistic regression glm = glm(case ~ age + parity + education + spontaneous + induced,           data=infert, family=binomial) GLM_summary(glm) #>  #> Generalized Linear Model (GLM) #>  #> Model Fit: #> AIC = 271.798 #> BIC = 296.392 #> χ²(6) = 58.37, p = 1e-10 *** #> ─────── Pseudo-R² ─────── #> McFadden’s R²   = 0.18463 (= 1 - logLik(model)/logLik(null.model)) #> Nagelkerke’s R² = 0.29107 (= Cragg-Uhler’s R², adjusts Cox & Snell’s) #>  #> Unstandardized Coefficients: #> Outcome Variable: case (family: binomial; link function: logit) #> N = 248 #> ────────────────────────────────────────────────────────────────────────────── #>                        b    S.E.      z     p        [95% CI of b]    OR   VIF #> ────────────────────────────────────────────────────────────────────────────── #> (Intercept)       -1.149 (1.412) -0.814  .416     [-3.917,  1.619] 0.317       #> age                0.040 (0.031)  1.269  .205     [-0.022,  0.101] 1.040 1.174 #> parity            -0.828 (0.196) -4.215 <.001 *** [-1.213, -0.443] 0.437 2.480 #> education6-11yrs  -1.044 (0.793) -1.318  .188     [-2.598,  0.509] 0.352 1.361 #> education12+ yrs  -1.403 (0.834) -1.682  .093 .   [-3.038,  0.232] 0.246 1.361 #> spontaneous        2.046 (0.310)  6.596 <.001 *** [ 1.438,  2.654] 7.736 2.191 #> induced            1.289 (0.301)  4.275 <.001 *** [ 0.698,  1.880] 3.628 2.222 #> ────────────────────────────────────────────────────────────────────────────── #> OR = odds ratio. #>  GLM_summary(glm, robust=\"HC1\", cluster=\"stratum\") #>  #> Generalized Linear Model (GLM) #>  #> Model Fit: #> AIC = 271.798 #> BIC = 296.392 #> χ²(6) = 58.37, p = 1e-10 *** #> ─────── Pseudo-R² ─────── #> McFadden’s R²   = 0.18463 (= 1 - logLik(model)/logLik(null.model)) #> Nagelkerke’s R² = 0.29107 (= Cragg-Uhler’s R², adjusts Cox & Snell’s) #>  #> Unstandardized Coefficients: #> Outcome Variable: case (family: binomial; link function: logit) #> N = 248 #> ────────────────────────────────────────────────────────────────────────────── #>                        b    S.E.      z     p        [95% CI of b]    OR   VIF #> ────────────────────────────────────────────────────────────────────────────── #> (Intercept)       -1.149 (1.412) -0.814  .416     [-3.917,  1.619] 0.317       #> age                0.040 (0.031)  1.269  .205     [-0.022,  0.101] 1.040 1.174 #> parity            -0.828 (0.196) -4.215 <.001 *** [-1.213, -0.443] 0.437 2.480 #> education6-11yrs  -1.044 (0.793) -1.318  .188     [-2.598,  0.509] 0.352 1.361 #> education12+ yrs  -1.403 (0.834) -1.682  .093 .   [-3.038,  0.232] 0.246 1.361 #> spontaneous        2.046 (0.310)  6.596 <.001 *** [ 1.438,  2.654] 7.736 2.191 #> induced            1.289 (0.301)  4.275 <.001 *** [ 0.698,  1.880] 3.628 2.222 #> ────────────────────────────────────────────────────────────────────────────── #> OR = odds ratio. #>  #> Cluster-Robust Standard Errors: #> ────────────────────────────────────────────────────────────────── #>                        b    S.E.      z     p        [95% CI of b] #> ────────────────────────────────────────────────────────────────── #> (Intercept)       -1.149 (1.412) -0.814  .416     [-3.917,  1.619] #> age                0.040 (0.031)  1.269  .205     [-0.022,  0.101] #> parity            -0.828 (0.196) -4.215 <.001 *** [-1.213, -0.443] #> education6-11yrs  -1.044 (0.793) -1.318  .188     [-2.598,  0.509] #> education12+ yrs  -1.403 (0.834) -1.682  .093 .   [-3.038,  0.232] #> spontaneous        2.046 (0.310)  6.596 <.001 *** [ 1.438,  2.654] #> induced            1.289 (0.301)  4.275 <.001 *** [ 0.698,  1.880] #> ────────────────────────────────────────────────────────────────── #> Robust S.E.: type = HC1; clustering variable = stratum. #>"},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"Compute ICC(1) (non-independence data), ICC(2) (reliability group means), \\(r_{WG}\\)/\\(r_{WG(J)}\\) (within-group agreement single-item/multi-item measures) multilevel analysis (HLM).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"","code":"HLM_ICC_rWG(   data,   group,   icc.var,   rwg.vars = icc.var,   rwg.levels = 0,   digits = 3,   nsmall = digits )"},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"data Data frame. group Grouping variable. icc.var Key variable analysis (usually dependent variable). rwg.vars Default icc.var. can : single variable (single-item measure), computing rWG. Multiple variables (multi-item measure), computing rWG(J), J = number items. rwg.levels \\(r_{WG}\\)/\\(r_{WG(J)}\\) compares actual group variance expected random variance (.e., variance uniform distribution, \\(\\sigma_{EU}^2\\)), required specify type uniform distribution . continuous uniform distribution, \\(\\sigma_{EU}^2 = (max - min)^2 / 12\\).   rwg.levels useful set 0 (default). discrete uniform distribution, \\(\\sigma_{EU}^2 = (^2 - 1) / 12\\),   number response options (levels).   rwg.levels provided (= formula).   example, measure 5-point Likert scale, set rwg.levels=5. digits, nsmall Number decimal places output. Default 3.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"Invisibly return list results.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"ICC(1) (intra-class correlation, non-independence data) ICC(1) = var.u0 / (var.u0 + var.e) = \\(\\sigma_{u0}^2 / (\\sigma_{u0}^2 + \\sigma_{e}^2)\\) ICC(1) ICC often compute report multilevel analysis     (usually Null Model, random intercept group included).     can interpreted either \"proportion variance explained groups\" (.e., heterogeneity groups)     \"expectation correlation coefficient two observations within group\" (.e., homogeneity within groups). ICC(2) (reliability group means) ICC(2) = mean(var.u0 / (var.u0 + var.e / n.k)) = \\(\\Sigma[\\sigma_{u0}^2 / (\\sigma_{u0}^2 + \\sigma_{e}^2 / n_k)] / K\\) ICC(2) measure \"representativeness group-level aggregated means within-group individual values\"     \"degree individual score can considered reliable assessment group-level construct\". \\(r_{WG}\\)/\\(r_{WG(J)}\\) (within-group agreement single-item/multi-item measures) \\(r_{WG} = 1 - \\sigma^2 / \\sigma_{EU}^2\\) \\(r_{WG(J)} = 1 - (\\sigma_{MJ}^2 / \\sigma_{EU}^2) / [J * (1 - \\sigma_{MJ}^2 / \\sigma_{EU}^2) + \\sigma_{MJ}^2 / \\sigma_{EU}^2]\\) \\(r_{WG}\\)/\\(r_{WG(J)}\\) measure within-group agreement consensus. group \\(r_{WG}\\)/\\(r_{WG(J)}\\). * Note formulas  \\(\\sigma_{u0}^2\\): -group variance (.e., tau00) \\(\\sigma_{e}^2\\): within-group variance (.e., residual variance) \\(n_k\\): group size k-th group \\(K\\): number groups \\(\\sigma^2\\): actual group variance k-th group \\(\\sigma_{MJ}^2\\): mean value actual group variance k-th group across J items \\(\\sigma_{EU}^2\\): expected random variance (.e., variance uniform distribution) \\(J\\): number items","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"Bliese, P. D. (2000). Within-group agreement, non-independence, reliability: Implications data aggregation Analysis. K. J. Klein & S. W. Kozlowski (Eds.), Multilevel theory, research, methods organizations (pp. 349-381). San Francisco, CA: Jossey-Bass, Inc. James, L.R., Demaree, R.G., & Wolf, G. (1984). Estimating within-group interrater reliability without response bias. Journal Applied Psychology, 69, 85-98.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_ICC_rWG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of HLM indices: ICC(1), ICC(2), and rWG/rWG(J). — HLM_ICC_rWG","text":"","code":"data = lme4::sleepstudy  # continuous variable HLM_ICC_rWG(data, group=\"Subject\", icc.var=\"Reaction\") #>  #> ------ Sample Size Information ------ #>  #> Level 1: N = 180 observations (\"Reaction\") #> Level 2: K = 18 groups (\"Subject\") #>  #>        n (group sizes) #> Min.                10 #> Median              10 #> Mean                10 #> Max.                10 #>  #> ------ ICC(1), ICC(2), and rWG ------ #>  #> ICC variable: \"Reaction\" #>  #> ICC(1) = 0.395 (non-independence of data) #> ICC(2) = 0.867 (reliability of group means) #>  #> rWG variable: \"Reaction\" #>  #> rWG (within-group agreement for single-item measures) #> ───────────────────────────────────────────── #>       Min. 1st Qu. Median  Mean 3rd Qu.  Max. #> ───────────────────────────────────────────── #> rWG  0.000   0.482  0.778 0.684   0.876 0.981 #> ───────────────────────────────────────────── #>   data = lmerTest::carrots  # 7-point scale HLM_ICC_rWG(data, group=\"Consumer\", icc.var=\"Preference\",             rwg.vars=\"Preference\",             rwg.levels=7) #>  #> ------ Sample Size Information ------ #>  #> Level 1: N = 1233 observations (\"Preference\") #> Level 2: K = 103 groups (\"Consumer\") #>  #>        n (group sizes) #> Min.          11.00000 #> Median        12.00000 #> Mean          11.97087 #> Max.          12.00000 #>  #> ------ ICC(1), ICC(2), and rWG ------ #>  #> ICC variable: \"Preference\" #>  #> ICC(1) = 0.143 (non-independence of data) #> ICC(2) = 0.666 (reliability of group means) #>  #> rWG variable: \"Preference\" #>  #> rWG (within-group agreement for single-item measures) #> ───────────────────────────────────────────── #>       Min. 1st Qu. Median  Mean 3rd Qu.  Max. #> ───────────────────────────────────────────── #> rWG  0.000   0.631  0.752 0.711   0.815 1.000 #> ───────────────────────────────────────────── #>  HLM_ICC_rWG(data, group=\"Consumer\", icc.var=\"Preference\",             rwg.vars=c(\"Sweetness\", \"Bitter\", \"Crisp\"),             rwg.levels=7) #>  #> ------ Sample Size Information ------ #>  #> Level 1: N = 1233 observations (\"Preference\") #> Level 2: K = 103 groups (\"Consumer\") #>  #>        n (group sizes) #> Min.          11.00000 #> Median        12.00000 #> Mean          11.97087 #> Max.          12.00000 #>  #> ------ ICC(1), ICC(2), and rWG(J) ------ #>  #> ICC variable: \"Preference\" #>  #> ICC(1) = 0.143 (non-independence of data) #> ICC(2) = 0.666 (reliability of group means) #>  #> rWG(J) variables: \"Sweetness\", \"Bitter\", \"Crisp\" #>  #> rWG(J) (within-group agreement for multi-item measures) #> ──────────────────────────────────────────────── #>          Min. 1st Qu. Median  Mean 3rd Qu.  Max. #> ──────────────────────────────────────────────── #> rWG(J)  0.170   0.807  0.871 0.841   0.908 0.983 #> ──────────────────────────────────────────────── #>"},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of HLM (lmer and glmer models). — HLM_summary","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"NOTE: model_summary preferred.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"","code":"HLM_summary(model = NULL, test.rand = FALSE, digits = 3, nsmall = digits, ...)"},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"model model fitted lmer glmer function using lmerTest package. test.rand [lmer glmer] TRUE FALSE (default). Test random effects (.e., variance components) using likelihood-ratio test (LRT), asymptotically chi-square distributed. large datasets, much time-consuming. digits, nsmall Number decimal places output. Default 3. ... arguments. may re-define formula, data, family.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"return value.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"Hox, J. J. (2010). Multilevel analysis: Techniques applications (2nd ed.). New York, NY: Routledge. Nakagawa, S., & Schielzeth, H. (2013). general simple method obtaining R^2 generalized linear mixed-effects models. Methods Ecology Evolution, 4, 133-142. Xu, R. (2003). Measuring explained variation linear mixed effects models. Statistics Medicine, 22, 3527-3541.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/HLM_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of HLM (lmer and glmer models). — HLM_summary","text":"","code":"library(lmerTest)  ## Example 1: data from lme4::sleepstudy # (1) 'Subject' is a grouping/clustering variable # (2) 'Days' is a level-1 predictor nested within 'Subject' # (3) No level-2 predictors m1 = lmer(Reaction ~ (1 | Subject), data=sleepstudy) m2 = lmer(Reaction ~ Days + (1 | Subject), data=sleepstudy) m3 = lmer(Reaction ~ Days + (Days | Subject), data=sleepstudy) HLM_summary(m1) #>  #> Hierarchical Linear Model (HLM) #> (also known as) Linear Mixed Model (LMM) #> (also known as) Multilevel Linear Model (MLM) #>  #> Model Information: #> Formula: Reaction ~ (1 | Subject) #> Level-1 Observations: N = 180 #> Level-2 Groups/Clusters: Subject, 18 #>  #> Model Fit: #> AIC = 1910.327 #> BIC = 1919.905 #> R_(m)² = 0.00000  (Marginal R²: fixed effects) #> R_(c)² = 0.39489  (Conditional R²: fixed + random effects) #> Omega² = 0.43347  (= 1 - proportion of unexplained variance) #>  #> Fixed Effects: #> Unstandardized Coefficients (b or γ): #> Outcome Variable: Reaction #> ──────────────────────────────────────────────────────────────────── #>                  b/γ    S.E.     t   df     p        [95% CI of b/γ] #> ──────────────────────────────────────────────────────────────────── #> (Intercept)  298.508 (9.050) 32.98 17.0 <.001 *** [279.414, 317.602] #> ──────────────────────────────────────────────────────────────────── #> 'df' is estimated by Satterthwaite approximation. #>  #> Random Effects: #> ──────────────────────────────────────────── #>  Cluster  K   Parameter     Variance     ICC #> ──────────────────────────────────────────── #>  Subject   18 (Intercept) 1278.33776 0.39489 #>  Residual                 1958.86518         #> ──────────────────────────────────────────── #>  HLM_summary(m2) #>  #> Hierarchical Linear Model (HLM) #> (also known as) Linear Mixed Model (LMM) #> (also known as) Multilevel Linear Model (MLM) #>  #> Model Information: #> Formula: Reaction ~ Days + (1 | Subject) #> Level-1 Observations: N = 180 #> Level-2 Groups/Clusters: Subject, 18 #>  #> Model Fit: #> AIC = 1794.465 #> BIC = 1807.237 #> R_(m)² = 0.27989  (Marginal R²: fixed effects) #> R_(c)² = 0.70426  (Conditional R²: fixed + random effects) #> Omega² = 0.72586  (= 1 - proportion of unexplained variance) #>  #> ANOVA Table: #> ─────────────────────────────────────────────────────── #>          Sum Sq   Mean Sq NumDF  DenDF      F     p     #> ─────────────────────────────────────────────────────── #> Days  162702.65 162702.65  1.00 161.00 169.40 <.001 *** #> ─────────────────────────────────────────────────────── #>  #> Fixed Effects: #> Unstandardized Coefficients (b or γ): #> Outcome Variable: Reaction #> ───────────────────────────────────────────────────────────────────── #>                  b/γ    S.E.     t    df     p        [95% CI of b/γ] #> ───────────────────────────────────────────────────────────────────── #> (Intercept)  251.405 (9.747) 25.79  22.8 <.001 *** [231.233, 271.577] #> Days          10.467 (0.804) 13.02 161.0 <.001 *** [  8.879,  12.055] #> ───────────────────────────────────────────────────────────────────── #> 'df' is estimated by Satterthwaite approximation. #>  #> Standardized Coefficients (β): #> Outcome Variable: Reaction #> ──────────────────────────────────────────────────────── #>           β    S.E.     t    df     p      [95% CI of β] #> ──────────────────────────────────────────────────────── #> Days  0.535 (0.041) 13.02 161.0 <.001 *** [0.454, 0.616] #> ──────────────────────────────────────────────────────── #>  #> Random Effects: #> ──────────────────────────────────────────── #>  Cluster  K   Parameter     Variance     ICC #> ──────────────────────────────────────────── #>  Subject   18 (Intercept) 1378.17851 0.58931 #>  Residual                  960.45658         #> ──────────────────────────────────────────── #>  HLM_summary(m3) #>  #> Hierarchical Linear Model (HLM) #> (also known as) Linear Mixed Model (LMM) #> (also known as) Multilevel Linear Model (MLM) #>  #> Model Information: #> Formula: Reaction ~ Days + (Days | Subject) #> Level-1 Observations: N = 180 #> Level-2 Groups/Clusters: Subject, 18 #>  #> Model Fit: #> AIC = 1755.628 #> BIC = 1774.786 #> R_(m)² = 0.27865  (Marginal R²: fixed effects) #> R_(c)² = 0.79922  (Conditional R²: fixed + random effects) #> Omega² = 0.82590  (= 1 - proportion of unexplained variance) #>  #> ANOVA Table: #> ─────────────────────────────────────────────────── #>         Sum Sq  Mean Sq NumDF DenDF     F     p     #> ─────────────────────────────────────────────────── #> Days  30030.94 30030.94  1.00 17.00 45.85 <.001 *** #> ─────────────────────────────────────────────────── #>  #> Fixed Effects: #> Unstandardized Coefficients (b or γ): #> Outcome Variable: Reaction #> ──────────────────────────────────────────────────────────────────── #>                  b/γ    S.E.     t   df     p        [95% CI of b/γ] #> ──────────────────────────────────────────────────────────────────── #> (Intercept)  251.405 (6.825) 36.84 17.0 <.001 *** [237.006, 265.804] #> Days          10.467 (1.546)  6.77 17.0 <.001 *** [  7.206,  13.729] #> ──────────────────────────────────────────────────────────────────── #> 'df' is estimated by Satterthwaite approximation. #>  #> Standardized Coefficients (β): #> Outcome Variable: Reaction #> ────────────────────────────────────────────────────── #>           β    S.E.    t   df     p      [95% CI of β] #> ────────────────────────────────────────────────────── #> Days  0.535 (0.079) 6.77 17.0 <.001 *** [0.368, 0.702] #> ────────────────────────────────────────────────────── #>  #> Random Effects: #> ─────────────────────────────────────────── #>  Cluster  K   Parameter    Variance     ICC #> ─────────────────────────────────────────── #>  Subject   18 (Intercept) 612.10016 0.48309 #>               Days         35.07171         #>  Residual                 654.94001         #> ─────────────────────────────────────────── #>   ## Example 2: data from lmerTest::carrots # (1) 'Consumer' is a grouping/clustering variable # (2) 'Sweetness' is a level-1 predictor # (3) 'Age' and 'Frequency' are level-2 predictors hlm.1 = lmer(Preference ~ Sweetness + Age + Frequency +                (1 | Consumer), data=carrots) hlm.2 = lmer(Preference ~ Sweetness + Age + Frequency +                (Sweetness | Consumer) + (1 | Product), data=carrots) HLM_summary(hlm.1) #>  #> Hierarchical Linear Model (HLM) #> (also known as) Linear Mixed Model (LMM) #> (also known as) Multilevel Linear Model (MLM) #>  #> Model Information: #> Formula: Preference ~ Sweetness + Age + Frequency + (1 | Consumer) #> Level-1 Observations: N = 1230 #> Level-2 Groups/Clusters: Consumer, 103 #>  #> Model Fit: #> AIC = 3328.442 #> BIC = 3384.705 #> R_(m)² = 0.32908  (Marginal R²: fixed effects) #> R_(c)² = 0.52156  (Conditional R²: fixed + random effects) #> Omega² = 0.50163  (= 1 - proportion of unexplained variance) #>  #> ANOVA Table: #> ──────────────────────────────────────────────────────── #>            Sum Sq Mean Sq NumDF   DenDF      F     p     #> ──────────────────────────────────────────────────────── #> Sweetness  487.13  487.13  1.00 1208.87 660.42 <.001 *** #> Age          4.11    1.37  3.00   93.39   1.86  .142     #> Frequency    1.80    0.45  4.00   93.75   0.61  .655     #> ──────────────────────────────────────────────────────── #>  #> Fixed Effects: #> Unstandardized Coefficients (b or γ): #> Outcome Variable: Preference #> ────────────────────────────────────────────────────────────────── #>                 b/γ    S.E.     t     df     p     [95% CI of b/γ] #> ────────────────────────────────────────────────────────────────── #> (Intercept)   2.626 (0.220) 11.93  119.9 <.001 *** [ 2.190, 3.061] #> Sweetness     0.508 (0.020) 25.70 1208.9 <.001 *** [ 0.469, 0.547] #> Age2          0.395 (0.249)  1.58   93.6  .117     [-0.100, 0.890] #> Age3          0.465 (0.214)  2.17   93.7  .033 *   [ 0.039, 0.891] #> Age4          0.531 (0.234)  2.27   93.6  .026 *   [ 0.066, 0.996] #> Frequency2    0.149 (0.162)  0.92   93.4  .360     [-0.172, 0.469] #> Frequency3    0.101 (0.217)  0.47   93.6  .642     [-0.330, 0.532] #> Frequency4   -0.501 (0.444) -1.13   93.2  .262     [-1.382, 0.380] #> Frequency5   -0.027 (0.376) -0.07   94.7  .943     [-0.774, 0.720] #> ────────────────────────────────────────────────────────────────── #> 'df' is estimated by Satterthwaite approximation. #>  #> Standardized Coefficients (β): #> Outcome Variable: Preference #> ───────────────────────────────────────────────────────────────── #>                  β    S.E.     t     df     p       [95% CI of β] #> ───────────────────────────────────────────────────────────────── #> Sweetness    0.609 (0.024) 25.70 1208.9 <.001 *** [ 0.562, 0.655] #> Age2         0.122 (0.077)  1.58   93.6  .117     [-0.031, 0.275] #> Age3         0.198 (0.091)  2.17   93.7  .033 *   [ 0.017, 0.380] #> Age4         0.197 (0.087)  2.27   93.6  .026 *   [ 0.025, 0.369] #> Frequency2   0.047 (0.051)  0.92   93.4  .360     [-0.055, 0.149] #> Frequency3   0.024 (0.052)  0.47   93.6  .642     [-0.080, 0.129] #> Frequency4  -0.059 (0.052) -1.13   93.2  .262     [-0.163, 0.045] #> Frequency5  -0.004 (0.053) -0.07   94.7  .943     [-0.108, 0.101] #> ───────────────────────────────────────────────────────────────── #>  #> Random Effects: #> ────────────────────────────────────────── #>  Cluster  K   Parameter   Variance     ICC #> ────────────────────────────────────────── #>  Consumer 103 (Intercept)  0.29673 0.28688 #>  Residual                  0.73761         #> ────────────────────────────────────────── #>  HLM_summary(hlm.2) #>  #> Hierarchical Linear Model (HLM) #> (also known as) Linear Mixed Model (LMM) #> (also known as) Multilevel Linear Model (MLM) #>  #> Model Information: #> Formula: Preference ~ Sweetness + Age + Frequency + (Sweetness | Consumer) + (1 | Product) #> Level-1 Observations: N = 1230 #> Level-2 Groups/Clusters: Consumer, 103; Product, 12 #>  #> Model Fit: #> AIC = 3281.886 #> BIC = 3353.493 #> R_(m)² = 0.31128  (Marginal R²: fixed effects) #> R_(c)² = 0.55254  (Conditional R²: fixed + random effects) #> Omega² = 0.57170  (= 1 - proportion of unexplained variance) #>  #> ANOVA Table: #> ─────────────────────────────────────────────────────── #>            Sum Sq Mean Sq NumDF  DenDF      F     p     #> ─────────────────────────────────────────────────────── #> Sweetness  184.22  184.22  1.00 103.72 277.74 <.001 *** #> Age          2.51    0.84  3.00  83.12   1.26  .293     #> Frequency    2.43    0.61  4.00  80.03   0.92  .458     #> ─────────────────────────────────────────────────────── #>  #> Fixed Effects: #> Unstandardized Coefficients (b or γ): #> Outcome Variable: Preference #> ───────────────────────────────────────────────────────────────── #>                 b/γ    S.E.     t    df     p     [95% CI of b/γ] #> ───────────────────────────────────────────────────────────────── #> (Intercept)   2.817 (0.221) 12.76 149.7 <.001 *** [ 2.381, 3.253] #> Sweetness     0.485 (0.029) 16.67 103.7 <.001 *** [ 0.428, 0.543] #> Age2          0.212 (0.222)  0.96  78.6  .341     [-0.229, 0.654] #> Age3          0.297 (0.189)  1.57  76.3  .120     [-0.080, 0.674] #> Age4          0.388 (0.207)  1.87  77.6  .065 .   [-0.025, 0.801] #> Frequency2    0.181 (0.150)  1.21  92.9  .230     [-0.117, 0.479] #> Frequency3    0.095 (0.203)  0.47  96.4  .639     [-0.307, 0.497] #> Frequency4   -0.516 (0.383) -1.35  68.4  .183     [-1.281, 0.249] #> Frequency5   -0.055 (0.327) -0.17  70.4  .867     [-0.707, 0.597] #> ───────────────────────────────────────────────────────────────── #> 'df' is estimated by Satterthwaite approximation. #>  #> Standardized Coefficients (β): #> Outcome Variable: Preference #> ──────────────────────────────────────────────────────────────── #>                  β    S.E.     t    df     p       [95% CI of β] #> ──────────────────────────────────────────────────────────────── #> Sweetness    0.581 (0.035) 16.67 103.7 <.001 *** [ 0.512, 0.650] #> Age2         0.066 (0.069)  0.96  78.6  .341     [-0.071, 0.202] #> Age3         0.127 (0.081)  1.57  76.3  .120     [-0.034, 0.287] #> Age4         0.144 (0.077)  1.87  77.6  .065 .   [-0.009, 0.297] #> Frequency2   0.058 (0.048)  1.21  92.9  .230     [-0.037, 0.152] #> Frequency3   0.023 (0.049)  0.47  96.4  .639     [-0.074, 0.120] #> Frequency4  -0.061 (0.045) -1.35  68.4  .183     [-0.151, 0.029] #> Frequency5  -0.008 (0.046) -0.17  70.4  .867     [-0.099, 0.083] #> ──────────────────────────────────────────────────────────────── #>  #> Random Effects: #> ────────────────────────────────────────── #>  Cluster  K   Parameter   Variance     ICC #> ────────────────────────────────────────── #>  Consumer 103 (Intercept)  1.11977 0.62512 #>               Sweetness    0.04438         #>  Product   12 (Intercept)  0.00825 0.00460 #>  Residual                  0.66328         #> ────────────────────────────────────────── #>"},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":null,"dir":"Reference","previous_headings":"","what":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"Excel, can use VLOOKUP, HLOOKUP, XLOOKUP (new function released 2019), combination INDEX MATCH search, match, look values. provide similar function.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"","code":"LOOKUP(   data,   vars,   data.ref,   vars.ref,   vars.lookup,   return = c(\"new.data\", \"new.var\", \"new.value\") )"},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"data Main data. vars Character (vector), specifying variable(s) searched data. data.ref Reference data containing reference variable(s) lookup variable(s). vars.ref Character (vector), length order vars, specifying reference variable(s) matched data.ref. vars.lookup Character (vector), specifying variable(s) looked returned data.ref. return return. Default (\"new.data\") return data frame lookup values added. may also set \"new.var\" \"new.value\".","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"New data object, new variable, new value (see argument return).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"multiple values simultaneously matched, warning message printed.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/LOOKUP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search, match, and look up values (like Excel's functions INDEX + MATCH). — LOOKUP","text":"","code":"ref = data.table(City=rep(c(\"A\", \"B\", \"C\"), each=5),                  Year=rep(2013:2017, times=3),                  GDP=sample(1000:2000, 15),                  PM2.5=sample(10:300, 15)) ref #>     City Year  GDP PM2.5 #>  1:    A 2013 1615   285 #>  2:    A 2014 1507    62 #>  3:    A 2015 1497   268 #>  4:    A 2016 1040   213 #>  5:    A 2017 1558   296 #>  6:    B 2013 1726   237 #>  7:    B 2014 1026    25 #>  8:    B 2015 1221   187 #>  9:    B 2016 1401    36 #> 10:    B 2017 1825   102 #> 11:    C 2013 1670    52 #> 12:    C 2014 1458   128 #> 13:    C 2015 1392   115 #> 14:    C 2016 1649   286 #> 15:    C 2017 1439   183  data = data.table(sub=1:5,                   city=c(\"A\", \"A\", \"B\", \"C\", \"C\"),                   year=c(2013, 2014, 2015, 2016, 2017)) data #>    sub city year #> 1:   1    A 2013 #> 2:   2    A 2014 #> 3:   3    B 2015 #> 4:   4    C 2016 #> 5:   5    C 2017  LOOKUP(data, c(\"city\", \"year\"), ref, c(\"City\", \"Year\"), \"GDP\") #>    sub city year  GDP #> 1:   1    A 2013 1615 #> 2:   2    A 2014 1507 #> 3:   3    B 2015 1221 #> 4:   4    C 2016 1649 #> 5:   5    C 2017 1439 LOOKUP(data, c(\"city\", \"year\"), ref, c(\"City\", \"Year\"), c(\"GDP\", \"PM2.5\")) #>    sub city year  GDP PM2.5 #> 1:   1    A 2013 1615   285 #> 2:   2    A 2014 1507    62 #> 3:   3    B 2015 1221   187 #> 4:   4    C 2016 1649   286 #> 5:   5    C 2017 1439   183"},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-factor ANOVA. — MANOVA","title":"Multi-factor ANOVA. — MANOVA","text":"Multi-factor ANOVA (-subjects, within-subjects, mixed designs), without covariates (ANCOVA). function based extends afex::aov_ez(). need specify data, dependent variable(s), factors (-subjects /within-subjects). Almost results need displayed together, including effect sizes (partial \\(\\eta^2\\)) confidence intervals (CIs). 90% CIs partial \\(\\eta^2\\) (two-sided) reported, following Steiger (2004). addition partial \\(\\eta^2\\), also reports generalized \\(\\eta^2\\), following Olejnik & Algina (2003). prepare data specify arguments MANOVA? Wide-format data (one person one row, repeated measures multiple columns): Betweem-subjects design MANOVA(data=, dv=, =, ...) Within-subjects design MANOVA(data=, dvs=, dvs.pattern=, within=, ...) Mixed design MANOVA(data=, dvs=, dvs.pattern=, =, within=, ...) Long-format data (one person multiple rows, repeated measures one column): Betweem-subjects design (applicable) Within-subjects design MANOVA(data=, subID=, dv=, within=, ...) Mixed design MANOVA(data=, subID=, dv=, =, within=, ...)","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-factor ANOVA. — MANOVA","text":"","code":"MANOVA(   data,   subID = NULL,   dv = NULL,   dvs = NULL,   dvs.pattern = NULL,   between = NULL,   within = NULL,   covariate = NULL,   ss.type = \"III\",   sph.correction = \"none\",   aov.include = FALSE,   digits = 3,   nsmall = digits,   file = NULL )"},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-factor ANOVA. — MANOVA","text":"data Data frame. wide-format long-format supported. subID Subject ID (column name). necessary long-format data. dv Dependent variable. wide-format data, dv can used -subjects designs.   within-subjects mixed designs, please use dvs dvs.pattern. long-format data, dv outcome variable. dvs Repeated measures. wide-format data (within-subjects mixed designs). Can : \"start:stop\" specify range variables   (sensitive order variables): e.g., \"A1B1:A2B3\" matched variables data   \"A1B1\" \"A2B3\" character vector directly specify variables   (insensitive order variables): e.g., c(\"Cond1\", \"Cond2\", \"Cond3\") cc(\"Cond1, Cond2, Cond3\") See cc usage. dvs.pattern use dvs, also specify pattern variable names using regular expression. Examples: \"Cond(.)\" extracts levels \"Cond1\", \"Cond2\", \"Cond3\", ...   may rename factor using within argument (e.g., within=\"Condition\") \"X(..)Y(..)\" extracts levels \"X01Y01\", \"X02Y02\", \"XaaYbc\", ... \"X(.+)Y(.+)\" extracts levels \"X1Y1\", \"XaYb\", \"XaY002\", ... Tips regular expression: \"(.)\" extracts single character (number, letter, symbols) \"(.+)\" extracts >= 1 character(s) \"(.*)\" extracts >= 0 character(s) \"([0-9])\" extracts single number \"([-z])\" extracts single letter information: Link 1 (English)         Link 2 (Chinese) -subjects factor(s). Multiple variables included character vector c(). within Within-subjects factor(s). Multiple variables included character vector c(). covariate Covariates. Multiple variables included character vector c(). ss.type Type sums squares (SS) ANOVA. Default \"III\". Possible values \"II\", \"III\", 2, 3. sph.correction [repeated measures >= 3 levels] Sphericity correction method adjusting degrees freedom (df) sphericity assumption violated. Default \"none\". Mauchly's test sphericity significant, may set \"GG\" (Greenhouse-Geisser) \"HF\" (Huynh-Feldt). aov.include Include aov object returned object? Default FALSE, suggested afex::aov_ez() (please see include_aov argument help page, provides detailed explanation). TRUE, also specify model.type=\"univariate\" EMMEANS. digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-factor ANOVA. — MANOVA","text":"result object (list) returned afex::aov_ez(), along several elements: , within, data.wide, data.long.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi-factor ANOVA. — MANOVA","text":"observations uniquely identified user-defined long-format data, function takes averages across multiple observations case. technical details, specifies fun_aggregate=mean afex::aov_ez() values_fn=mean tidyr::pivot_wider().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"interaction-plot","dir":"Reference","previous_headings":"","what":"Interaction Plot","title":"Multi-factor ANOVA. — MANOVA","text":"can save returned object use emmeans::emmip() function create interaction plot (based fitted model formula specification). usage, please see help page emmeans::emmip(). returns object class ggplot, can easily modified saved using ggplot2 syntax.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multi-factor ANOVA. — MANOVA","text":"Olejnik, S., & Algina, J. (2003). Generalized eta omega squared statistics: Measures effect size common research designs. Psychological Methods, 8(4), 434-447. Steiger, J. H. (2004). Beyond F test: Effect size confidence intervals tests close fit analysis variance contrast analysis. Psychological Methods, 9(2), 164-182.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/MANOVA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-factor ANOVA. — MANOVA","text":"","code":"#### Between-Subjects Design ####  between.1 #>    A SCORE #> 1  1     3 #> 2  1     6 #> 3  1     4 #> 4  1     3 #> 5  1     5 #> 6  1     7 #> 7  1     5 #> 8  1     2 #> 9  2     4 #> 10 2     6 #> 11 2     4 #> 12 2     2 #> 13 2     4 #> 14 2     5 #> 15 2     3 #> 16 2     3 #> 17 3     8 #> 18 3     9 #> 19 3     8 #> 20 3     7 #> 21 3     5 #> 22 3     6 #> 23 3     7 #> 24 3     6 #> 25 4     9 #> 26 4     8 #> 27 4     8 #> 28 4     7 #> 29 4    12 #> 30 4    13 #> 31 4    12 #> 32 4    11 MANOVA(between.1, dv=\"SCORE\", between=\"A\") #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.812   3  28 22.533 <.001 ***   .707 [.526, .798] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       3.235   3  28  .037 *   #> ─────────────────────────────────────── #>   between.2 #>    A B SCORE #> 1  1 1     3 #> 2  1 1     6 #> 3  1 1     4 #> 4  1 1     3 #> 5  1 2     4 #> 6  1 2     6 #> 7  1 2     4 #> 8  1 2     2 #> 9  1 3     5 #> 10 1 3     7 #> 11 1 3     5 #> 12 1 3     2 #> 13 2 1     4 #> 14 2 1     5 #> 15 2 1     3 #> 16 2 1     3 #> 17 2 2     8 #> 18 2 2     9 #> 19 2 2     8 #> 20 2 2     7 #> 21 2 3    12 #> 22 2 3    13 #> 23 2 3    12 #> 24 2 3    11 MANOVA(between.2, dv=\"SCORE\", between=c(\"A\", \"B\")) #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 24 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────────── #> A      80.667 1.861   1  18 43.343 <.001 ***   .707 [.482, .817] .707 #> B      40.542 1.861   2  18 21.784 <.001 ***   .708 [.470, .815] .708 #> A * B  28.292 1.861   2  18 15.201 <.001 ***   .628 [.347, .763] .628 #> ───────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.605   5  18  .697     #> ─────────────────────────────────────── #>   between.3 #>    A B C SCORE #> 1  1 1 1     3 #> 2  1 1 1     6 #> 3  1 1 1     4 #> 4  1 1 1     3 #> 5  1 1 2     5 #> 6  1 1 2     7 #> 7  1 1 2     5 #> 8  1 1 2     2 #> 9  1 2 1     4 #> 10 1 2 1     6 #> 11 1 2 1     4 #> 12 1 2 1     2 #> 13 1 2 2     4 #> 14 1 2 2     5 #> 15 1 2 2     3 #> 16 1 2 2     3 #> 17 2 1 1     8 #> 18 2 1 1     9 #> 19 2 1 1     8 #> 20 2 1 1     7 #> 21 2 1 2     5 #> 22 2 1 2     6 #> 23 2 1 2     7 #> 24 2 1 2     6 #> 25 2 2 1     9 #> 26 2 2 1     8 #> 27 2 2 1     8 #> 28 2 2 1     7 #> 29 2 2 2    12 #> 30 2 2 2    13 #> 31 2 2 2    12 #> 32 2 2 2    11 MANOVA(between.3, dv=\"SCORE\", between=c(\"A\", \"B\", \"C\")) #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 32 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B, C #> Within-subjects factor(s):  – #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 1.563   1  24 98.000 <.001 ***   .803 [.670, .870] .803 #> B           12.500 1.563   1  24  8.000  .009 **    .250 [.042, .466] .250 #> C            3.125 1.563   1  24  2.000  .170       .077 [.000, .283] .077 #> A * B       24.500 1.563   1  24 15.680 <.001 ***   .395 [.147, .585] .395 #> A * C        1.125 1.563   1  24  0.720  .405       .029 [.000, .206] .029 #> B * C       12.500 1.563   1  24  8.000  .009 **    .250 [.042, .466] .250 #> A * B * C   24.500 1.563   1  24 15.680 <.001 ***   .395 [.147, .585] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.668   7  24  .697     #> ─────────────────────────────────────── #>   ## How to create an interaction plot using `emmeans::emmip()`? ## See help page for its usage: ?emmeans::emmip() m = MANOVA(between.2, dv=\"SCORE\", between=c(\"A\", \"B\")) #>  #> ====== ANOVA (Between-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 24 #>  #> ANOVA Table: #> Dependent variable(s):      SCORE #> Between-subjects factor(s): A, B #> Within-subjects factor(s):  – #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────────── #> A      80.667 1.861   1  18 43.343 <.001 ***   .707 [.482, .817] .707 #> B      40.542 1.861   2  18 21.784 <.001 ***   .708 [.470, .815] .708 #> A * B  28.292 1.861   2  18 15.201 <.001 ***   .628 [.347, .763] .628 #> ───────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ─────────────────────────────────────── #>            Levene’s F df1 df2     p     #> ─────────────────────────────────────── #> DV: SCORE       0.605   5  18  .697     #> ─────────────────────────────────────── #>  emmip(m, ~ A | B, CIs=TRUE)  emmip(m, ~ B | A, CIs=TRUE)  emmip(m, B ~ A, CIs=TRUE)  emmip(m, A ~ B, CIs=TRUE)    #### Within-Subjects Design ####  within.1 #>   ID A1 A2 A3 A4 #> 1 S1  3  4  8  9 #> 2 S2  6  6  9  8 #> 3 S3  4  4  8  8 #> 4 S4  3  2  7  7 #> 5 S5  5  4  5 12 #> 6 S6  7  5  6 13 #> 7 S7  5  3  7 12 #> 8 S8  2  3  6 11 MANOVA(within.1, dvs=\"A1:A4\", dvs.pattern=\"A(.)\",        within=\"A\") #>  #> Note: #> dvs=\"A1:A4\" is matched to variables: #> A1, A2, A3, A4 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────── #>  \"A\"   Mean    S.D. n #> ───────────────────── #>   A1  4.375 (1.685) 8 #>   A2  3.875 (1.246) 8 #>   A3  7.000 (1.309) 8 #>   A4 10.000 (2.268) 8 #> ───────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      A1, A2, A3, A4 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A #> Covariate(s):               – #> ───────────────────────────────────────────────────────────────── #>        MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ───────────────────────────────────────────────────────────────── #> A  63.375 2.518   3  21 25.170 <.001 ***   .782 [.609, .858] .707 #> ───────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────── #>    Mauchly's W     p     #> ──────────────────────── #> A       0.1899  .095 .   #> ──────────────────────── #>  ## the same: MANOVA(within.1, dvs=c(\"A1\", \"A2\", \"A3\", \"A4\"), dvs.pattern=\"A(.)\",        within=\"MyFactor\")  # renamed the within-subjects factor #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ──────────────────────────── #>  \"MyFactor\"   Mean    S.D. n #> ──────────────────────────── #>   MyFactor1  4.375 (1.685) 8 #>   MyFactor2  3.875 (1.246) 8 #>   MyFactor3  7.000 (1.309) 8 #>   MyFactor4 10.000 (2.268) 8 #> ──────────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      A1, A2, A3, A4 #> Between-subjects factor(s): – #> Within-subjects factor(s):  MyFactor #> Covariate(s):               – #> ──────────────────────────────────────────────────────────────────────── #>               MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ──────────────────────────────────────────────────────────────────────── #> MyFactor  63.375 2.518   3  21 25.170 <.001 ***   .782 [.609, .858] .707 #> ──────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> ─────────────────────────────── #>           Mauchly's W     p     #> ─────────────────────────────── #> MyFactor       0.1899  .095 .   #> ─────────────────────────────── #>   within.2 #>   ID A1B1 A1B2 A1B3 A2B1 A2B2 A2B3 #> 1 S1    3    4    5    4    8   12 #> 2 S2    6    6    7    5    9   13 #> 3 S3    4    4    5    3    8   12 #> 4 S4    3    2    2    3    7   11 MANOVA(within.2, dvs=\"A1B1:A2B3\", dvs.pattern=\"A(.)B(.)\",        within=c(\"A\", \"B\")) #>  #> Note: #> dvs=\"A1B1:A2B3\" is matched to variables: #> A1B1, A1B2, A1B3, A2B1, A2B2, A2B3 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 4 #>  #> ANOVA Table: #> Dependent variable(s):      A1B1, A1B2, A1B3, A2B1, A2B2, A2B3 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A, B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2       F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────── #> A      80.667 1.111   1   3  72.600  .003 **    .960 [.699, .985] .707 #> B      40.542 0.264   2   6 153.632 <.001 ***   .981 [.930, .991] .708 #> A * B  28.292 0.236   2   6 119.824 <.001 ***   .976 [.911, .988] .628 #> ────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────── #>        Mauchly's W     p     #> ──────────────────────────── #> B           0.0665  .066 .   #> A * B       0.2491  .249     #> ──────────────────────────── #>   within.3 #>   ID A1B1C1 A1B1C2 A1B2C1 A1B2C2 A2B1C1 A2B1C2 A2B2C1 A2B2C2 #> 1 S1      3      5      4      4      8      5      9     12 #> 2 S2      6      7      6      5      9      6      8     13 #> 3 S3      4      5      4      3      8      7      8     12 #> 4 S4      3      2      2      3      7      6      7     11 MANOVA(within.3, dvs=\"A1B1C1:A2B2C2\", dvs.pattern=\"A(.)B(.)C(.)\",        within=c(\"A\", \"B\", \"C\")) #>  #> Note: #> dvs=\"A1B1C1:A2B2C2\" is matched to variables: #> A1B1C1, A1B1C2, A1B2C1, A1B2C2, A2B1C1, A2B1C2, A2B2C1, A2B2C2 #>  #> ====== ANOVA (Within-Subjects Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 4 #>  #> ANOVA Table: #> Dependent variable(s):      A1B1C1, A1B1C2, A1B2C1, A1B2C2, A2B1C1, A2B1C2, A2B2C1, A2B2C2 #> Between-subjects factor(s): – #> Within-subjects factor(s):  A, B, C #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 1.875   1   3 81.667  .003 **    .965 [.727, .986] .803 #> B           12.500 0.583   1   3 21.429  .019 *     .877 [.279, .954] .250 #> C            3.125 0.042   1   3 75.000  .003 **    .962 [.707, .985] .077 #> A * B       24.500 0.250   1   3 98.000  .002 **    .970 [.768, .989] .395 #> A * C        1.125 0.708   1   3  1.588  .297       .346 [.000, .543] .029 #> B * C       12.500 0.417   1   3 30.000  .012 *     .909 [.411, .965] .250 #> A * B * C   24.500 1.083   1   3 22.615  .018 *     .883 [.300, .956] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> No between-subjects factors. No need to do the Levene’s test. #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>    #### Mixed Design ####  mixed.2_1b1w #>   A B1 B2 B3 #> 1 1  3  4  5 #> 2 1  6  6  7 #> 3 1  4  4  5 #> 4 1  3  2  2 #> 5 2  4  8 12 #> 6 2  5  9 13 #> 7 2  3  8 12 #> 8 2  3  7 11 MANOVA(mixed.2_1b1w, dvs=\"B1:B3\", dvs.pattern=\"B(.)\",        between=\"A\", within=\"B\") #>  #> Note: #> dvs=\"B1:B3\" is matched to variables: #> B1, B2, B3 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      B1, B2, B3 #> Between-subjects factor(s): A #> Within-subjects factor(s):  B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────── #>            MS   MSE df1 df2       F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────── #> A      80.667 5.083   1   6  15.869  .007 **    .726 [.248, .871] .707 #> B      40.542 0.250   2  12 162.167 <.001 ***   .964 [.918, .980] .708 #> A * B  28.292 0.250   2  12 113.167 <.001 ***   .950 [.885, .971] .628 #> ────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────── #>         Levene’s F df1 df2     p     #> ──────────────────────────────────── #> DV: B1       0.300   1   6  .604     #> DV: B2       0.600   1   6  .468     #> DV: B3       1.485   1   6  .269     #> ──────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────── #>        Mauchly's W     p     #> ──────────────────────────── #> B           0.1574  .010 **  #> A * B       0.1574  .010 **  #> ──────────────────────────── #> The sphericity assumption is violated. #> You may specify: sph.correction=\"GG\" (or =\"HF\") #>  MANOVA(mixed.2_1b1w, dvs=\"B1:B3\", dvs.pattern=\"B(.)\",        between=\"A\", within=\"B\", sph.correction=\"GG\") #>  #> Note: #> dvs=\"B1:B3\" is matched to variables: #> B1, B2, B3 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────── #>  \"A\" \"B\"   Mean    S.D. n #> ───────────────────────── #>   A1  B1  4.000 (1.414) 4 #>   A1  B2  4.000 (1.633) 4 #>   A1  B3  4.750 (2.062) 4 #>   A2  B1  3.750 (0.957) 4 #>   A2  B2  8.000 (0.816) 4 #>   A2  B3 12.000 (0.816) 4 #> ───────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      B1, B2, B3 #> Between-subjects factor(s): A #> Within-subjects factor(s):  B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>            MS   MSE   df1   df2       F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A      80.667 5.083 1.000 6.000  15.869  .007 **    .726 [.248, .871] .707 #> B      74.702 0.461 1.085 6.513 162.167 <.001 ***   .964 [.880, .983] .708 #> A * B  52.130 0.461 1.085 6.513 113.167 <.001 ***   .950 [.833, .976] .628 #> ────────────────────────────────────────────────────────────────────────── #> Sphericity correction method: GG (Greenhouse-Geisser) #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────── #>         Levene’s F df1 df2     p     #> ──────────────────────────────────── #> DV: B1       0.300   1   6  .604     #> DV: B2       0.600   1   6  .468     #> DV: B3       1.485   1   6  .269     #> ──────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────── #>        Mauchly's W     p     #> ──────────────────────────── #> B           0.1574  .010 **  #> A * B       0.1574  .010 **  #> ──────────────────────────── #>   mixed.3_1b2w #>   A B1C1 B1C2 B2C1 B2C2 #> 1 1    3    5    4    4 #> 2 1    6    7    6    5 #> 3 1    4    5    4    3 #> 4 1    3    2    2    3 #> 5 2    8    5    9   12 #> 6 2    9    6    8   13 #> 7 2    8    7    8   12 #> 8 2    7    6    7   11 MANOVA(mixed.3_1b2w, dvs=\"B1C1:B2C2\", dvs.pattern=\"B(.)C(.)\",        between=\"A\", within=c(\"B\", \"C\")) #>  #> Note: #> dvs=\"B1C1:B2C2\" is matched to variables: #> B1C1, B1C2, B2C1, B2C2 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"B\" \"C\"   Mean    S.D. n #> ───────────────────────────── #>   A1  B1  C1  4.000 (1.414) 4 #>   A1  B1  C2  4.750 (2.062) 4 #>   A1  B2  C1  4.000 (1.633) 4 #>   A1  B2  C2  3.750 (0.957) 4 #>   A2  B1  C1  8.000 (0.816) 4 #>   A2  B1  C2  6.000 (0.816) 4 #>   A2  B2  C1  8.000 (0.816) 4 #>   A2  B2  C2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      B1C1, B1C2, B2C1, B2C2 #> Between-subjects factor(s): A #> Within-subjects factor(s):  B, C #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 4.708   1   6 32.522  .001 **    .844 [.503, .926] .803 #> B           12.500 0.417   1   6 30.000  .002 **    .833 [.475, .921] .250 #> A * B       24.500 0.417   1   6 58.800 <.001 ***   .907 [.684, .956] .395 #> C            3.125 0.375   1   6  8.333  .028 *     .581 [.064, .801] .077 #> A * C        1.125 0.375   1   6  3.000  .134       .333 [.000, .671] .029 #> B * C       12.500 0.750   1   6 16.667  .006 **    .735 [.264, .875] .250 #> A * B * C   24.500 0.750   1   6 32.667  .001 **    .845 [.505, .927] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ────────────────────────────────────── #>           Levene’s F df1 df2     p     #> ────────────────────────────────────── #> DV: B1C1       1.000   1   6  .356     #> DV: B1C2       1.485   1   6  .269     #> DV: B2C1       0.600   1   6  .468     #> DV: B2C2       0.500   1   6  .506     #> ────────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>   mixed.3_2b1w #>    A C B1 B2 #> 1  1 1  3  4 #> 2  1 1  6  6 #> 3  1 1  4  4 #> 4  1 1  3  2 #> 5  1 2  5  4 #> 6  1 2  7  5 #> 7  1 2  5  3 #> 8  1 2  2  3 #> 9  2 1  8  9 #> 10 2 1  9  8 #> 11 2 1  8  8 #> 12 2 1  7  7 #> 13 2 2  5 12 #> 14 2 2  6 13 #> 15 2 2  7 12 #> 16 2 2  6 11 MANOVA(mixed.3_2b1w, dvs=\"B1:B2\", dvs.pattern=\"B(.)\",        between=c(\"A\", \"C\"), within=\"B\") #>  #> Note: #> dvs=\"B1:B2\" is matched to variables: #> B1, B2 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────── #>  \"A\" \"C\" \"B\"   Mean    S.D. n #> ───────────────────────────── #>   A1  C1  B1  4.000 (1.414) 4 #>   A1  C1  B2  4.000 (1.633) 4 #>   A1  C2  B1  4.750 (2.062) 4 #>   A1  C2  B2  3.750 (0.957) 4 #>   A2  C1  B1  8.000 (0.816) 4 #>   A2  C1  B2  8.000 (0.816) 4 #>   A2  C2  B1  6.000 (0.816) 4 #>   A2  C2  B2 12.000 (0.816) 4 #> ───────────────────────────── #> Total sample size: N = 16 #>  #> ANOVA Table: #> Dependent variable(s):      B1, B2 #> Between-subjects factor(s): A, C #> Within-subjects factor(s):  B #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────── #>                 MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────── #> A          153.125 2.542   1  12 60.246 <.001 ***   .834 [.639, .906] .803 #> C            3.125 2.542   1  12  1.230  .289       .093 [.000, .390] .077 #> A * C        1.125 2.542   1  12  0.443  .518       .036 [.000, .305] .029 #> B           12.500 0.583   1  12 21.429 <.001 ***   .641 [.308, .795] .250 #> A * B       24.500 0.583   1  12 42.000 <.001 ***   .778 [.532, .874] .395 #> C * B       12.500 0.583   1  12 21.429 <.001 ***   .641 [.308, .795] .250 #> A * C * B   24.500 0.583   1  12 42.000 <.001 ***   .778 [.532, .874] .395 #> ────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────── #>         Levene’s F df1 df2     p     #> ──────────────────────────────────── #> DV: B1       0.946   3  12  .449     #> DV: B2       0.423   3  12  .740     #> ──────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> The repeated measures have only two levels. The assumption of sphericity is always met. #>    #### Other Examples ####  data.new = mixed.3_1b2w names(data.new) = c(\"Group\", \"Cond_01\", \"Cond_02\", \"Cond_03\", \"Cond_04\") MANOVA(data.new,        dvs=\"Cond_01:Cond_04\",        dvs.pattern=\"Cond_(..)\",        between=\"Group\",        within=\"Condition\")  # rename the factor #>  #> Note: #> dvs=\"Cond_01:Cond_04\" is matched to variables: #> Cond_01, Cond_02, Cond_03, Cond_04 #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────────────── #>  \"Group\" \"Condition\"   Mean    S.D. n #> ───────────────────────────────────── #>   Group1 Condition01  4.000 (1.414) 4 #>   Group1 Condition02  4.750 (2.062) 4 #>   Group1 Condition03  4.000 (1.633) 4 #>   Group1 Condition04  3.750 (0.957) 4 #>   Group2 Condition01  8.000 (0.816) 4 #>   Group2 Condition02  6.000 (0.816) 4 #>   Group2 Condition03  8.000 (0.816) 4 #>   Group2 Condition04 12.000 (0.816) 4 #> ───────────────────────────────────── #> Total sample size: N = 8 #>  #> ANOVA Table: #> Dependent variable(s):      Cond_01, Cond_02, Cond_03, Cond_04 #> Between-subjects factor(s): Group #> Within-subjects factor(s):  Condition #> Covariate(s):               – #> ────────────────────────────────────────────────────────────────────────────────── #>                         MS   MSE df1 df2      F     p     η²p [90% CI of η²p]  η²G #> ────────────────────────────────────────────────────────────────────────────────── #> Group              153.125 4.708   1   6 32.522  .001 **    .844 [.503, .926] .803 #> Condition            9.375 0.514   3  18 18.243 <.001 ***   .753 [.533, .843] .429 #> Group * Condition   16.708 0.514   3  18 32.514 <.001 ***   .844 [.702, .902] .572 #> ────────────────────────────────────────────────────────────────────────────────── #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ───────────────────────────────────────── #>              Levene’s F df1 df2     p     #> ───────────────────────────────────────── #> DV: Cond_01       1.000   1   6  .356     #> DV: Cond_02       1.485   1   6  .269     #> DV: Cond_03       0.600   1   6  .468     #> DV: Cond_04       0.500   1   6  .506     #> ───────────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────────────────── #>                    Mauchly's W     p     #> ──────────────────────────────────────── #> Condition               0.5544  .738     #> Group * Condition       0.5544  .738     #> ──────────────────────────────────────── #>   # ?afex::obk.long MANOVA(afex::obk.long,        subID=\"id\",        dv=\"value\",        between=c(\"treatment\", \"gender\"),        within=c(\"phase\", \"hour\"),        cov=\"age\",        sph.correction=\"GG\") #>  #>     * Data are aggregated to mean (across items/trials) #>     if there are >=2 observations per subject and cell. #>     You may use Linear Mixed Model to analyze the data, #>     e.g., with subjects and items as level-2 clusters. #>  #> ====== ANOVA (Mixed Design) ====== #>  #> Descriptives: #> ───────────────────────────────────────────────────── #>  \"treatment\" \"gender\" \"phase\" \"hour\"   Mean    S.D. n #> ───────────────────────────────────────────────────── #>      control        F    fup   hour1  4.000 (0.000) 2 #>      control        F    fup   hour2  3.500 (0.707) 2 #>      control        F    fup   hour3  5.500 (0.707) 2 #>      control        F    fup   hour4  3.500 (0.707) 2 #>      control        F    fup   hour5  3.500 (0.707) 2 #>      control        F    post  hour1  4.000 (2.828) 2 #>      control        F    post  hour2  4.500 (3.536) 2 #>      control        F    post  hour3  5.500 (3.536) 2 #>      control        F    post  hour4  5.500 (0.707) 2 #>      control        F    post  hour5  3.000 (0.000) 2 #>      control        F    pre   hour1  4.000 (1.414) 2 #>      control        F    pre   hour2  4.000 (0.000) 2 #>      control        F    pre   hour3  6.500 (0.707) 2 #>      control        F    pre   hour4  4.500 (0.707) 2 #>      control        F    pre   hour5  3.500 (0.707) 2 #>      control        M    fup   hour1  4.333 (2.517) 3 #>      control        M    fup   hour2  4.667 (1.528) 3 #>      control        M    fup   hour3  5.667 (3.512) 3 #>      control        M    fup   hour4  5.000 (1.732) 3 #>      control        M    fup   hour5  3.667 (2.517) 3 #>      control        M    post  hour1  3.000 (1.000) 3 #>      control        M    post  hour2  3.000 (1.732) 3 #>      control        M    post  hour3  5.000 (2.000) 3 #>      control        M    post  hour4  4.333 (1.155) 3 #>      control        M    post  hour5  3.000 (1.000) 3 #>      control        M    pre   hour1  3.333 (2.082) 3 #>      control        M    pre   hour2  4.000 (2.000) 3 #>      control        M    pre   hour3  4.667 (0.577) 3 #>      control        M    pre   hour4  4.000 (2.646) 3 #>      control        M    pre   hour5  4.000 (3.000) 3 #>      A              F    fup   hour1  5.500 (0.707) 2 #>      A              F    fup   hour2  5.000 (1.414) 2 #>      A              F    fup   hour3  7.000 (0.000) 2 #>      A              F    fup   hour4  5.000 (0.000) 2 #>      A              F    fup   hour5  5.000 (1.414) 2 #>      A              F    post  hour1  3.000 (1.414) 2 #>      A              F    post  hour2  4.500 (0.707) 2 #>      A              F    post  hour3  7.000 (1.414) 2 #>      A              F    post  hour4  5.000 (1.414) 2 #>      A              F    post  hour5  3.000 (2.828) 2 #>      A              F    pre   hour1  2.500 (0.707) 2 #>      A              F    pre   hour2  3.000 (0.000) 2 #>      A              F    pre   hour3  4.500 (0.707) 2 #>      A              F    pre   hour4  4.500 (2.121) 2 #>      A              F    pre   hour5  3.000 (1.414) 2 #>      A              M    fup   hour1  8.500 (0.707) 2 #>      A              M    fup   hour2  9.500 (0.707) 2 #>      A              M    fup   hour3 11.000 (0.000) 2 #>      A              M    fup   hour4  9.000 (0.000) 2 #>      A              M    fup   hour5  7.000 (1.414) 2 #>      A              M    post  hour1  8.000 (1.414) 2 #>      A              M    post  hour2  8.000 (1.414) 2 #>      A              M    post  hour3  9.000 (1.414) 2 #>      A              M    post  hour4  9.000 (1.414) 2 #>      A              M    post  hour5  8.500 (0.707) 2 #>      A              M    pre   hour1  6.000 (1.414) 2 #>      A              M    pre   hour2  6.500 (2.121) 2 #>      A              M    pre   hour3  6.500 (0.707) 2 #>      A              M    pre   hour4  6.500 (3.536) 2 #>      A              M    pre   hour5  7.000 (2.828) 2 #>      B              F    fup   hour1  6.750 (0.500) 4 #>      B              F    fup   hour2  7.250 (0.500) 4 #>      B              F    fup   hour3  8.500 (1.000) 4 #>      B              F    fup   hour4  7.500 (1.915) 4 #>      B              F    fup   hour5  6.250 (2.217) 4 #>      B              F    post  hour1  5.500 (1.291) 4 #>      B              F    post  hour2  6.250 (0.500) 4 #>      B              F    post  hour3  7.000 (0.816) 4 #>      B              F    post  hour4  7.000 (1.826) 4 #>      B              F    post  hour5  5.500 (2.380) 4 #>      B              F    pre   hour1  3.250 (1.500) 4 #>      B              F    pre   hour2  3.500 (1.732) 4 #>      B              F    pre   hour3  4.750 (2.062) 4 #>      B              F    pre   hour4  4.500 (2.887) 4 #>      B              F    pre   hour5  4.000 (1.633) 4 #>      B              M    fup   hour1  7.000 (1.732) 3 #>      B              M    fup   hour2  7.000 (1.000) 3 #>      B              M    fup   hour3  9.000 (1.000) 3 #>      B              M    fup   hour4  7.000 (1.000) 3 #>      B              M    fup   hour5  6.667 (1.528) 3 #>      B              M    post  hour1  6.667 (2.082) 3 #>      B              M    post  hour2  7.000 (3.000) 3 #>      B              M    post  hour3  8.000 (2.646) 3 #>      B              M    post  hour4  7.333 (2.082) 3 #>      B              M    post  hour5  6.000 (2.000) 3 #>      B              M    pre   hour1  4.333 (1.528) 3 #>      B              M    pre   hour2  4.667 (2.082) 3 #>      B              M    pre   hour3  5.667 (2.082) 3 #>      B              M    pre   hour4  3.667 (2.082) 3 #>      B              M    pre   hour5  3.333 (0.577) 3 #> ───────────────────────────────────────────────────── #> Total sample size: N = 16 #>  #> ANOVA Table: #> Dependent variable(s):      value #> Between-subjects factor(s): treatment, gender #> Within-subjects factor(s):  phase, hour #> Covariate(s):               age #> ─────────────────────────────────────────────────────────────────────────────────────────────────────── #>                                        MS    MSE   df1    df2      F     p     η²p [90% CI of η²p]  η²G #> ─────────────────────────────────────────────────────────────────────────────────────────────────────── #> treatment                          85.700 23.962 2.000  9.000  3.577  .072 .     .443 [.000, .684] .294 #> gender                             94.598 23.962 1.000  9.000  3.948  .078 .     .305 [.000, .610] .187 #> age                                12.399 23.962 1.000  9.000  0.517  .490       .054 [.000, .381] .029 #> treatment * gender                 30.766 23.962 2.000  9.000  1.284  .323       .222 [.000, .516] .130 #> phase                              79.287  3.909 1.697 15.277 20.281 <.001 ***   .693 [.420, .813] .246 #> treatment * phase                  23.743  3.909 3.395 15.277  6.073  .005 **    .574 [.192, .728] .164 #> gender * phase                      0.963  3.909 1.697 15.277  0.246  .749       .027 [.000, .193] .004 #> age * phase                        12.108  3.909 1.697 15.277  3.097  .081 .     .256 [.000, .502] .048 #> treatment * gender * phase          6.261  3.909 3.395 15.277  1.601  .228       .262 [.000, .470] .049 #> hour                               50.786  2.475 2.137 19.230 20.519 <.001 ***   .695 [.459, .804] .209 #> treatment * hour                    1.766  2.475 4.273 19.230  0.714  .601       .137 [.000, .270] .018 #> gender * hour                       1.753  2.475 2.137 19.230  0.708  .514       .073 [.000, .254] .009 #> age * hour                          6.976  2.475 2.137 19.230  2.818  .082 .     .238 [.000, .456] .035 #> treatment * gender * hour           1.459  2.475 4.273 19.230  0.590  .684       .116 [.000, .233] .015 #> phase * hour                        2.802  2.826 3.485 31.362  0.991  .419       .099 [.000, .223] .023 #> treatment * phase * hour            0.944  2.826 6.969 31.362  0.334  .932       .069 [.000, .027] .016 #> gender * phase * hour               2.540  2.826 3.485 31.362  0.899  .465       .091 [.000, .210] .021 #> age * phase * hour                  2.164  2.826 3.485 31.362  0.766  .540       .078 [.000, .188] .018 #> treatment * gender * phase * hour   1.840  2.826 6.969 31.362  0.651  .710       .126 [.000, .170] .030 #> ─────────────────────────────────────────────────────────────────────────────────────────────────────── #> Sphericity correction method: GG (Greenhouse-Geisser) #> MSE = mean square error (the residual variance of the linear model) #> η²p = partial eta-squared = SS / (SS + SSE) = F * df1 / (F * df1 + df2) #> ω²p = partial omega-squared = (F - 1) * df1 / (F * df1 + df2 + 1) #> η²G = generalized eta-squared (see Olejnik & Algina, 2003) #> Cohen’s f² = η²p / (1 - η²p) #>  #> Levene’s Test for Homogeneity of Variance: #> ──────────────────────────────────────────── #>                 Levene’s F df1 df2     p     #> ──────────────────────────────────────────── #> DV: pre_hour1        1.019   5  10  .456     #> DV: pre_hour2        3.233   5  10  .054 .   #> DV: pre_hour3        5.654   5  10  .010 **  #> DV: pre_hour4        0.793   5  10  .578     #> DV: pre_hour5        1.208   5  10  .372     #> DV: post_hour1       1.831   5  10  .194     #> DV: post_hour2       2.664   5  10  .088 .   #> DV: post_hour3       2.566   5  10  .096 .   #> DV: post_hour4       1.570   5  10  .254     #> DV: post_hour5       1.773   5  10  .206     #> DV: fup_hour1        3.012   5  10  .065 .   #> DV: fup_hour2        1.392   5  10  .306     #> DV: fup_hour3        2.672   5  10  .087 .   #> DV: fup_hour4        3.363   5  10  .049 *   #> DV: fup_hour5        0.679   5  10  .650     #> ──────────────────────────────────────────── #>  #> Mauchly’s Test of Sphericity: #> ──────────────────────────────────────────────────────── #>                                    Mauchly's W     p     #> ──────────────────────────────────────────────────────── #> phase                                   0.8218  .456     #> treatment * phase                       0.8218  .456     #> gender * phase                          0.8218  .456     #> age * phase                             0.8218  .456     #> treatment * gender * phase              0.8218  .456     #> hour                                    0.0967  .049 *   #> treatment * hour                        0.0967  .049 *   #> gender * hour                           0.0967  .049 *   #> age * hour                              0.0967  .049 *   #> treatment * gender * hour               0.0967  .049 *   #> phase * hour                            0.0002  .087 .   #> treatment * phase * hour                0.0002  .087 .   #> gender * phase * hour                   0.0002  .087 .   #> age * phase * hour                      0.0002  .087 .   #> treatment * gender * phase * hour       0.0002  .087 .   #> ──────────────────────────────────────────────────────── #>"},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":null,"dir":"Reference","previous_headings":"","what":"PROCESS for mediation and/or moderation analyses. — PROCESS","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"perform mediation, moderation, conditional process (moderated mediation) analyses, people may use software like Mplus, SPSS \"PROCESS\" macro, SPSS \"MLmed\" macro. R packages can also perform analyses separately complex way, including R package \"mediation\", R package \"interactions\", R package \"lavaan\". R packages scripts/modules developed improve convenience, including jamovi module \"jAMM\" (Marcello Gallucci, based lavaan package), R package \"processR\" (Keon-Woong Moon, official, also based lavaan package), R script file \"process.R\" (official PROCESS R code Andrew F. Hayes, yet R package bugs limitations). , bruceR::PROCESS() function provides alternative performing mediation/moderation analyses R. function supports total 24 kinds SPSS PROCESS models (Hayes, 2018) also supports multilevel mediation/moderation analyses. Overall, supports frequently used types mediation, moderation, moderated moderation (3-way interaction), moderated mediation (conditional indirect effect) analyses (generalized) linear linear mixed models. Specifically, bruceR::PROCESS() function fits regression models based data, variable names, arguments users input (need specify PROCESS model number need manually mean-center variables). function can automatically judge model number/type also conduct grand-mean centering model building (using bruceR::grand_mean_center() function). automatic grand-mean centering can turned setting center=FALSE. Note automatic grand-mean centering (1) makes results main effects accurate interpretation; (2) change results model fit (affects interpretation main effects); (3) conducted \"PART 1\" (accurate estimate main effects) \"PART 2\" intuitive interpretable use raw values variables simple-slope tests \"PART 2\"; (4) optional users mean-centering always done interaction; (5) conflicted group-mean centering group-mean centering grand mean variable also 0, automatic grand-mean centering (mean = 0) change values variable. need group-mean centering, please using PROCESS. bruceR::group_mean_center() useful function group-mean centering. Remember automatic grand-mean centering PROCESS never affects values group-mean centered variable, already grand mean 0. bruceR::PROCESS() function uses: interactions::sim_slopes() function   estimate simple slopes (conditional direct effects) moderation, moderated moderation, moderated mediation models   (PROCESS Models 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 58, 59, 72, 73, 75, 76). mediation::mediate() function   estimate (conditional) indirect effects (moderated) mediation models   (PROCESS Models 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 58, 59, 72, 73, 75, 76). lavaan::sem() function perform serial multiple mediation analysis (PROCESS Model 6). use function research report results paper, please cite bruceR also R packages uses internally (mediation, interactions, /lavaan). Two parts results printed: PART 1. Regression model summary (using bruceR::model_summary() summarize models) PART 2. Mediation/moderation effect estimates (using one combination packages functions estimate effects) organize PART 2 output, results Simple Slopes titled green, whereas results Indirect Path titled blue. Disclaimer: Although function named PROCESS, Andrew F. Hayes role design, development independent official SPSS PROCESS macro \"process.R\" script. error limitation attributed three R packages/functions bruceR::PROCESS() uses internally. Moreover, mediation analyses include random processes (.e., bootstrap resampling Monte Carlo simulation), results mediation analyses unlikely exactly across different software (even set random seed different software).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"","code":"PROCESS(   data,   y = \"\",   x = \"\",   meds = c(),   mods = c(),   covs = c(),   clusters = c(),   hlm.re.m = \"\",   hlm.re.y = \"\",   hlm.type = c(\"1-1-1\", \"2-1-1\", \"2-2-1\"),   med.type = c(\"parallel\", \"serial\"),   mod.type = c(\"2-way\", \"3-way\"),   mod.path = c(\"x-y\", \"x-m\", \"m-y\", \"all\"),   cov.path = c(\"y\", \"m\", \"both\"),   mod1.val = NULL,   mod2.val = NULL,   ci = c(\"boot\", \"bc.boot\", \"bca.boot\", \"mcmc\"),   nsim = 100,   seed = NULL,   center = TRUE,   std = FALSE,   digits = 3,   nsmall = digits,   file = NULL )"},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"data Data frame. y, x Variable name outcome (Y) predictor (X). supports continuous (numeric) dichotomous (factor) variables. meds Variable name(s) mediator(s) (M). Use c() combine multiple mediators. supports continuous (numeric) dichotomous (factor) variables. allows infinite number mediators parallel 2~4 mediators serial. * Order matters med.type=\"serial\" (PROCESS Model 6: serial mediation). mods Variable name(s) 0~2 moderator(s) (W). Use c() combine multiple moderators. supports types variables: continuous (numeric), dichotomous (factor), multicategorical (factor). * Order matters mod.type=\"3-way\" (PROCESS Models 3, 5.3, 11, 12, 18, 19, 72, 73). ** set argument med.type=\"serial\" (PROCESS Model 6). covs Variable name(s) covariate(s) (.e., control variables). Use c() combine multiple covariates. supports types (infinite number ) variables. clusters HLM (multilevel) cluster(s): e.g., \"School\", c(\"Prov\", \"City\"), c(\"Sub\", \"Item\"). hlm.re.m, hlm.re.y HLM (multilevel) random effect term M model Y model. default, converts clusters lme4 syntax random intercepts: e.g., \"(1 | School)\" \"(1 | Sub) + (1 | Item)\". may specify arguments include complex terms: e.g., random slopes \"(X | School)\", 3-level random effects \"(1 | Prov/City)\". hlm.type HLM (multilevel) mediation type (levels \"X-M-Y\"): \"1-1-1\" (default), \"2-1-1\" (indeed \"1-1-1\" mixed model), \"2-2-1\" (currently fully supported, limited mediation package). cases, need set argument. med.type Type mediator: \"parallel\" (default) \"serial\" (relevant PROCESS Model 6). Partial matches \"p\" \"s\" also work. cases, need set argument. mod.type Type moderator: \"2-way\" (default) \"3-way\" (relevant PROCESS Models 3, 5.3, 11, 12, 18, 19, 72, 73). Partial matches \"2\" \"3\" also work. mod.path path(s) moderator(s) influence? \"x-y\", \"x-m\", \"m-y\", combination (use c() combine), \"\" (.e., ). default value. cov.path path(s) control variable(s) influence? \"y\", \"m\", \"\" (default). mod1.val, mod2.val default (NULL), uses Mean +/- SD continuous moderator (numeric) levels dichotomous/multicategorical moderator (factor) perform simple slope analyses /conditional mediation analyses. may manually specify vector certain values: e.g., mod1.val=c(1, 3, 5) mod1.val=c(\"\", \"B\", \"C\"). ci Method estimating standard error (SE) 95% confidence interval (CI) indirect effect(s). Default \"boot\" (generalized) linear models \"mcmc\" (generalized) linear mixed models (.e., multilevel models). \"boot\" Percentile Bootstrap \"bc.boot\" Bias-Corrected Percentile Bootstrap \"bca.boot\" Bias-Corrected Accelerated (BCa) Percentile Bootstrap \"mcmc\" Markov Chain Monte Carlo (Quasi-Bayesian) * Note methods never apply estimates simple slopes. report 95% CIs simple slopes Bootstrap Monte Carlo CIs, just standard CIs without resampling method. nsim Number simulation samples (bootstrap resampling Monte Carlo simulation) estimating SE 95% CI. Default 100 running examples faster. formal analyses, however, nsim=1000 (larger) strongly suggested! seed Random seed obtaining reproducible results. Default NULL. may set number prefer (e.g., seed=1234, just uncountable number). * Note mediation models include random processes (.e., bootstrap resampling Monte Carlo simulation). get exactly results runs, need set random seed. However, even set seed number, unlikely get exactly results across different R packages (e.g., lavaan vs. mediation) software (e.g., SPSS, Mplus, R, jamovi). center Centering numeric (continuous) predictors? Default TRUE (suggested). std Standardizing variables get standardized coefficients? Default FALSE. TRUE, standardize numeric (continuous) variables building regression models. However, suggested set std=TRUE generalized linear (mixed) models. digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc). Currently, regression model summary can saved.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"Invisibly return list results: process.id PROCESS model number. process.type PROCESS model type. model.m \"Mediator\" (M) models (list multiple models). model.y \"Outcome\" (Y) model. results Effect estimates results (unnamed list object).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"details illustrations, see PROCESS-bruceR-SPSS (PDF Markdown files).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"Hayes, . F. (2018). Introduction mediation, moderation, conditional process analysis (second edition): regression-based approach. Guilford Press. Yzerbyt, V., Muller, D., Batailler, C., & Judd, C. M. (2018). New recommendations testing indirect effects mediational models: need report test component paths. Journal Personality Social Psychology, 115(6), 929-943.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/PROCESS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PROCESS for mediation and/or moderation analyses. — PROCESS","text":"","code":"#### NOTE #### ## In the following examples, I set nsim=100 to save time. ## In formal analyses, nsim=1000 (or larger) is suggested!  #### Demo Data #### # ?mediation::student data = mediation::student %>%   dplyr::select(SCH_ID, free, smorale, pared, income,                 gender, work, attachment, fight, late, score) names(data)[2:3] = c(\"SCH_free\", \"SCH_morale\") names(data)[4:7] = c(\"parent_edu\", \"family_inc\", \"gender\", \"partjob\") data$gender01 = 1 - data$gender  # 0 = female, 1 = male # dichotomous X: as.factor() data$gender = factor(data$gender01, levels=0:1, labels=c(\"Female\", \"Male\")) # dichotomous Y: as.factor() data$pass = as.factor(ifelse(data$score>=50, 1, 0))  #### Descriptive Statistics and Correlation Analyses #### Freq(data$gender) #> Frequency Statistics: #> ───────────────── #>            N    % #> ───────────────── #> Female  5044 52.1 #> Male    4635 47.9 #> ───────────────── #> Total N = 9,679 Freq(data$pass) #> Frequency Statistics: #> ──────────── #>       N    % #> ──────────── #> 0  3856 39.8 #> 1  5823 60.2 #> ──────────── #> Total N = 9,679 Describe(data)     # file=\"xxx.doc\" #> Descriptive Statistics: #> ────────────────────────────────────────────────────────────────────── #>                N   Mean     SD | Median   Min    Max Skewness Kurtosis #> ────────────────────────────────────────────────────────────────────── #> SCH_ID      9679 285.50 164.45 | 285.00  1.00 568.00    -0.00    -1.21 #> SCH_free    9679   2.99   1.86 |   3.00  1.00   7.00     0.47    -0.97 #> SCH_morale  9679   4.02   0.75 |   4.00  2.00   5.00    -0.45    -0.08 #> parent_edu  9679   0.44   0.50 |   0.00  0.00   1.00     0.26    -1.93 #> family_inc  9679   9.26   2.34 |  10.00  1.00  16.00    -0.79     0.72 #> gender*     9679   1.48   0.50 |   1.00  1.00   2.00     0.08    -1.99 #> partjob     9679   0.39   0.49 |   0.00  0.00   1.00     0.47    -1.78 #> attachment  9679   0.89   0.32 |   1.00  0.00   1.00    -2.42     3.87 #> fight       9679   0.13   0.33 |   0.00  0.00   1.00     2.26     3.10 #> late        9679   2.24   1.13 |   2.00  1.00   5.00     0.90     0.29 #> score       9679  51.91   9.69 |  52.00 19.00  87.00    -0.11    -0.12 #> gender01    9679   0.48   0.50 |   0.00  0.00   1.00     0.08    -1.99 #> pass*       9679   1.60   0.49 |   2.00  1.00   2.00    -0.42    -1.83 #> ────────────────────────────────────────────────────────────────────── #>  #> NOTE: `gender`, `pass` transformed to numeric. Corr(data[,4:11])  # file=\"xxx.doc\" #> NOTE: `gender` transformed to numeric. #>   #> Correlation matrix is displayed in the RStudio `Plots` Pane. #>  #> Pearson's r and 95% confidence intervals: #> ────────────────────────────────────────────────────────── #>                            r       [95% CI]     p        N #> ────────────────────────────────────────────────────────── #> parent_edu-family_inc   0.38 [ 0.36,  0.40] <.001 *** 9679 #> parent_edu-gender       0.01 [-0.01,  0.03]  .320     9679 #> parent_edu-partjob     -0.02 [-0.04,  0.00]  .071 .   9679 #> parent_edu-attachment   0.03 [ 0.01,  0.05]  .012 *   9679 #> parent_edu-fight       -0.08 [-0.10, -0.06] <.001 *** 9679 #> parent_edu-late        -0.04 [-0.06, -0.02] <.001 *** 9679 #> parent_edu-score        0.28 [ 0.27,  0.30] <.001 *** 9679 #> family_inc-gender       0.03 [ 0.01,  0.05]  .008 **  9679 #> family_inc-partjob      0.02 [ 0.00,  0.04]  .044 *   9679 #> family_inc-attachment   0.00 [-0.02,  0.02]  .763     9679 #> family_inc-fight       -0.10 [-0.12, -0.08] <.001 *** 9679 #> family_inc-late        -0.07 [-0.09, -0.05] <.001 *** 9679 #> family_inc-score        0.33 [ 0.32,  0.35] <.001 *** 9679 #> gender-partjob          0.00 [-0.02,  0.02]  .842     9679 #> gender-attachment      -0.11 [-0.13, -0.09] <.001 *** 9679 #> gender-fight            0.18 [ 0.16,  0.20] <.001 *** 9679 #> gender-late             0.01 [-0.01,  0.03]  .582     9679 #> gender-score            0.08 [ 0.06,  0.10] <.001 *** 9679 #> partjob-attachment     -0.03 [-0.05, -0.01]  .001 **  9679 #> partjob-fight           0.06 [ 0.04,  0.08] <.001 *** 9679 #> partjob-late            0.04 [ 0.02,  0.06] <.001 *** 9679 #> partjob-score          -0.02 [-0.04, -0.00]  .047 *   9679 #> attachment-fight       -0.16 [-0.18, -0.14] <.001 *** 9679 #> attachment-late        -0.16 [-0.18, -0.14] <.001 *** 9679 #> attachment-score        0.06 [ 0.04,  0.08] <.001 *** 9679 #> fight-late              0.17 [ 0.15,  0.18] <.001 *** 9679 #> fight-score            -0.16 [-0.18, -0.14] <.001 *** 9679 #> late-score             -0.14 [-0.16, -0.12] <.001 *** 9679 #> ────────────────────────────────────────────────────────── #>   #### PROCESS Analyses ####  ## Model 1 ## PROCESS(data, y=\"score\", x=\"late\", mods=\"gender\")  # continuous Y #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : score #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    score ~ late*gender #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ─────────────────────────────────────────── #>                  (1) score     (2) score    #> ─────────────────────────────────────────── #> (Intercept)        51.912 ***    51.174 *** #>                    (0.098)       (0.135)    #> late               -1.174 ***    -0.947 *** #>                    (0.087)       (0.122)    #> genderMale                        1.545 *** #>                                  (0.195)    #> late:genderMale                  -0.462 **  #>                                  (0.173)    #> ─────────────────────────────────────────── #> R^2                 0.019         0.026     #> Adj. R^2            0.018         0.025     #> Num. obs.        9679          9679         #> ─────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"score\" (Y) #> ────────────────────────────────────── #>                   F df1  df2     p     #> ────────────────────────────────────── #> late * gender  7.14   1 9675  .008 **  #> ────────────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"score\" (Y) #> ─────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.       t     p             [95% CI] #> ─────────────────────────────────────────────────────────── #>  Female   -0.947 (0.122)  -7.772 <.001 *** [-1.186, -0.708] #>  Male     -1.409 (0.122) -11.513 <.001 *** [-1.649, -1.169] #> ─────────────────────────────────────────────────────────── #>  PROCESS(data, y=\"pass\", x=\"late\", mods=\"gender\")   # dichotomous Y #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : pass #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    pass ~ late*gender #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ────────────────────────────────────────────── #>                   (1) pass       (2) pass      #> ────────────────────────────────────────────── #> (Intercept)           0.418 ***      0.306 *** #>                      (0.021)        (0.029)    #> late                 -0.232 ***     -0.201 *** #>                      (0.019)        (0.026)    #> genderMale                           0.238 *** #>                                     (0.042)    #> late:genderMale                     -0.066     #>                                     (0.037)    #> ────────────────────────────────────────────── #> McFadden's R^2        0.012          0.015     #> Nagelkerke's R^2      0.022          0.027     #> AIC               12859.980      12829.489     #> BIC               12874.335      12858.200     #> Num. obs.          9679           9679         #> ────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"pass\" (Y) #> ───────────────────────────────── #>                Chisq df     p     #> ───────────────────────────────── #> late * gender   3.18  1  .075 .   #> ───────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"pass\" (Y) #> ─────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.       z     p             [95% CI] #> ─────────────────────────────────────────────────────────── #>  Female   -0.201 (0.026)  -7.769 <.001 *** [-0.252, -0.151] #>  Male     -0.268 (0.027) -10.082 <.001 *** [-0.320, -0.216] #> ─────────────────────────────────────────────────────────── #>   # (multilevel moderation) PROCESS(data, y=\"score\", x=\"late\", mods=\"gender\",  # continuous Y (LMM)         clusters=\"SCH_ID\") #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : score #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender #> - Covariates (C) : - #> -   HLM Clusters : SCH_ID #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    score ~ late*gender + (1 | SCH_ID) #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ───────────────────────────────────────────────────── #>                          (1) score      (2) score     #> ───────────────────────────────────────────────────── #> (Intercept)                 51.705 ***     50.986 *** #>                             (0.204)        (0.221)    #> late                        -0.932 ***     -0.763 *** #>                             (0.082)        (0.114)    #> genderMale                                  1.509 *** #>                                            (0.182)    #> late:genderMale                            -0.346 *   #>                                            (0.160)    #> ───────────────────────────────────────────────────── #> Marginal R^2                 0.012          0.018     #> Conditional R^2              0.209          0.214     #> AIC                      70092.182      70027.142     #> BIC                      70120.893      70070.208     #> Num. obs.                 9679           9679         #> Num. groups: SCH_ID        568            568         #> Var: SCH_ID (Intercept)     18.549         18.392     #> Var: Residual               74.298         73.764     #> ───────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"score\" (Y) #> ────────────────────────────────────── #>                   F df1  df2     p     #> ────────────────────────────────────── #> late * gender  4.70   1 9356  .030 *   #> ────────────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"score\" (Y) #> ────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.      t     p             [95% CI] #> ────────────────────────────────────────────────────────── #>  Female   -0.763 (0.114) -6.676 <.001 *** [-0.987, -0.539] #>  Male     -1.109 (0.114) -9.688 <.001 *** [-1.333, -0.885] #> ────────────────────────────────────────────────────────── #>  PROCESS(data, y=\"pass\", x=\"late\", mods=\"gender\",   # dichotomous Y (GLMM)         clusters=\"SCH_ID\") #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : pass #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender #> - Covariates (C) : - #> -   HLM Clusters : SCH_ID #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    pass ~ late*gender + (1 | SCH_ID) #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ───────────────────────────────────────────────────── #>                          (1) pass       (2) pass      #> ───────────────────────────────────────────────────── #> (Intercept)                  0.441 ***      0.314 *** #>                             (0.044)        (0.049)    #> late                        -0.224 ***     -0.202 *** #>                             (0.021)        (0.029)    #> genderMale                                  0.271 *** #>                                            (0.047)    #> late:genderMale                            -0.049     #>                                            (0.041)    #> ───────────────────────────────────────────────────── #> AIC                      12227.697      12197.299     #> BIC                      12249.231      12233.188     #> Num. obs.                 9679           9679         #> Num. groups: SCH_ID        568            568         #> Var: SCH_ID (Intercept)      0.754          0.756     #> ───────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"pass\" (Y) #> ───────────────────────────────── #>                Chisq df     p     #> ───────────────────────────────── #> late * gender   1.43  1  .232     #> ───────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"pass\" (Y) #> ────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.      z     p             [95% CI] #> ────────────────────────────────────────────────────────── #>  Female   -0.202 (0.029) -6.997 <.001 *** [-0.259, -0.145] #>  Male     -0.251 (0.029) -8.541 <.001 *** [-0.308, -0.193] #> ────────────────────────────────────────────────────────── #>   # (Johnson-Neyman (J-N) interval and plot) PROCESS(data, y=\"score\", x=\"gender\", mods=\"late\") -> P #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : score #> -  Predictor (X) : gender (recoded: Female=0, Male=1) #> -  Mediators (M) : - #> - Moderators (W) : late #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    score ~ gender*late #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ─────────────────────────────────────── #>              (1) score     (2) score    #> ─────────────────────────────────────── #> (Intercept)    51.912 ***    51.913 *** #>                (0.098)       (0.097)    #> gender          1.530 ***     1.545 *** #>                (0.196)       (0.195)    #> late                         -1.169 *** #>                              (0.086)    #> gender:late                  -0.462 **  #>                              (0.173)    #> ─────────────────────────────────────── #> R^2             0.006         0.026     #> Adj. R^2        0.006         0.025     #> Num. obs.    9679          9679         #> ─────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"score\" (Y) #> ────────────────────────────────────── #>                   F df1  df2     p     #> ────────────────────────────────────── #> gender * late  7.14   1 9675  .008 **  #> ────────────────────────────────────── #>  #> Simple Slopes: \"gender\" (X) ==> \"score\" (Y) #> ─────────────────────────────────────────────────────────── #>  \"late\"       Effect    S.E.     t     p           [95% CI] #> ─────────────────────────────────────────────────────────── #>  1.116 (- SD)  2.064 (0.275) 7.504 <.001 *** [1.525, 2.604] #>  2.242 (Mean)  1.545 (0.195) 7.938 <.001 *** [1.163, 1.926] #>  3.367 (+ SD)  1.025 (0.275) 3.727 <.001 *** [0.486, 1.564] #> ─────────────────────────────────────────────────────────── #>  P$results[[1]]$jn[[1]]       # Johnson-Neyman interval #> JOHNSON-NEYMAN INTERVAL  #>  #> When late is OUTSIDE the interval [4.03, 14.93], the slope of gender #> is p < .05. #>  #> Note: The range of observed values of late is [1.00, 5.00] #>  P$results[[1]]$jn[[1]]$plot  # Johnson-Neyman plot (ggplot object)  GLM_summary(P$model.y)       # detailed results of regression #>  #> General Linear Model (OLS Regression) #>  #> Model Fit: #> F(3, 9675) = 84.92, p = 3e-54 *** #> R² = 0.02566 (Adjusted R² = 0.02535) #>  #> Unstandardized Coefficients: #> Outcome Variable: score #> N = 9679 #> ──────────────────────────────────────────────────────────────────── #>                   b    S.E.       t     p        [95% CI of b]   VIF #> ──────────────────────────────────────────────────────────────────── #> (Intercept)  51.913 (0.097) 534.035 <.001 *** [51.723, 52.104]       #> gender        1.545 (0.195)   7.938 <.001 *** [ 1.163,  1.926] 1.000 #> late         -1.169 (0.086) -13.519 <.001 *** [-1.338, -0.999] 1.001 #> gender:late  -0.462 (0.173)  -2.673  .008 **  [-0.800, -0.123] 1.001 #> ──────────────────────────────────────────────────────────────────── #>  #> Standardized Coefficients (β): #> Outcome Variable: score #> N = 9679 #> ───────────────────────────────────────────────────────────────────────────────── #>                   β    S.E.       t     p        [95% CI of β] r(partial) r(part) #> ───────────────────────────────────────────────────────────────────────────────── #> gender        0.080 (0.010)   7.938 <.001 *** [ 0.060,  0.099]      0.080   0.080 #> late         -0.136 (0.010) -13.519 <.001 *** [-0.155, -0.116]     -0.136  -0.136 #> gender:late  -0.027 (0.010)  -2.673  .008 **  [-0.047, -0.007]     -0.027  -0.027 #> ───────────────────────────────────────────────────────────────────────────────── #>   # (allows multicategorical moderator) d = airquality d$Month = as.factor(d$Month)  # moderator: factor with levels \"5\"~\"9\" PROCESS(d, y=\"Temp\", x=\"Solar.R\", mods=\"Month\") #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 1 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Moderation #> -    Outcome (Y) : Temp #> -  Predictor (X) : Solar.R #> -  Mediators (M) : - #> - Moderators (W) : Month #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    Temp ~ Solar.R*Month #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ──────────────────────────────────────── #>                 (1) Temp     (2) Temp    #> ──────────────────────────────────────── #> (Intercept)      78.116 ***   66.012 *** #>                  (0.736)      (1.232)    #> Solar.R           0.028 ***    0.027 *   #>                  (0.008)      (0.011)    #> Month6                        12.967 *** #>                               (1.699)    #> Month7                        17.366 *** #>                               (1.742)    #> Month8                        18.235 *** #>                               (1.741)    #> Month9                        11.129 *** #>                               (1.721)    #> Solar.R:Month6                 0.002     #>                               (0.017)    #> Solar.R:Month7                -0.009     #>                               (0.018)    #> Solar.R:Month8                 0.009     #>                               (0.019)    #> Solar.R:Month9                -0.014     #>                               (0.019)    #> ──────────────────────────────────────── #> R^2               0.076        0.549     #> Adj. R^2          0.070        0.519     #> Num. obs.       146          146         #> ──────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Simple Moderation (Model 1) #> Sample Size : 146 (7 missing observations deleted) #> Random Seed : - #> Simulations : - #>  #> Interaction Effect on \"Temp\" (Y) #> ─────────────────────────────────────── #>                     F df1 df2     p     #> ─────────────────────────────────────── #> Solar.R * Month  0.36   4 136  .838     #> ─────────────────────────────────────── #>  #> Simple Slopes: \"Solar.R\" (X) ==> \"Temp\" (Y) #> ─────────────────────────────────────────────────────── #>  \"Month\" Effect    S.E.     t     p            [95% CI] #> ─────────────────────────────────────────────────────── #>  5        0.027 (0.011) 2.432  .016 *   [ 0.005, 0.048] #>  6        0.029 (0.013) 2.242  .027 *   [ 0.003, 0.054] #>  7        0.017 (0.014) 1.186  .238     [-0.011, 0.046] #>  8        0.035 (0.016) 2.202  .029 *   [ 0.004, 0.067] #>  9        0.013 (0.015) 0.865  .389     [-0.017, 0.043] #> ─────────────────────────────────────────────────────── #>   ## Model 2 ## PROCESS(data, y=\"score\", x=\"late\",         mods=c(\"gender\", \"family_inc\"),         mod.type=\"2-way\")  # or omit \"mod.type\", default is \"2-way\" #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 2 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Parallel Moderation (2 mods; 2-way) #> -    Outcome (Y) : score #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender, family_inc #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    score ~ late*gender + late*family_inc #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ─────────────────────────────────────────── #>                  (1) score     (2) score    #> ─────────────────────────────────────────── #> (Intercept)        51.912 ***    51.255 *** #>                    (0.098)       (0.127)    #> late               -1.174 ***    -0.836 *** #>                    (0.087)       (0.115)    #> genderMale                        1.375 *** #>                                  (0.184)    #> family_inc                        1.339 *** #>                                  (0.040)    #> late:genderMale                  -0.301     #>                                  (0.163)    #> late:family_inc                   0.007     #>                                  (0.034)    #> ─────────────────────────────────────────── #> R^2                 0.019         0.129     #> Adj. R^2            0.018         0.129     #> Num. obs.        9679          9679         #> ─────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Parallel Moderation (2 mods; 2-way) (Model 2) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effects on \"score\" (Y) #> ─────────────────────────────────────────── #>                        F df1  df2     p     #> ─────────────────────────────────────────── #> late * gender       3.40   1 9673  .065 .   #> late * family_inc   0.04   1 9673  .849     #> (All Interactions)  1.72   2 9673  .179     #> ─────────────────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"score\" (Y) #> ──────────────────────────────────────────────────────────────────────── #>  \"family_inc\"  \"gender\" Effect    S.E.      t     p             [95% CI] #> ──────────────────────────────────────────────────────────────────────── #>  6.923 (- SD)  Female   -0.851 (0.137) -6.219 <.001 *** [-1.119, -0.583] #>  6.923 (- SD)  Male     -1.152 (0.138) -8.369 <.001 *** [-1.422, -0.882] #>  9.258 (Mean)  Female   -0.836 (0.115) -7.238 <.001 *** [-1.062, -0.609] #>  9.258 (Mean)  Male     -1.137 (0.116) -9.792 <.001 *** [-1.365, -0.909] #>  11.594 (+ SD) Female   -0.820 (0.144) -5.699 <.001 *** [-1.103, -0.538] #>  11.594 (+ SD) Male     -1.122 (0.144) -7.778 <.001 *** [-1.405, -0.839] #> ──────────────────────────────────────────────────────────────────────── #>   ## Model 3 ## PROCESS(data, y=\"score\", x=\"late\",         mods=c(\"gender\", \"family_inc\"),         mod.type=\"3-way\") #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 3 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Moderated Moderation (2 mods; 3-way) #> -    Outcome (Y) : score #> -  Predictor (X) : late #> -  Mediators (M) : - #> - Moderators (W) : gender, family_inc #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    score ~ late*gender*family_inc #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ────────────────────────────────────────────────────── #>                             (1) score     (2) score    #> ────────────────────────────────────────────────────── #> (Intercept)                   51.912 ***    51.266 *** #>                               (0.098)       (0.127)    #> late                          -1.174 ***    -0.818 *** #>                               (0.087)       (0.116)    #> genderMale                                   1.348 *** #>                                             (0.185)    #> family_inc                                   1.375 *** #>                                             (0.055)    #> late:genderMale                             -0.339 *   #>                                             (0.164)    #> late:family_inc                              0.088     #>                                             (0.050)    #> genderMale:family_inc                       -0.069     #>                                             (0.079)    #> late:genderMale:family_inc                  -0.153 *   #>                                             (0.069)    #> ────────────────────────────────────────────────────── #> R^2                            0.019         0.130     #> Adj. R^2                       0.018         0.129     #> Num. obs.                   9679          9679         #> ────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Moderated Moderation (2 mods; 3-way) (Model 3) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effects on \"score\" (Y) #> ─────────────────────────────────────────────────── #>                                F df1  df2     p     #> ─────────────────────────────────────────────────── #> late * gender               4.26   1 9671  .039 *   #> late * family_inc           3.11   1 9671  .078 .   #> gender * family_inc         0.75   1 9671  .386     #> late * gender * family_inc  4.95   1 9671  .026 *   #> (All Interactions)          2.33   4 9671  .054 .   #> ─────────────────────────────────────────────────── #>  #> Conditional Interaction Effects on \"score\" (Y) #> ──────────────────────────────────────────────────── #>  \"family_inc\"    Interaction    F df1  df2     p     #> ──────────────────────────────────────────────────── #>  6.923 (- SD)  late * gender 0.01   1 9671  .938     #>  9.258 (Mean)  late * gender 4.26   1 9671  .039 *   #>  11.594 (+ SD) late * gender 8.56   1 9671  .003 **  #> ──────────────────────────────────────────────────── #>  #> Simple Slopes: \"late\" (X) ==> \"score\" (Y) #> ──────────────────────────────────────────────────────────────────────── #>  \"family_inc\"  \"gender\" Effect    S.E.      t     p             [95% CI] #> ──────────────────────────────────────────────────────────────────────── #>  6.923 (- SD)  Female   -1.022 (0.157) -6.506 <.001 *** [-1.330, -0.714] #>  6.923 (- SD)  Male     -1.005 (0.155) -6.470 <.001 *** [-1.309, -0.700] #>  9.258 (Mean)  Female   -0.818 (0.116) -7.068 <.001 *** [-1.044, -0.591] #>  9.258 (Mean)  Male     -1.157 (0.117) -9.927 <.001 *** [-1.385, -0.928] #>  11.594 (+ SD) Female   -0.613 (0.170) -3.604 <.001 *** [-0.947, -0.280] #>  11.594 (+ SD) Male     -1.308 (0.166) -7.894 <.001 *** [-1.633, -0.983] #> ──────────────────────────────────────────────────────────────────────── #>  PROCESS(data, y=\"pass\", x=\"gender\",         mods=c(\"late\", \"family_inc\"),         mod1.val=c(1, 3, 5),     # moderator 1: late         mod2.val=seq(1, 15, 2),  # moderator 2: family_inc         mod.type=\"3-way\") #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 3 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Moderated Moderation (2 mods; 3-way) #> -    Outcome (Y) : pass #> -  Predictor (X) : gender (recoded: Female=0, Male=1) #> -  Mediators (M) : - #> - Moderators (W) : late, family_inc #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Outcome: #> -    pass ~ gender*late*family_inc #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ──────────────────────────────────────────────────── #>                         (1) pass       (2) pass      #> ──────────────────────────────────────────────────── #> (Intercept)                 0.414 ***      0.442 *** #>                            (0.021)        (0.022)    #> gender                      0.228 ***      0.219 *** #>                            (0.042)        (0.044)    #> late                                      -0.216 *** #>                                           (0.019)    #> family_inc                                 0.259 *** #>                                           (0.010)    #> gender:late                               -0.046     #>                                           (0.039)    #> gender:family_inc                         -0.022     #>                                           (0.020)    #> late:family_inc                            0.005     #>                                           (0.009)    #> gender:late:family_inc                    -0.032     #>                                           (0.018)    #> ──────────────────────────────────────────────────── #> McFadden's R^2              0.002          0.073     #> Nagelkerke's R^2            0.004          0.127     #> AIC                     12989.483      12080.387     #> BIC                     13003.839      12137.809     #> Num. obs.                9679           9679         #> ──────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘interactions’ (v1.1.5) #> Effect Type : Moderated Moderation (2 mods; 3-way) (Model 3) #> Sample Size : 9679 #> Random Seed : - #> Simulations : - #>  #> Interaction Effects on \"pass\" (Y) #> ────────────────────────────────────────────── #>                             Chisq df     p     #> ────────────────────────────────────────────── #> gender * late                1.43  1  .231     #> gender * family_inc          1.17  1  .279     #> late * family_inc            0.32  1  .573     #> gender * late * family_inc   3.18  1  .075 .   #> (All Interactions)           5.72  4  .221     #> ────────────────────────────────────────────── #>  #> Conditional Interaction Effects on \"pass\" (Y) #> ────────────────────────────────────────────── #>  \"family_inc\"   Interaction Chisq df     p     #> ────────────────────────────────────────────── #>  1.000        gender * late  2.08  1  .149     #>  3.000        gender * late  1.73  1  .188     #>  5.000        gender * late  1.15  1  .285     #>  7.000        gender * late  0.22  1  .642     #>  9.000        gender * late  0.97  1  .323     #>  11.000       gender * late  3.93  1  .047 *   #>  13.000       gender * late  4.34  1  .037 *   #>  15.000       gender * late  4.19  1  .041 *   #> ────────────────────────────────────────────── #>  #> Simple Slopes: \"gender\" (X) ==> \"pass\" (Y) #> ──────────────────────────────────────────────────────────────────── #>  \"family_inc\" \"late\" Effect    S.E.      z     p            [95% CI] #> ──────────────────────────────────────────────────────────────────── #>  1.000        1.000   0.131 (0.253)  0.518  .605     [-0.365, 0.627] #>  1.000        3.000   0.561 (0.201)  2.795  .005 **  [ 0.168, 0.954] #>  1.000        5.000   0.991 (0.441)  2.247  .025 *   [ 0.127, 1.855] #>  3.000        1.000   0.166 (0.196)  0.850  .395     [-0.217, 0.550] #>  3.000        3.000   0.470 (0.155)  3.029  .002 **  [ 0.166, 0.774] #>  3.000        5.000   0.773 (0.341)  2.270  .023 *   [ 0.106, 1.440] #>  5.000        1.000   0.202 (0.141)  1.435  .151     [-0.074, 0.477] #>  5.000        3.000   0.378 (0.111)  3.402 <.001 *** [ 0.160, 0.596] #>  5.000        5.000   0.555 (0.244)  2.275  .023 *   [ 0.077, 1.033] #>  7.000        1.000   0.237 (0.092)  2.576  .010 **  [ 0.057, 0.418] #>  7.000        3.000   0.287 (0.072)  3.962 <.001 *** [ 0.145, 0.429] #>  7.000        5.000   0.337 (0.159)  2.124  .034 *   [ 0.026, 0.649] #>  9.000        1.000   0.272 (0.066)  4.109 <.001 *** [ 0.143, 0.402] #>  9.000        3.000   0.196 (0.052)  3.775 <.001 *** [ 0.094, 0.298] #>  9.000        5.000   0.120 (0.114)  1.049  .294     [-0.104, 0.343] #>  11.000       1.000   0.308 (0.087)  3.544 <.001 *** [ 0.138, 0.478] #>  11.000       3.000   0.105 (0.069)  1.529  .126     [-0.030, 0.239] #>  11.000       5.000  -0.098 (0.151) -0.650  .515     [-0.395, 0.198] #>  13.000       1.000   0.343 (0.134)  2.564  .010 *   [ 0.081, 0.606] #>  13.000       3.000   0.014 (0.106)  0.128  .898     [-0.194, 0.221] #>  13.000       5.000  -0.316 (0.234) -1.351  .177     [-0.775, 0.143] #>  15.000       1.000   0.379 (0.188)  2.009  .045 *   [ 0.009, 0.748] #>  15.000       3.000  -0.078 (0.150) -0.520  .603     [-0.371, 0.215] #>  15.000       5.000  -0.534 (0.330) -1.619  .105     [-1.181, 0.113] #> ──────────────────────────────────────────────────────────────────── #>   ## Model 4 ## PROCESS(data, y=\"score\", x=\"parent_edu\",         meds=\"family_inc\", covs=\"gender\",         ci=\"boot\", nsim=100, seed=1) #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 4 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Mediation #> -    Outcome (Y) : score #> -  Predictor (X) : parent_edu #> -  Mediators (M) : family_inc #> - Moderators (W) : - #> - Covariates (C) : gender #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Mediator: #> -    family_inc ~ gender + parent_edu #> Formula of Outcome: #> -    score ~ gender + parent_edu + family_inc #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ─────────────────────────────────────────────────────── #>              (1) score     (2) family_inc  (3) score    #> ─────────────────────────────────────────────────────── #> (Intercept)    51.206 ***     9.207 ***      51.262 *** #>                (0.130)       (0.030)         (0.126)    #> genderMale      1.474 ***     0.108 *         1.358 *** #>                (0.188)       (0.044)         (0.182)    #> parent_edu      5.537 ***     1.793 ***       3.594 *** #>                (0.190)       (0.044)         (0.199)    #> family_inc                                    1.083 *** #>                                              (0.042)    #> ─────────────────────────────────────────────────────── #> R^2             0.087         0.146           0.145     #> Adj. R^2        0.086         0.146           0.145     #> Num. obs.    9679          9679            9679         #> ─────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘mediation’ (v4.5.0) #> Effect Type : Simple Mediation (Model 4) #> Sample Size : 9679 #> Random Seed : set.seed(1) #> Simulations : 100 (Bootstrap) #>  #> Warning: nsim=1000 (or larger) is suggested! #>  #> Running 100 simulations... #> Indirect Path: \"parent_edu\" (X) ==> \"family_inc\" (M) ==> \"score\" (Y) #> ───────────────────────────────────────────────────────────── #>                Effect    S.E.      z     p      [Boot 95% CI] #> ───────────────────────────────────────────────────────────── #> Indirect (ab)   1.943 (0.089) 21.759 <.001 *** [1.752, 2.095] #> Direct (c')     3.594 (0.220) 16.319 <.001 *** [3.155, 3.981] #> Total (c)       5.537 (0.203) 27.249 <.001 *** [5.084, 5.898] #> ───────────────────────────────────────────────────────────── #> Percentile Bootstrap Confidence Interval #> (SE and CI are estimated based on 100 Bootstrap samples.) #>  #> Note. The results based on bootstrapping or other random processes #> are unlikely identical to other statistical software (e.g., SPSS). #> To make results reproducible, you need to set a seed (any number). #> Please see the help page for details: help(PROCESS) #> Ignore this note if you have already set a seed. :) #>   # (allows an infinite number of multiple mediators in parallel) PROCESS(data, y=\"score\", x=\"parent_edu\",         meds=c(\"family_inc\", \"late\"),         covs=c(\"gender\", \"partjob\"),         ci=\"boot\", nsim=100, seed=1) #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 4 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Parallel Multiple Mediation (2 meds) #> -    Outcome (Y) : score #> -  Predictor (X) : parent_edu #> -  Mediators (M) : family_inc, late #> - Moderators (W) : - #> - Covariates (C) : gender, partjob #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Mediator: #> -    family_inc ~ gender + partjob + parent_edu #> -    late ~ gender + partjob + parent_edu #> Formula of Outcome: #> -    score ~ gender + partjob + parent_edu + family_inc + late #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ───────────────────────────────────────────────────────────────────── #>              (1) score     (2) family_inc  (3) late      (4) score    #> ───────────────────────────────────────────────────────────────────── #> (Intercept)    51.206 ***     9.207 ***       2.235 ***    51.254 *** #>                (0.130)       (0.030)         (0.016)       (0.125)    #> genderMale      1.475 ***     0.107 *         0.013         1.374 *** #>                (0.188)       (0.044)         (0.023)       (0.181)    #> partjob        -0.301         0.132 **        0.091 ***    -0.353     #>                (0.193)       (0.045)         (0.023)       (0.186)    #> parent_edu      5.531 ***     1.796 ***      -0.092 ***     3.545 *** #>                (0.190)       (0.044)         (0.023)       (0.197)    #> family_inc                                                  1.057 *** #>                                                            (0.042)    #> late                                                       -0.957 *** #>                                                            (0.081)    #> ───────────────────────────────────────────────────────────────────── #> R^2             0.087         0.146           0.003         0.158     #> Adj. R^2        0.087         0.146           0.003         0.157     #> Num. obs.    9679          9679            9679          9679         #> ───────────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘mediation’ (v4.5.0) #> Effect Type : Parallel Multiple Mediation (2 meds) (Model 4) #> Sample Size : 9679 #> Random Seed : set.seed(1) #> Simulations : 100 (Bootstrap) #>  #> Warning: nsim=1000 (or larger) is suggested! #>  #> Running 100 simulations... #> Indirect Path: \"parent_edu\" (X) ==> \"family_inc\" (M) ==> \"score\" (Y) #> ───────────────────────────────────────────────────────────── #>                Effect    S.E.      z     p      [Boot 95% CI] #> ───────────────────────────────────────────────────────────── #> Indirect (ab)   1.898 (0.089) 21.262 <.001 *** [1.711, 2.055] #> Direct (c')     3.545 (0.218) 16.280 <.001 *** [3.089, 3.937] #> ───────────────────────────────────────────────────────────── #> Percentile Bootstrap Confidence Interval #> (SE and CI are estimated based on 100 Bootstrap samples.) #>  #> Running 100 simulations... #> Indirect Path: \"parent_edu\" (X) ==> \"late\" (M) ==> \"score\" (Y) #> ───────────────────────────────────────────────────────────── #>                Effect    S.E.      z     p      [Boot 95% CI] #> ───────────────────────────────────────────────────────────── #> Indirect (ab)   0.088 (0.022)  3.946 <.001 *** [0.054, 0.136] #> Direct (c')     3.545 (0.218) 16.280 <.001 *** [3.089, 3.937] #> ───────────────────────────────────────────────────────────── #> Percentile Bootstrap Confidence Interval #> (SE and CI are estimated based on 100 Bootstrap samples.) #>  #> Note. The results based on bootstrapping or other random processes #> are unlikely identical to other statistical software (e.g., SPSS). #> To make results reproducible, you need to set a seed (any number). #> Please see the help page for details: help(PROCESS) #> Ignore this note if you have already set a seed. :) #>   # (multilevel mediation) PROCESS(data, y=\"score\", x=\"SCH_free\",         meds=\"late\", clusters=\"SCH_ID\",         ci=\"mcmc\", nsim=100, seed=1) #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 4 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Simple Mediation #> -    Outcome (Y) : score #> -  Predictor (X) : SCH_free #> -  Mediators (M) : late #> - Moderators (W) : - #> - Covariates (C) : - #> -   HLM Clusters : SCH_ID #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Mediator: #> -    late ~ SCH_free + (1 | SCH_ID) #> Formula of Outcome: #> -    score ~ SCH_free + late + (1 | SCH_ID) #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ──────────────────────────────────────────────────────────────────── #>                          (1) score      (2) late       (3) score     #> ──────────────────────────────────────────────────────────────────── #> (Intercept)                 51.853 ***      2.245 ***     51.858 *** #>                             (0.162)        (0.017)        (0.159)    #> SCH_free                    -1.611 ***      0.049 ***     -1.566 *** #>                             (0.085)        (0.009)        (0.084)    #> late                                                      -0.902 *** #>                                                           (0.082)    #> ──────────────────────────────────────────────────────────────────── #> Marginal R^2                 0.095          0.007          0.106     #> Conditional R^2              0.201          0.073          0.208     #> AIC                      69944.810      29498.368      69828.530     #> BIC                      69973.521      29527.079      69864.419     #> Num. obs.                 9679           9679           9679         #> Num. groups: SCH_ID        568            568            568         #> Var: SCH_ID (Intercept)      9.935          0.084          9.592     #> Var: Residual               75.201          1.176         74.339     #> ──────────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘mediation’ (v4.5.0) #> Effect Type : Simple Mediation (Model 4) #> Sample Size : 9679 #> Random Seed : set.seed(1) #> Simulations : 100 (Monte Carlo) #>  #> Warning: nsim=1000 (or larger) is suggested! #>  #> Running 100 simulations... #> Indirect Path: \"SCH_free\" (X) ==> \"late\" (M) ==> \"score\" (Y) #> ──────────────────────────────────────────────────────────────── #>                Effect    S.E.       z     p        [MCMC 95% CI] #> ──────────────────────────────────────────────────────────────── #> Indirect (ab)  -0.044 (0.009)  -5.155 <.001 *** [-0.061, -0.030] #> Direct (c')    -1.573 (0.078) -20.230 <.001 *** [-1.720, -1.440] #> Total (c)      -1.618 (0.078) -20.624 <.001 *** [-1.769, -1.480] #> ──────────────────────────────────────────────────────────────── #> Monte Carlo (Quasi-Bayesian) Confidence Interval #> (Effect, SE, and CI are estimated based on 100 Monte Carlo samples.) #>  #> Note. The results based on bootstrapping or other random processes #> are unlikely identical to other statistical software (e.g., SPSS). #> To make results reproducible, you need to set a seed (any number). #> Please see the help page for details: help(PROCESS) #> Ignore this note if you have already set a seed. :) #>   ## Model 6 ## PROCESS(data, y=\"score\", x=\"parent_edu\",         meds=c(\"family_inc\", \"late\"),         covs=c(\"gender\", \"partjob\"),         med.type=\"serial\",         ci=\"boot\", nsim=100, seed=1) #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 6 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Serial Multiple Mediation (2 meds) #> -    Outcome (Y) : score #> -  Predictor (X) : parent_edu #> -  Mediators (M) : family_inc, late #> - Moderators (W) : - #> - Covariates (C) : gender, partjob #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Mediator: #> -    family_inc ~ gender + partjob + parent_edu #> -    late ~ gender + partjob + parent_edu + family_inc #> Formula of Outcome: #> -    score ~ gender + partjob + parent_edu + family_inc + late #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ───────────────────────────────────────────────────────────────────── #>              (1) score     (2) family_inc  (3) late      (4) score    #> ───────────────────────────────────────────────────────────────────── #> (Intercept)    51.206 ***     9.207 ***       2.516 ***    51.254 *** #>                (0.130)       (0.030)         (0.051)       (0.125)    #> genderMale      1.475 ***     0.107 *         0.017         1.374 *** #>                (0.188)       (0.044)         (0.023)       (0.181)    #> partjob        -0.301         0.132 **        0.096 ***    -0.353     #>                (0.193)       (0.045)         (0.023)       (0.186)    #> parent_edu      5.531 ***     1.796 ***      -0.037         3.545 *** #>                (0.190)       (0.044)         (0.025)       (0.197)    #> family_inc                                   -0.030 ***     1.057 *** #>                                              (0.005)       (0.042)    #> late                                                       -0.957 *** #>                                                            (0.081)    #> ───────────────────────────────────────────────────────────────────── #> R^2             0.087         0.146           0.007         0.158     #> Adj. R^2        0.087         0.146           0.006         0.157     #> Num. obs.    9679          9679            9679          9679         #> ───────────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘lavaan’ (v0.6.11) #> Effect Type : Serial Multiple Mediation (2 meds) (Model 6) #> Sample Size : 9679 #> Random Seed : set.seed(1) #> Simulations : 100 (Bootstrap) #>  #> Warning: nsim=1000 (or larger) is suggested! #>  #> Running 100 simulations (lavaan model)... #> LAVAAN Syntax: #> family_inc ~ gender + partjob + a1*parent_edu #> late ~ gender + partjob + a2*parent_edu + d12*family_inc #> score ~ gender + partjob + c.*parent_edu + b1*family_inc + b2*late #> Indirect_All := a1*b1 + a2*b2 + a1*d12*b2 #> Ind_X_M1_Y := a1*b1 #> Ind_X_M2_Y := a2*b2 #> Ind_X_M1_M2_Y := a1*d12*b2 #> Direct := c. #> Total := c. + a1*b1 + a2*b2 + a1*d12*b2 #> ──────────────────────────────────────────────────────────────────────── #>                  Estimate    S.E.      z     p       [Boot 95% CI]  Beta #> ──────────────────────────────────────────────────────────────────────── #>   Indirect_All      1.986 (0.098) 20.178 <.001 *** [ 1.763, 2.167] 0.102 #>   Ind_X_M1_Y        1.898 (0.091) 20.938 <.001 *** [ 1.692, 2.071] 0.097 #>   Ind_X_M2_Y        0.036 (0.028)  1.284  .199     [-0.011, 0.100] 0.002 #>   Ind_X_M1_M2_Y     0.052 (0.011)  4.890 <.001 *** [ 0.031, 0.071] 0.003 #>   Direct            3.545 (0.209) 16.968 <.001 *** [ 3.155, 3.933] 0.182 #>   Total             5.531 (0.202) 27.377 <.001 *** [ 5.164, 5.933] 0.283 #> ──────────────────────────────────────────────────────────────────────── #> Percentile Bootstrap Confidence Interval #> (SE and CI are estimated based on 100 Bootstrap samples.) #>  #> Note. The results based on bootstrapping or other random processes #> are unlikely identical to other statistical software (e.g., SPSS). #> To make results reproducible, you need to set a seed (any number). #> Please see the help page for details: help(PROCESS) #> Ignore this note if you have already set a seed. :) #>   ## Model 8 ## PROCESS(data, y=\"score\", x=\"fight\",         meds=\"late\",         mods=\"gender\",         mod.path=c(\"x-m\", \"x-y\"),         ci=\"boot\", nsim=100, seed=1) #>  #> ****************** PART 1. Regression Model Summary ****************** #>  #> PROCESS Model Code : 8 (Hayes, 2018; www.guilford.com/p/hayes3) #> PROCESS Model Type : Moderated Mediation #> -    Outcome (Y) : score #> -  Predictor (X) : fight #> -  Mediators (M) : late #> - Moderators (W) : gender #> - Covariates (C) : - #> -   HLM Clusters : - #>  #> All numeric predictors have been grand-mean centered. #> (For details, please see the help page of PROCESS.) #>  #> Formula of Mediator: #> -    late ~ fight*gender #> Formula of Outcome: #> -    score ~ fight*gender + late #>  #> CAUTION: #>   Fixed effect (coef.) of a predictor involved in an interaction #>   denotes its \"simple effect/slope\" at the other predictor = 0. #>   Only when all predictors in an interaction are mean-centered #>   can the fixed effect denote the \"main effect\"! #>    #> Model Summary #>  #> ────────────────────────────────────────────────────────── #>                   (1) score     (2) late      (3) score    #> ────────────────────────────────────────────────────────── #> (Intercept)         51.912 ***     2.272 ***    50.824 *** #>                     (0.097)       (0.016)       (0.136)    #> fight               -4.585 ***     0.646 ***    -6.188 *** #>                     (0.293)       (0.062)       (0.527)    #> genderMale                        -0.057 *       2.129 *** #>                                   (0.023)       (0.196)    #> fight:genderMale                  -0.103         2.305 *** #>                                   (0.074)       (0.633)    #> late                                            -0.950 *** #>                                                 (0.087)    #> ────────────────────────────────────────────────────────── #> R^2                  0.025         0.028         0.050     #> Adj. R^2             0.025         0.028         0.049     #> Num. obs.         9679          9679          9679         #> ────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> ************ PART 2. Mediation/Moderation Effect Estimate ************ #>  #> Package Use : ‘mediation’ (v4.5.0), ‘interactions’ (v1.1.5) #> Effect Type : Moderated Mediation (Model 8) #> Sample Size : 9679 #> Random Seed : set.seed(1) #> Simulations : 100 (Bootstrap) #>  #> Warning: nsim=1000 (or larger) is suggested! #>  #> Interaction Effect on \"score\" (Y) #> ──────────────────────────────────────── #>                     F df1  df2     p     #> ──────────────────────────────────────── #> fight * gender  13.24   1 9674 <.001 *** #> ──────────────────────────────────────── #>  #> Simple Slopes: \"fight\" (X) ==> \"score\" (Y) #> (Conditional Direct Effects [c'] of X on Y) #> ─────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.       t     p             [95% CI] #> ─────────────────────────────────────────────────────────── #>  Female   -6.188 (0.527) -11.742 <.001 *** [-7.221, -5.155] #>  Male     -3.883 (0.359) -10.821 <.001 *** [-4.587, -3.180] #> ─────────────────────────────────────────────────────────── #>  #> Interaction Effect on \"late\" (M) #> ─────────────────────────────────────── #>                    F df1  df2     p     #> ─────────────────────────────────────── #> fight * gender  1.90   1 9675  .168     #> ─────────────────────────────────────── #>  #> Simple Slopes: \"fight\" (X) ==> \"late\" (M) #> (Conditional Effects [a] of X on M) #> ──────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.      t     p           [95% CI] #> ──────────────────────────────────────────────────────── #>  Female    0.646 (0.062) 10.485 <.001 *** [0.525, 0.766] #>  Male      0.543 (0.042) 12.989 <.001 *** [0.461, 0.625] #> ──────────────────────────────────────────────────────── #>  #> Running 100 * 2 simulations... #> Indirect Path: \"fight\" (X) ==> \"late\" (M) ==> \"score\" (Y) #> (Conditional Indirect Effects [ab] of X through M on Y) #> ────────────────────────────────────────────────────────── #>  \"gender\" Effect    S.E.      z     p        [Boot 95% CI] #> ────────────────────────────────────────────────────────── #>  Female   -0.614 (0.086) -7.117 <.001 *** [-0.807, -0.477] #>  Male     -0.516 (0.060) -8.538 <.001 *** [-0.645, -0.411] #> ────────────────────────────────────────────────────────── #> Percentile Bootstrap Confidence Interval #> (SE and CI are estimated based on 100 Bootstrap samples.) #>  #> Note. The results based on bootstrapping or other random processes #> are unlikely identical to other statistical software (e.g., SPSS). #> To make results reproducible, you need to set a seed (any number). #> Please see the help page for details: help(PROCESS) #> Ignore this note if you have already set a seed. :) #>   ## For more examples and details, see the \"note\" subfolder at: ## https://github.com/psychbruce/bruceR/tree/main/note"},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print strings with rich formats and colors. — Print","title":"Print strings with rich formats and colors. — Print","text":"frustrated print() cat()? Try Print()! Run examples see can .","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print strings with rich formats and colors. — Print","text":"","code":"Print(...)  Glue(...)"},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print strings with rich formats and colors. — Print","text":"... Character strings enclosed \"{ }\" evaluated R code. Character strings enclosed \"<< >>\" printed formatted colored text. Long strings broken line concatenated together. Leading whitespace blank lines first last lines automatically trimmed.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print strings with rich formats and colors. — Print","text":"Formatted text.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print strings with rich formats and colors. — Print","text":"Possible formats/colors can used \"<< >>\" include: (1) bold, italic, underline, reset, blurred, inverse, hidden, strikethrough; (2) black, white, silver, red, green, blue, yellow, cyan, magenta; (3) bgBlack, bgWhite, bgRed, bgGreen, bgBlue, bgYellow, bgCyan, bgMagenta. See details glue::glue() glue::glue_col().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Print strings with rich formats and colors. — Print","text":"Print: Paste print strings. Glue: Paste strings.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Print.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print strings with rich formats and colors. — Print","text":"","code":"name = \"Bruce\" Print(\"My name is <<underline <<bold {name}>>>>.        <<bold <<blue Pi = {pi:.15}.>>>>        <<italic <<green 1 + 1 = {1 + 1}.>>>>        sqrt({x}) = <<red {sqrt(x):.3}>>\", x=10) #> My name is Bruce. #> Pi = 3.141592653589793. #> 1 + 1 = 2. #> sqrt(10) = 3.162"},{"path":"https://psychbruce.github.io/bruceR/reference/RECODE.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode a variable. — RECODE","title":"Recode a variable. — RECODE","text":"wrapper car::recode().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RECODE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode a variable. — RECODE","text":"","code":"RECODE(var, recodes)"},{"path":"https://psychbruce.github.io/bruceR/reference/RECODE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode a variable. — RECODE","text":"var Variable (numeric, character, factor). recodes character string definine rule recoding. e.g., \"lo:1=0; c(2,3)=1; 4=2; 5:hi=3; else=999\"","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RECODE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode a variable. — RECODE","text":"vector recoded variable.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RECODE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode a variable. — RECODE","text":"","code":"d = data.table(var=c(NA, 0, 1, 2, 3, 4, 5, 6)) added(d, {   var.new = RECODE(var, \"lo:1=0; c(2,3)=1; 4=2; 5:hi=3; else=999\") }) #> √ Raw data has already been changed. Please check. d #>    var var.new #> 1:  NA     999 #> 2:   0       0 #> 3:   1       0 #> 4:   2       1 #> 5:   3       1 #> 6:   4       2 #> 7:   5       3 #> 8:   6       3"},{"path":"https://psychbruce.github.io/bruceR/reference/RESCALE.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","title":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","text":"Rescale variable (e.g., 5-point 7-point).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RESCALE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","text":"","code":"RESCALE(var, from = range(var, na.rm = T), to)"},{"path":"https://psychbruce.github.io/bruceR/reference/RESCALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","text":"var Variable (numeric). Numeric vector, range old scale (e.g., 1:5). defined, compute range var. Numeric vector, range new scale (e.g., 1:7).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RESCALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","text":"vector rescaled variable.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RESCALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale a variable (e.g., from 5-point to 7-point). — RESCALE","text":"","code":"d = data.table(var=rep(1:5, 2)) added(d, {   var1 = RESCALE(var, to=1:7)   var2 = RESCALE(var, from=1:5, to=1:7) }) #> √ Raw data has already been changed. Please check. d  # var1 is equal to var2 #>     var var1 var2 #>  1:   1  1.0  1.0 #>  2:   2  2.5  2.5 #>  3:   3  4.0  4.0 #>  4:   4  5.5  5.5 #>  5:   5  7.0  7.0 #>  6:   1  1.0  1.0 #>  7:   2  2.5  2.5 #>  8:   3  4.0  4.0 #>  9:   4  5.5  5.5 #> 10:   5  7.0  7.0"},{"path":"https://psychbruce.github.io/bruceR/reference/RGB.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple extension of rgb(). — RGB","title":"A simple extension of rgb(). — RGB","text":"simple extension rgb().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RGB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple extension of rgb(). — RGB","text":"","code":"RGB(r, g, b, alpha)"},{"path":"https://psychbruce.github.io/bruceR/reference/RGB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple extension of rgb(). — RGB","text":"r, g, b Red, Green, Blue: 0~255. alpha Color transparency (opacity): 0~1. specified, opaque color generated.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RGB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple extension of rgb(). — RGB","text":"\"#rrggbb\" \"#rrggbbaa\".","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/RGB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple extension of rgb(). — RGB","text":"","code":"RGB(255, 0, 0)  # red: \"#FF0000\" #> [1] \"#FF0000\" RGB(255, 0, 0, 0.8)  # red with 80\\% opacity: \"#FF0000CC\" #> [1] \"#FF0000CC\""},{"path":"https://psychbruce.github.io/bruceR/reference/Run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run code parsed from text. — Run","title":"Run code parsed from text. — Run","text":"Run code parsed text.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run code parsed from text. — Run","text":"","code":"Run(..., silent = FALSE)"},{"path":"https://psychbruce.github.io/bruceR/reference/Run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run code parsed from text. — Run","text":"... Character string(s) run. can use \"{ }\" insert R object environment. silent Suppress error/warning messages. Default FALSE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run code parsed from text. — Run","text":"Invisibly return running expression(s).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/Run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run code parsed from text. — Run","text":"","code":"Run(\"a=1\", \"b=2\") Run(\"print({a+b})\") #> [1] 3"},{"path":"https://psychbruce.github.io/bruceR/reference/TTEST.html","id":null,"dir":"Reference","previous_headings":"","what":"One-sample, independent-samples, and paired-samples t-test. — TTEST","title":"One-sample, independent-samples, and paired-samples t-test. — TTEST","text":"One-sample, independent-samples, paired-samples t-test, Frequentist Bayesian approaches. output includes descriptives, t statistics, mean difference 95% CI, Cohen's d 95% CI, Bayes factor (BF10). also tests assumption homogeneity variance allows users determine whether variances equal . Users can simultaneously test multiple dependent /independent variables. results one pair Y-X summarized one row output. Key results can saved APA format MS Word.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/TTEST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-sample, independent-samples, and paired-samples t-test. — TTEST","text":"","code":"TTEST(   data,   y,   x = NULL,   paired = FALSE,   var.equal = TRUE,   mean.diff = TRUE,   test.value = 0,   test.sided = c(\"=\", \"<\", \">\"),   factor.rev = TRUE,   bayes.prior = \"medium\",   digits = 2,   nsmall = digits,   file = NULL )"},{"path":"https://psychbruce.github.io/bruceR/reference/TTEST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-sample, independent-samples, and paired-samples t-test. — TTEST","text":"data Data frame (wide-format , .e., one case one row). y Dependent variable(s). Multiple variables included character vector c(). paired-samples t-test, number variables 2, 4, 6, etc. x Independent variable(s). Multiple variables included character vector c(). necessary independent-samples t-test. paired paired-samples t-test, set TRUE. Default FALSE. var.equal Levene's test indicates violation homogeneity variance, better set argument FALSE. Default TRUE. mean.diff Whether display results mean difference 95% CI. Default TRUE. test.value true value mean (difference means two-samples test). Default 0. test.sided \"=\" (two-sided, default), \"<\" (one-sided), \">\" (one-sided). factor.rev Whether reverse levels factor (X) test compares higher vs. lower level. Default TRUE. bayes.prior Prior scale Bayesian t-test. Default 0.707. See details BayesFactor::ttestBF(). digits, nsmall Number decimal places output. Default 2. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/TTEST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"One-sample, independent-samples, and paired-samples t-test. — TTEST","text":"Note point estimate Cohen's d computed using common method \"Cohen's d = mean difference / (pooled) standard deviation\", consistent results R packages (e.g., effectsize) software (e.g., jamovi). 95% CI Cohen's d estimated based 95% CI mean difference (.e., also divided pooled standard deviation). However, different packages software diverge greatly estimate 95% CI Cohen's d. R packages psych effectsize, R software jamovi, several online statistical tools estimating effect sizes indeed produce surprisingly inconsistent results 95% CI Cohen's d. See illustration issue section \"Examples\".","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/TTEST.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"One-sample, independent-samples, and paired-samples t-test. — TTEST","text":"","code":"## Demo data ## d1 = between.3 d1$Y1 = d1$SCORE  # shorter name for convenience d1$Y2 = rnorm(32)  # random variable d1$B = factor(d1$B, levels=1:2, labels=c(\"Low\", \"High\")) d1$C = factor(d1$C, levels=1:2, labels=c(\"M\", \"F\")) d2 = within.1  ## One-sample t-test ## TTEST(d1, \"SCORE\") #>  #> One-Sample t-test #>  #> Hypothesis: two-sided (μ ≠ 0) #>  #> Descriptives: #> ──────────────────────── #>  Variable  N Mean (S.D.) #> ──────────────────────── #>     SCORE 32 6.31 (2.95) #> ──────────────────────── #>  #> Results of t-test: #> ────────────────────────────────────────────────────────────────────────────────────── #>                         t df     p     Difference [95% CI] Cohen’s d [95% CI]     BF10 #> ────────────────────────────────────────────────────────────────────────────────────── #> SCORE: (SCORE - 0)  12.13 31 <.001 ***   6.31 [5.25, 7.37]  2.14 [1.78, 2.50] 2.85e+10 #> ────────────────────────────────────────────────────────────────────────────────────── #>  TTEST(d1, \"SCORE\", test.value=5) #>  #> One-Sample t-test #>  #> Hypothesis: two-sided (μ ≠ 5) #>  #> Descriptives: #> ──────────────────────── #>  Variable  N Mean (S.D.) #> ──────────────────────── #>     SCORE 32 6.31 (2.95) #> ──────────────────────── #>  #> Results of t-test: #> ───────────────────────────────────────────────────────────────────────────────────── #>                        t df     p     Difference [95% CI] Cohen’s d [95% CI]     BF10 #> ───────────────────────────────────────────────────────────────────────────────────── #> SCORE: (SCORE - 5)  2.52 31  .017 *     1.31 [0.25, 2.37]  0.45 [0.09, 0.81] 2.81e+00 #> ───────────────────────────────────────────────────────────────────────────────────── #>   ## Independent-samples t-test ## TTEST(d1, \"SCORE\", x=\"A\") #>  #> Independent-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ───────────────────────────────────── #>  Variable Factor Level  N Mean (S.D.) #> ───────────────────────────────────── #>     SCORE      A     1 16 4.12 (1.45) #>     SCORE      A     2 16 8.50 (2.37) #> ───────────────────────────────────── #>  #> Levene’s test for homogeneity of variance: #> ────────────────────────────────────────────── #>                   Levene’s F df1 df2     p     #> ────────────────────────────────────────────── #> SCORE: A (2 - 1)        3.25   1  30  .081 .   #> ────────────────────────────────────────────── #> Note: H0 = equal variance (homoscedasticity). #> If significant (violation of the assumption), #> then you should better set `var.equal=FALSE`. #>  #> Results of t-test: #> ─────────────────────────────────────────────────────────────────────────────────── #>                      t df     p     Difference [95% CI] Cohen’s d [95% CI]     BF10 #> ─────────────────────────────────────────────────────────────────────────────────── #> SCORE: A (2 - 1)  6.30 30 <.001 ***   4.38 [2.96, 5.79]  2.23 [1.51, 2.95] 1.89e+04 #> ─────────────────────────────────────────────────────────────────────────────────── #>  TTEST(d1, \"SCORE\", x=\"A\", var.equal=FALSE) #>  #> Independent-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ───────────────────────────────────── #>  Variable Factor Level  N Mean (S.D.) #> ───────────────────────────────────── #>     SCORE      A     1 16 4.12 (1.45) #>     SCORE      A     2 16 8.50 (2.37) #> ───────────────────────────────────── #>  #> Levene’s test for homogeneity of variance: #> ────────────────────────────────────────────── #>                   Levene’s F df1 df2     p     #> ────────────────────────────────────────────── #> SCORE: A (2 - 1)        3.25   1  30  .081 .   #> ────────────────────────────────────────────── #> Note: H0 = equal variance (homoscedasticity). #> If significant (violation of the assumption), #> then you should better set `var.equal=FALSE`. #>  #> Results of t-test (adjusted df): #> ────────────────────────────────────────────────────────────────────────────────────── #>                      t    df     p     Difference [95% CI] Cohen’s d [95% CI]     BF10 #> ────────────────────────────────────────────────────────────────────────────────────── #> SCORE: A (2 - 1)  6.30 24.92 <.001 ***   4.38 [2.94, 5.81]  2.23 [1.50, 2.96] 1.89e+04 #> ────────────────────────────────────────────────────────────────────────────────────── #>  TTEST(d1, y=\"Y1\", x=c(\"A\", \"B\", \"C\")) #>  #> Independent-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ───────────────────────────────────── #>  Variable Factor Level  N Mean (S.D.) #> ───────────────────────────────────── #>        Y1      A  1    16 4.12 (1.45) #>        Y1      A  2    16 8.50 (2.37) #>        Y1      B  Low  16 5.69 (1.99) #>        Y1      B  High 16 6.94 (3.62) #>        Y1      C  M    16 6.00 (2.34) #>        Y1      C  F    16 6.62 (3.50) #> ───────────────────────────────────── #>  #> Levene’s test for homogeneity of variance: #> ──────────────────────────────────────────────── #>                     Levene’s F df1 df2     p     #> ──────────────────────────────────────────────── #> Y1: A (2 - 1)             3.25   1  30  .081 .   #> Y1: B (High - Low)        7.85   1  30  .009 **  #> Y1: C (F - M)             1.88   1  30  .181     #> ──────────────────────────────────────────────── #> Note: H0 = equal variance (homoscedasticity). #> If significant (violation of the assumption), #> then you should better set `var.equal=FALSE`. #>  #> Results of t-test: #> ───────────────────────────────────────────────────────────────────────────────────── #>                        t df     p     Difference [95% CI] Cohen’s d [95% CI]     BF10 #> ───────────────────────────────────────────────────────────────────────────────────── #> Y1: A (2 - 1)       6.30 30 <.001 ***  4.38 [ 2.96, 5.79] 2.23 [ 1.51, 2.95] 1.89e+04 #> Y1: B (High - Low)  1.21 30  .236      1.25 [-0.86, 3.36] 0.43 [-0.29, 1.15] 5.86e-01 #> Y1: C (F - M)       0.59 30  .557      0.62 [-1.52, 2.77] 0.21 [-0.51, 0.93] 3.85e-01 #> ───────────────────────────────────────────────────────────────────────────────────── #>  TTEST(d1, y=c(\"Y1\", \"Y2\"), x=c(\"A\", \"B\", \"C\"),       mean.diff=FALSE,  # remove to save space       file=\"t-result.doc\") #>  #> Independent-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ────────────────────────────────────── #>  Variable Factor Level  N  Mean (S.D.) #> ────────────────────────────────────── #>        Y1      A  1    16  4.12 (1.45) #>        Y1      A  2    16  8.50 (2.37) #>        Y1      B  Low  16  5.69 (1.99) #>        Y1      B  High 16  6.94 (3.62) #>        Y1      C  M    16  6.00 (2.34) #>        Y1      C  F    16  6.62 (3.50) #>        Y2      A  1    16 -0.78 (0.76) #>        Y2      A  2    16 -0.05 (0.65) #>        Y2      B  Low  16 -0.43 (0.58) #>        Y2      B  High 16 -0.39 (0.97) #>        Y2      C  M    16 -0.37 (0.66) #>        Y2      C  F    16 -0.45 (0.92) #> ────────────────────────────────────── #>  #> Levene’s test for homogeneity of variance: #> ──────────────────────────────────────────────── #>                     Levene’s F df1 df2     p     #> ──────────────────────────────────────────────── #> Y1: A (2 - 1)             3.25   1  30  .081 .   #> Y1: B (High - Low)        7.85   1  30  .009 **  #> Y1: C (F - M)             1.88   1  30  .181     #> Y2: A (2 - 1)             0.04   1  30  .838     #> Y2: B (High - Low)        7.17   1  30  .012 *   #> Y2: C (F - M)             1.07   1  30  .309     #> ──────────────────────────────────────────────── #> Note: H0 = equal variance (homoscedasticity). #> If significant (violation of the assumption), #> then you should better set `var.equal=FALSE`. #>  #> √ Table saved to \"/tmp/RtmpKFkSfK/file3dd048afc62e/reference/t-result.doc\" #>  unlink(\"t-result.doc\")  # delete file for code check  ## Paired-samples t-test ## TTEST(d2, y=c(\"A1\", \"A2\"), paired=TRUE) #>  #> Paired-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ─────────────────────── #>  Variable N Mean (S.D.) #> ─────────────────────── #>        A1 8 4.38 (1.69) #>        A2 8 3.88 (1.25) #> ─────────────────────── #>  #> Results of t-test: #> ────────────────────────────────────────────────────────────────────────────────────── #>                        t df     p     Difference [95% CI]  Cohen’s d [95% CI]     BF10 #> ────────────────────────────────────────────────────────────────────────────────────── #> Paired: (A2 - A1)  -1.18  7  .275     -0.50 [-1.50, 0.50] -0.42 [-1.25, 0.42] 5.78e-01 #> ────────────────────────────────────────────────────────────────────────────────────── #>  TTEST(d2, y=c(\"A1\", \"A2\", \"A3\", \"A4\"), paired=TRUE) #>  #> Paired-Samples t-test #>  #> Hypothesis: two-sided (μ2 - μ1 ≠ 0) #>  #> Descriptives: #> ──────────────────────── #>  Variable N  Mean (S.D.) #> ──────────────────────── #>        A1 8  4.38 (1.69) #>        A2 8  3.88 (1.25) #>        A3 8  7.00 (1.31) #>        A4 8 10.00 (2.27) #> ──────────────────────── #>  #> Results of t-test: #> ────────────────────────────────────────────────────────────────────────────────────── #>                        t df     p     Difference [95% CI]  Cohen’s d [95% CI]     BF10 #> ────────────────────────────────────────────────────────────────────────────────────── #> Paired: (A2 - A1)  -1.18  7  .275     -0.50 [-1.50, 0.50] -0.42 [-1.25, 0.42] 5.78e-01 #> Paired: (A4 - A3)   2.54  7  .039 *    3.00 [ 0.21, 5.79]  0.90 [ 0.06, 1.73] 2.31e+00 #> ────────────────────────────────────────────────────────────────────────────────────── #>    if (FALSE) {    ## Illustration for the issue stated in \"Details\"    # Inconsistency in the 95% CI of Cohen's d between R packages:   # In this example, the true point estimate of Cohen's d = 3.00   # and its 95% CI should be equal to 95% CI of mean difference.    data = data.frame(X=rep(1:2, each=3), Y=1:6)   data  # simple demo data    TTEST(data, y=\"Y\", x=\"X\")   # d = 3.00 [0.73, 5.27] (estimated based on 95% CI of mean difference)    MANOVA(data, dv=\"Y\", between=\"X\") %>%     EMMEANS(\"X\")   # d = 3.00 [0.73, 5.27] (the same as TTEST)    psych::cohen.d(x=data, group=\"X\")   # d = 3.67 [0.04, 7.35] (strange)    psych::d.ci(d=3.00, n1=3, n2=3)   # d = 3.00 [-0.15, 6.12] (significance inconsistent with t-test)    # jamovi uses psych::d.ci() to compute 95% CI   # so its results are also: 3.00 [-0.15, 6.12]    effectsize::cohens_d(Y ~ rev(X), data=data)   # d = 3.00 [0.38, 5.50] (using the noncentrality parameter method)    effectsize::t_to_d(t=t.test(Y ~ rev(X), data=data, var.equal=TRUE)$statistic,                      df_error=4)   # d = 3.67 [0.47, 6.74] (merely an approximate estimate, often overestimated)   # see ?effectsize::t_to_d    # https://www.psychometrica.de/effect_size.html   # d = 3.00 [0.67, 5.33] (slightly different from TTEST)    # https://www.campbellcollaboration.org/escalc/   # d = 3.00 [0.67, 5.33] (slightly different from TTEST)    # Conclusion:   # TTEST() provides a reasonable estimate of Cohen's d and its 95% CI,   # and effectsize::cohens_d() offers another method to compute the CI. }"},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":null,"dir":"Reference","previous_headings":"","what":"Create, modify, and delete variables. — add","title":"Create, modify, and delete variables. — add","text":"Enhanced functions create, modify, /delete variables. functions combine advantages within (base), mutate (dplyr), transmute (dplyr), := (data.table). See examples usage convenience.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create, modify, and delete variables. — add","text":"","code":"add(data, expr, when, by, drop = FALSE)  added(data, expr, when, by, drop = FALSE)"},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create, modify, and delete variables. — add","text":"data data.table (preferred). expr R expression(s) enclosed {...} compute variables. Passing data.table: DT[ , `:=`(expr), ] Execute line expression {...} one one, newly created variables available immediately. advantage mutate implemented data.table. [Optional] Compute rows rows meeting condition(s)? Passing data.table: DT[, , ] [Optional] Compute group(s)? Passing data.table: DT[ , , ] drop Drop existing variables return new variables? Default FALSE, returns variables.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create, modify, and delete variables. — add","text":"add() returns new data.table, raw data unchanged. added() returns nothing already changed raw data.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create, modify, and delete variables. — add","text":"add: Return new data. need assign new data object: added: Return nothing change raw data immediately. need assign new data:","code":"data = add(data, {...}) added(data, {...})"},{"path":"https://psychbruce.github.io/bruceR/reference/add.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create, modify, and delete variables. — add","text":"","code":"## ====== Usage 1: add() ====== ##  d = as.data.table(within.1) d$XYZ = 1:8 d #>    ID A1 A2 A3 A4 XYZ #> 1: S1  3  4  8  9   1 #> 2: S2  6  6  9  8   2 #> 3: S3  4  4  8  8   3 #> 4: S4  3  2  7  7   4 #> 5: S5  5  4  5 12   5 #> 6: S6  7  5  6 13   6 #> 7: S7  5  3  7 12   7 #> 8: S8  2  3  6 11   8  # add() does not change the raw data: add(d, {B = 1; C = 2}) #>    ID A1 A2 A3 A4 XYZ B C #> 1: S1  3  4  8  9   1 1 2 #> 2: S2  6  6  9  8   2 1 2 #> 3: S3  4  4  8  8   3 1 2 #> 4: S4  3  2  7  7   4 1 2 #> 5: S5  5  4  5 12   5 1 2 #> 6: S6  7  5  6 13   6 1 2 #> 7: S7  5  3  7 12   7 1 2 #> 8: S8  2  3  6 11   8 1 2 d #>    ID A1 A2 A3 A4 XYZ #> 1: S1  3  4  8  9   1 #> 2: S2  6  6  9  8   2 #> 3: S3  4  4  8  8   3 #> 4: S4  3  2  7  7   4 #> 5: S5  5  4  5 12   5 #> 6: S6  7  5  6 13   6 #> 7: S7  5  3  7 12   7 #> 8: S8  2  3  6 11   8  # new data should be assigned to an object: d = d %>% add({   ID = str_extract(ID, \"\\\\d\")  # modify a variable   XYZ = NULL                   # delete a variable   A = .mean(\"A\", 1:4)          # create a new variable   B = A * 4    # new variable is immediately available   C = 1        # never need ,/; at the end of any line }) d #>    ID A1 A2 A3 A4    A  B C #> 1:  1  3  4  8  9 6.00 24 1 #> 2:  2  6  6  9  8 7.25 29 1 #> 3:  3  4  4  8  8 6.00 24 1 #> 4:  4  3  2  7  7 4.75 19 1 #> 5:  5  5  4  5 12 6.50 26 1 #> 6:  6  7  5  6 13 7.75 31 1 #> 7:  7  5  3  7 12 6.75 27 1 #> 8:  8  2  3  6 11 5.50 22 1   ## ====== Usage 2: added() ====== ##  d = as.data.table(within.1) d$XYZ = 1:8 d #>    ID A1 A2 A3 A4 XYZ #> 1: S1  3  4  8  9   1 #> 2: S2  6  6  9  8   2 #> 3: S3  4  4  8  8   3 #> 4: S4  3  2  7  7   4 #> 5: S5  5  4  5 12   5 #> 6: S6  7  5  6 13   6 #> 7: S7  5  3  7 12   7 #> 8: S8  2  3  6 11   8  # added() has already changed the raw data: added(d, {B = 1; C = 2}) #> √ Raw data has already been changed. Please check. d #>    ID A1 A2 A3 A4 XYZ B C #> 1: S1  3  4  8  9   1 1 2 #> 2: S2  6  6  9  8   2 1 2 #> 3: S3  4  4  8  8   3 1 2 #> 4: S4  3  2  7  7   4 1 2 #> 5: S5  5  4  5 12   5 1 2 #> 6: S6  7  5  6 13   6 1 2 #> 7: S7  5  3  7 12   7 1 2 #> 8: S8  2  3  6 11   8 1 2  # raw data has already become the new data: added(d, {   ID = str_extract(ID, \"\\\\d\")   XYZ = NULL   A = .mean(\"A\", 1:4)   B = A * 4   C = 1 }) #> √ Raw data has already been changed. Please check. d #>    ID A1 A2 A3 A4  B C    A #> 1:  1  3  4  8  9 24 1 6.00 #> 2:  2  6  6  9  8 29 1 7.25 #> 3:  3  4  4  8  8 24 1 6.00 #> 4:  4  3  2  7  7 19 1 4.75 #> 5:  5  5  4  5 12 26 1 6.50 #> 6:  6  7  5  6 13 31 1 7.75 #> 7:  7  5  3  7 12 27 1 6.75 #> 8:  8  2  3  6 11 22 1 5.50   ## ====== Using `when` and `by` ====== ##  d = as.data.table(between.2) d #>     A B SCORE #>  1: 1 1     3 #>  2: 1 1     6 #>  3: 1 1     4 #>  4: 1 1     3 #>  5: 1 2     4 #>  6: 1 2     6 #>  7: 1 2     4 #>  8: 1 2     2 #>  9: 1 3     5 #> 10: 1 3     7 #> 11: 1 3     5 #> 12: 1 3     2 #> 13: 2 1     4 #> 14: 2 1     5 #> 15: 2 1     3 #> 16: 2 1     3 #> 17: 2 2     8 #> 18: 2 2     9 #> 19: 2 2     8 #> 20: 2 2     7 #> 21: 2 3    12 #> 22: 2 3    13 #> 23: 2 3    12 #> 24: 2 3    11 #>     A B SCORE  added(d, {SCORE2 = SCORE - mean(SCORE)},       A == 1 & B %in% 1:2,  # `when`: for what conditions       by=B)                 # `by`: by what groups #> √ Raw data has already been changed. Please check. d #>     A B SCORE SCORE2 #>  1: 1 1     3     -1 #>  2: 1 1     6      2 #>  3: 1 1     4      0 #>  4: 1 1     3     -1 #>  5: 1 2     4      0 #>  6: 1 2     6      2 #>  7: 1 2     4      0 #>  8: 1 2     2     -2 #>  9: 1 3     5     NA #> 10: 1 3     7     NA #> 11: 1 3     5     NA #> 12: 1 3     2     NA #> 13: 2 1     4     NA #> 14: 2 1     5     NA #> 15: 2 1     3     NA #> 16: 2 1     3     NA #> 17: 2 2     8     NA #> 18: 2 2     9     NA #> 19: 2 2     8     NA #> 20: 2 2     7     NA #> 21: 2 3    12     NA #> 22: 2 3    13     NA #> 23: 2 3    12     NA #> 24: 2 3    11     NA #>     A B SCORE SCORE2 na.omit(d) #>    A B SCORE SCORE2 #> 1: 1 1     3     -1 #> 2: 1 1     6      2 #> 3: 1 1     4      0 #> 4: 1 1     3     -1 #> 5: 1 2     4      0 #> 6: 1 2     6      2 #> 7: 1 2     4      0 #> 8: 1 2     2     -2   ## ====== Return Only New Variables ====== ##  newvars = add(within.1, {   ID = str_extract(ID, \"\\\\d\")   A = .mean(\"A\", 1:4) }, drop=TRUE) newvars #>    ID    A #> 1:  1 6.00 #> 2:  2 7.25 #> 3:  3 6.00 #> 4:  4 4.75 #> 5:  5 6.50 #> 6:  6 7.75 #> 7:  7 6.75 #> 8:  8 5.50   ## ====== Better Than `base::within()` ====== ##  d = as.data.table(within.1)  # wrong order: C B A within(d, {   A = 4   B = A + 1   C = 6 }) #>    ID A1 A2 A3 A4 C B A #> 1: S1  3  4  8  9 6 5 4 #> 2: S2  6  6  9  8 6 5 4 #> 3: S3  4  4  8  8 6 5 4 #> 4: S4  3  2  7  7 6 5 4 #> 5: S5  5  4  5 12 6 5 4 #> 6: S6  7  5  6 13 6 5 4 #> 7: S7  5  3  7 12 6 5 4 #> 8: S8  2  3  6 11 6 5 4  # correct order: A B C add(d, {   A = 4   B = A + 1   C = 6 }) #>    ID A1 A2 A3 A4 A B C #> 1: S1  3  4  8  9 4 5 6 #> 2: S2  6  6  9  8 4 5 6 #> 3: S3  4  4  8  8 4 5 6 #> 4: S4  3  2  7  7 4 5 6 #> 5: S5  5  4  5 12 4 5 6 #> 6: S6  7  5  6 13 4 5 6 #> 7: S7  5  3  7 12 4 5 6 #> 8: S8  2  3  6 11 4 5 6"},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-demodata.html","id":null,"dir":"Reference","previous_headings":"","what":"Demo data. — bruceR-demodata","title":"Demo data. — bruceR-demodata","text":"Demo datasets multi-factor ANOVA examples show functions MANOVA EMMEANS work.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-demodata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Demo data. — bruceR-demodata","text":"1. -Subjects Design  .1 - (4) .2 - (2) * B(3) .3 - (2) * B(2) * C(2)  2. Within-Subjects Design  within.1 - (4) within.2 - (2) * B(3) within.3 - (2) * B(2) * C(2)  3. Mixed Design  mixed.2_1b1w - (2, ) * B(3, within) mixed.3_1b2w - (2, ) * B(2, within) * C(2, within) mixed.3_2b1w - (2, ) * B(2, within) * C(2, )","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-demodata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Demo data. — bruceR-demodata","text":"Multi-Factor Experimental Design Psychology Education","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bruceR: BRoadly Useful Convenient and Efficient R functions — bruceR-package","title":"bruceR: BRoadly Useful Convenient and Efficient R functions — bruceR-package","text":"BRoadly Useful Convenient Efficient R functions BRing Users Concise Elegant R data analyses. Package homepage: https://psychbruce.github.io/bruceR/ Install latest development version GitHub: devtools::install_github(\"psychbruce/bruceR\") Report bugs GitHub Issues.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"bruceR: BRoadly Useful Convenient and Efficient R functions — bruceR-package","text":"Loading bruceR library(bruceR) also load R packages : [Data]: dplyr: Data manipulation processing. tidyr: Data cleaning reshaping. stringr: Toolbox string operation (regular expressions). forcats: Toolbox factor manipulation (categorical variables). data.table: Advanced data.frame higher efficiency. [Stat]: emmeans: Estimates marginal means multiple contrasts. effectsize: Estimates effect sizes standardized parameters. performance: Estimates regression models performance. lmerTest: Tests linear mixed effects models (LMM, also known HLM multilevel models). [Plot]: ggplot2: Data visualization. ggtext: Markdown/HTML rich text format ggplot2 (geoms themes). cowplot: Advanced toolbox ggplot2 (arrange multiple plots add labels). see: Advanced toolbox ggplot2 (geoms, scales, themes, color palettes).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-package.html","id":"main-functions-in-brucer","dir":"Reference","previous_headings":"","what":"Main Functions in bruceR","title":"bruceR: BRoadly Useful Convenient and Efficient R functions — bruceR-package","text":"(1) Basic R Programming set.wd (alias: set_wd) import,       export cc pkg_depend,       pkg_install_suggested formatF,       formatN print_table Print,       Glue,       Run %^% %notin% %allin%,       %anyin%,       %nonein%,       %partin% (2) Multivariate Computation add,       added .sum,       .mean SUM,       MEAN,       STD,       MODE,       COUNT,       CONSEC RECODE,       RESCALE LOOKUP (3) Reliability Factor Analyses Alpha EFA / PCA CFA (4) Descriptive Statistics Correlation Analyses Describe Freq Corr cor_diff (5) T-Test, Multi-Factor ANOVA, Simple-Effect Analysis, Post-Hoc Multiple Comparison TTEST MANOVA EMMEANS (6) Tidy Report Regression Models model_summary lavaan_summary GLM_summary HLM_summary HLM_ICC_rWG regress (7) Mediation Moderation Analyses PROCESS med_summary (8) Additional Toolbox Statistics Graphics grand_mean_center group_mean_center ccf_plot granger_test granger_causality theme_bruce show_colors","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/bruceR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bruceR: BRoadly Useful Convenient and Efficient R functions — bruceR-package","text":"Han-Wu-Shuang (Bruce) Bao","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cc.html","id":null,"dir":"Reference","previous_headings":"","what":"Split up a string (with separators) into a character vector. — cc","title":"Split up a string (with separators) into a character vector. — cc","text":"Split string (separators) character vector (whitespace around separator trimmed).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split up a string (with separators) into a character vector. — cc","text":"","code":"cc(..., sep = \"auto\", trim = TRUE)"},{"path":"https://psychbruce.github.io/bruceR/reference/cc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split up a string (with separators) into a character vector. — cc","text":"... Character string(s). sep Pattern separation. Default \"auto\": , ; | \\n \\t trim Remove whitespace start end string(s)? Default TRUE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split up a string (with separators) into a character vector. — cc","text":"Character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split up a string (with separators) into a character vector. — cc","text":"","code":"cc(\"a,b,c,d,e\") #> [1] \"a\" \"b\" \"c\" \"d\" \"e\"  cc(\" a , b , c , d , e \") #> [1] \"a\" \"b\" \"c\" \"d\" \"e\"  cc(\" a , b , c , d , e \", trim=FALSE) #> [1] \" a \" \" b \" \" c \" \" d \" \" e \"  cc(\"1, 2, 3, 4, 5\") #> [1] \"1\" \"2\" \"3\" \"4\" \"5\"  cc(\"A 1 , B 2 ; C 3 | D 4 \\t E 5\") #> [1] \"A 1\" \"B 2\" \"C 3\" \"D 4\" \"E 5\"  cc(\"A, B, C\",    \" D | E \",    c(\"F\", \"G\")) #> [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\"  cc(\" American British Chinese \") #> [1] \"American\" \"British\"  \"Chinese\""},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-correlation analysis. — ccf_plot","title":"Cross-correlation analysis. — ccf_plot","text":"Plot results cross-correlation analysis using ggplot2 (rather R base plot) flexible modification plot.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-correlation analysis. — ccf_plot","text":"","code":"ccf_plot(   formula,   data,   lag.max = 30,   sig.level = 0.05,   xbreaks = seq(-100, 100, 10),   ybreaks = seq(-1, 1, 0.2),   ylim = NULL,   alpha.ns = 1,   pos.color = \"black\",   neg.color = \"black\",   ci.color = \"blue\",   title = NULL,   subtitle = NULL,   xlab = \"Lag\",   ylab = \"Cross-Correlation\" )"},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-correlation analysis. — ccf_plot","text":"formula Model formula like y ~ x. data Data frame. lag.max Maximum time lag. Default 30. sig.level Significance level. Default 0.05. xbreaks X-axis breaks. ybreaks Y-axis breaks. ylim Y-axis limits. Default NULL automatically estimate. alpha.ns Color transparency (opacity: 0~1) non-significant values. Default 1 transparency (.e., opaque color). pos.color Color positive values. Default \"black\". neg.color Color negative values. Default \"black\". ci.color Color upper lower bounds significant values. Default \"blue\". title Plot title. Default illustration formula. subtitle Plot subtitle. xlab X-axis title. Default \"Lag\". ylab Y-axis title. Default \"Cross-Correlation\".","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-correlation analysis. — ccf_plot","text":"gg object, can modify using ggplot2 syntax save using ggsave().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-correlation analysis. — ccf_plot","text":"Significant correlations negative time lags suggest shifts predictor precede shifts outcome.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/ccf_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-correlation analysis. — ccf_plot","text":"","code":"# resemble the default plot output by `ccf()` p1 = ccf_plot(chicken ~ egg, data=lmtest::ChickEgg)  # a more colorful plot p2 = ccf_plot(chicken ~ egg, data=lmtest::ChickEgg, alpha.ns=0.3,               pos.color=\"#CD201F\",               neg.color=\"#21759B\",               ci.color=\"black\")"},{"path":"https://psychbruce.github.io/bruceR/reference/cor_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the difference between two correlations. — cor_diff","title":"Test the difference between two correlations. — cor_diff","text":"Test difference two correlations.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cor_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the difference between two correlations. — cor_diff","text":"","code":"cor_diff(r1, n1, r2, n2, n = NULL, rcov = NULL)"},{"path":"https://psychbruce.github.io/bruceR/reference/cor_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the difference between two correlations. — cor_diff","text":"r1, r2 Correlation coefficients (Pearson's r). n, n1, n2 Sample sizes. rcov [Optional] nonindependent rs: r1 r(X,Y), r2 r(X,Z), , Y Z also correlated, also consider rcov: r(Y,Z)","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cor_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the difference between two correlations. — cor_diff","text":"Invisibly return p value.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/cor_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test the difference between two correlations. — cor_diff","text":"","code":"# two independent rs (X~Y vs. Z~W) cor_diff(r1=0.20, n1=100, r2=0.45, n2=100) #> r1 = 0.200 (N = 100) #> r2 = 0.450 (N = 100) #> Difference of correlation: z = -1.96, p = 0.050 *    # two nonindependent rs (X~Y vs. X~Z, with Y and Z also correlated [rcov]) cor_diff(r1=0.20, r2=0.45, n=100, rcov=0.80) #> r1 = 0.200 #> r2 = 0.450 #> (N = 100, r_cov = 0.800) #> Difference of correlation: t(97) = -4.56, p = 1e-05 ***"},{"path":"https://psychbruce.github.io/bruceR/reference/dtime.html","id":null,"dir":"Reference","previous_headings":"","what":"Timer (compute time difference). — dtime","title":"Timer (compute time difference). — dtime","text":"Timer (compute time difference).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/dtime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Timer (compute time difference). — dtime","text":"","code":"dtime(t0, unit = \"secs\", digits = 0, nsmall = digits)"},{"path":"https://psychbruce.github.io/bruceR/reference/dtime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Timer (compute time difference). — dtime","text":"t0 Time beginning. unit Options: \"auto\", \"secs\", \"mins\", \"hours\", \"days\", \"weeks\". Default \"secs\". digits, nsmall Number decimal places output. Default 0.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/dtime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Timer (compute time difference). — dtime","text":"character string time difference.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/dtime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Timer (compute time difference). — dtime","text":"","code":"if (FALSE) {  t0 = Sys.time() dtime(t0) }"},{"path":"https://psychbruce.github.io/bruceR/reference/export.html","id":null,"dir":"Reference","previous_headings":"","what":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","title":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","text":"Export data file, format automatically judged file extension. function inspired rio::export() several modifications. purpose avoid using lots write_xxx() functions code provide one tidy function data export. supports many file formats uses corresponding R functions: Plain text (.txt, .csv, .csv2, .tsv, .psv), using data.table::fwrite();   encoding argument specified, using utils::write.table() instead Excel (.xls, .xlsx), using openxlsx::write.xlsx() SPSS (.sav), using haven::write_sav() Stata (.dta), using haven::write_dta() R objects (.rda, .rdata, .Rdata), using base::save() R serialized objects (.rds), using base::saveRDS() Clipboard (Windows Mac OS), using clipr::write_clip() formats, using rio::export()","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/export.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","text":"","code":"export(   x,   file,   sheet = NULL,   encoding = NULL,   header = \"auto\",   overwrite = TRUE )"},{"path":"https://psychbruce.github.io/bruceR/reference/export.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","text":"x R object, usually data frame (data.frame, data.table, tbl_df). Multiple R objects included named list (see examples). want save R objects data frame (e.g., model results), better specify file extensions .rda, .rdata, .Rdata. file File name (extension). unspecified, data exported clipboard. sheet [Excel] Excel sheet name(s). Default Sheet1, Sheet2, ... may specify multiple sheet names character vector c() length x (see examples). encoding File encoding. Default NULL. Alternatives can \"UTF-8\", \"GBK\", \"CP936\", etc. find messy code Chinese text exported data (often CSV opened Excel), usually effective set encoding=\"GBK\" encoding=\"CP936\". header first row contain column names (TRUE FALSE)? Default \"auto\". overwrite Overwrite existing file ()? Default TRUE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/export.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","text":"return value.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/export.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export data to a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — export","text":"","code":"if (FALSE) {    export(airquality)  # paste to clipboard   export(airquality, file=\"mydata.csv\")   export(airquality, file=\"mydata.sav\")    export(list(airquality, npk), file=\"mydata.xlsx\")  # Sheet1, Sheet2   export(list(air=airquality, npk=npk), file=\"mydata.xlsx\")  # a named list   export(list(airquality, npk), sheet=c(\"air\", \"npk\"), file=\"mydata.xlsx\")    export(list(a=1, b=npk, c=\"character\"), file=\"abc.Rdata\")  # .rda, .rdata   d = import(\"abc.Rdata\")  # load only the first object and rename it to `d`   load(\"abc.Rdata\")  # load all objects with original names to environment    export(lm(yield ~ N*P*K, data=npk), file=\"lm_npk.Rdata\")   model = import(\"lm_npk.Rdata\")   load(\"lm_npk.Rdata\")  # because x is unnamed, the object has a name \"List1\"    export(list(m1=lm(yield ~ N*P*K, data=npk)), file=\"lm_npk.Rdata\")   model = import(\"lm_npk.Rdata\")   load(\"lm_npk.Rdata\")  # because x is named, the object has a name \"m1\" }"},{"path":"https://psychbruce.github.io/bruceR/reference/formatF.html","id":null,"dir":"Reference","previous_headings":"","what":"Format numeric values. — formatF","title":"Format numeric values. — formatF","text":"Format numeric values.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formatF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format numeric values. — formatF","text":"","code":"formatF(x, digits = 3, nsmall = digits)"},{"path":"https://psychbruce.github.io/bruceR/reference/formatF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format numeric values. — formatF","text":"x number numeric vector. digits, nsmall Number decimal places output. Default 3.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formatF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format numeric values. — formatF","text":"Formatted character string.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/formatF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format numeric values. — formatF","text":"","code":"formatF(pi, 20) #> [1] \"3.14159265358979311600\""},{"path":"https://psychbruce.github.io/bruceR/reference/formatN.html","id":null,"dir":"Reference","previous_headings":"","what":"Format ","title":"Format ","text":"Format \"1234\" \"1,234\".","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formatN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format ","text":"","code":"formatN(x, mark = \",\")"},{"path":"https://psychbruce.github.io/bruceR/reference/formatN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format ","text":"x number numeric vector. mark Usually \",\".","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formatN.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format ","text":"Formatted character string.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/formatN.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format ","text":"","code":"formatN(1234) #> [1] \"1,234\""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_expand.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand all interaction terms in a formula. — formula_expand","title":"Expand all interaction terms in a formula. — formula_expand","text":"Expand interaction terms formula.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_expand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand all interaction terms in a formula. — formula_expand","text":"","code":"formula_expand(formula, as.char = FALSE)"},{"path":"https://psychbruce.github.io/bruceR/reference/formula_expand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand all interaction terms in a formula. — formula_expand","text":"formula R formula character string indicating formula. .char Return character? Default FALSE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_expand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand all interaction terms in a formula. — formula_expand","text":"formula/character object including expanded terms.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_expand.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand all interaction terms in a formula. — formula_expand","text":"","code":"formula_expand(y ~ a*b*c) #> y ~ a + b + c + a:b + a:c + b:c + a:b:c #> <environment: 0x561bce80da88> formula_expand(\"y ~ a*b*c\") #> y ~ a + b + c + a:b + a:c + b:c + a:b:c #> <environment: 0x561bd34085b8>"},{"path":"https://psychbruce.github.io/bruceR/reference/formula_paste.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste a formula into a string. — formula_paste","title":"Paste a formula into a string. — formula_paste","text":"Paste formula string.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_paste.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste a formula into a string. — formula_paste","text":"","code":"formula_paste(formula)"},{"path":"https://psychbruce.github.io/bruceR/reference/formula_paste.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste a formula into a string. — formula_paste","text":"formula R formula.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_paste.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste a formula into a string. — formula_paste","text":"character string indicating formula.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/formula_paste.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Paste a formula into a string. — formula_paste","text":"","code":"formula_paste(y ~ x) #> [1] \"y ~ x\" formula_paste(y ~ x + (1 | g)) #> [1] \"y ~ x + (1 | g)\""},{"path":"https://psychbruce.github.io/bruceR/reference/grand_mean_center.html","id":null,"dir":"Reference","previous_headings":"","what":"Grand-mean centering. — grand_mean_center","title":"Grand-mean centering. — grand_mean_center","text":"Compute grand-mean centered variables. Usually used GLM interaction-term predictors HLM level-2 predictors.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grand_mean_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grand-mean centering. — grand_mean_center","text":"","code":"grand_mean_center(data, vars = names(data), std = FALSE, add.suffix = \"\")"},{"path":"https://psychbruce.github.io/bruceR/reference/grand_mean_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grand-mean centering. — grand_mean_center","text":"data Data object. vars Variable(s) centered. std Standardized . Default FALSE. add.suffix suffix centered variable(s). Default \"\". may set \"_c\", \"_center\", etc.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grand_mean_center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grand-mean centering. — grand_mean_center","text":"new data object containing centered variable(s).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grand_mean_center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grand-mean centering. — grand_mean_center","text":"","code":"d = data.table(a=1:5, b=6:10)  d.c = grand_mean_center(d, \"a\") d.c #>     a  b #> 1: -2  6 #> 2: -1  7 #> 3:  0  8 #> 4:  1  9 #> 5:  2 10  d.c = grand_mean_center(d, c(\"a\", \"b\"), add.suffix=\"_center\") d.c #>    a  b a_center b_center #> 1: 1  6       -2       -2 #> 2: 2  7       -1       -1 #> 3: 3  8        0        0 #> 4: 4  9        1        1 #> 5: 5 10        2        2"},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":null,"dir":"Reference","previous_headings":"","what":"Granger causality test (multivariate). — granger_causality","title":"Granger causality test (multivariate). — granger_causality","text":"Granger test predictive causality (multivariate time series) based vector autoregression (VAR) model. output resembles output vargranger command Stata (using F test).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granger causality test (multivariate). — granger_causality","text":"","code":"granger_causality(   varmodel,   var.y = NULL,   var.x = NULL,   test = c(\"F\", \"Chisq\"),   file = NULL,   check.dropped = FALSE )"},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Granger causality test (multivariate). — granger_causality","text":"varmodel VAR model fitted using vars::VAR() function. var.y, var.x [Optional] Default NULL (variables). specified, perform tests specific variables. Values can single variable (e.g., \"X\"), vector variables (e.g., c(\"X1\", \"X2\")), string containing regular expression (e.g., \"X1|X2\"). test F test /Wald \\(\\chi\\)^2 test. Default : c(\"F\", \"Chisq\"). file File name MS Word (.doc). check.dropped Check dropped variables. Default FALSE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Granger causality test (multivariate). — granger_causality","text":"data frame results.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Granger causality test (multivariate). — granger_causality","text":"Granger causality test (based VAR model) examines whether lagged values predictor (predictors) help predict outcome controlling lagged values outcome . Granger causality necessarily constitute true causal effect.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/granger_causality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Granger causality test (multivariate). — granger_causality","text":"","code":"if (FALSE) {    # R package \"vars\" should be installed   library(vars)   data(Canada)   VARselect(Canada)   vm = VAR(Canada, p=3)   model_summary(vm)   granger_causality(vm) }"},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Granger causality test (bivariate). — granger_test","title":"Granger causality test (bivariate). — granger_test","text":"Granger test predictive causality (two time series) using lmtest::grangertest() function.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granger causality test (bivariate). — granger_test","text":"","code":"granger_test(formula, data, lags = 1:5, test.reverse = TRUE, file = NULL)"},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Granger causality test (bivariate). — granger_test","text":"formula Model formula like y ~ x. data Data frame. lags Time lags. Default 1:5. test.reverse Whether test reverse causality. Default TRUE. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Granger causality test (bivariate). — granger_test","text":"data frame results.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Granger causality test (bivariate). — granger_test","text":"Granger causality test examines whether lagged values predictor incremental role predicting (.e., help predict) outcome controlling lagged values outcome. Granger causality necessarily constitute true causal effect.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/granger_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Granger causality test (bivariate). — granger_test","text":"","code":"granger_test(chicken ~ egg, data=lmtest::ChickEgg) #>  #> Granger Causality Test (Bivariate) #>  #> Hypothesized direction: #> chicken ~ chicken[1:Lags] + egg[1:Lags] #> Lags = 1:\tF(1, 50) = 1.21, p = 0.277     #> Lags = 2:\tF(2, 47) = 8.82, p = 6e-04 *** #> Lags = 3:\tF(3, 44) = 5.40, p = 0.003 **  #> Lags = 4:\tF(4, 41) = 4.26, p = 0.006 **  #> Lags = 5:\tF(5, 38) = 4.73, p = 0.002 **  #>  #> Reverse direction: #> egg ~ egg[1:Lags] + chicken[1:Lags] #> Lags = 1:\tF(1, 50) = 0.05, p = 0.829     #> Lags = 2:\tF(2, 47) = 0.88, p = 0.422     #> Lags = 3:\tF(3, 44) = 0.59, p = 0.624     #> Lags = 4:\tF(4, 41) = 0.39, p = 0.813     #> Lags = 5:\tF(5, 38) = 0.29, p = 0.913     #>  granger_test(chicken ~ egg, data=lmtest::ChickEgg, lags=1:10, file=\"Granger.doc\") #>  #> Granger Causality Test (Bivariate) #>  #> Hypothesized direction: #> chicken ~ chicken[1:Lags] + egg[1:Lags] #> Lags = 1:\tF(1, 50) = 1.21, p = 0.277     #> Lags = 2:\tF(2, 47) = 8.82, p = 6e-04 *** #> Lags = 3:\tF(3, 44) = 5.40, p = 0.003 **  #> Lags = 4:\tF(4, 41) = 4.26, p = 0.006 **  #> Lags = 5:\tF(5, 38) = 4.73, p = 0.002 **  #> Lags = 6:\tF(6, 35) = 3.65, p = 0.006 **  #> Lags = 7:\tF(7, 32) = 4.06, p = 0.003 **  #> Lags = 8:\tF(8, 29) = 3.15, p = 0.011 *   #> Lags = 9:\tF(9, 26) = 4.37, p = 0.001 **  #> Lags = 10:\tF(10, 23) = 3.90, p = 0.003 **  #>  #> Reverse direction: #> egg ~ egg[1:Lags] + chicken[1:Lags] #> Lags = 1:\tF(1, 50) = 0.05, p = 0.829     #> Lags = 2:\tF(2, 47) = 0.88, p = 0.422     #> Lags = 3:\tF(3, 44) = 0.59, p = 0.624     #> Lags = 4:\tF(4, 41) = 0.39, p = 0.813     #> Lags = 5:\tF(5, 38) = 0.29, p = 0.913     #> Lags = 6:\tF(6, 35) = 0.36, p = 0.898     #> Lags = 7:\tF(7, 32) = 0.61, p = 0.747     #> Lags = 8:\tF(8, 29) = 0.61, p = 0.762     #> Lags = 9:\tF(9, 26) = 0.56, p = 0.820     #> Lags = 10:\tF(10, 23) = 0.38, p = 0.944     #>  #> √ Table saved to \"/tmp/RtmpKFkSfK/file3dd048afc62e/reference/Granger.doc\" #>  unlink(\"Granger.doc\")  # delete file for code check"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-allin-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple extension of %in%. — %allin%","title":"A simple extension of %in%. — %allin%","text":"simple extension %%.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-allin-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple extension of %in%. — %allin%","text":"","code":"x %allin% vector"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-allin-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple extension of %in%. — %allin%","text":"x Numeric character vector. vector Numeric character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-allin-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple extension of %in%. — %allin%","text":"TRUE FALSE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-allin-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple extension of %in%. — %allin%","text":"","code":"1:2 %allin% 1:3  # TRUE #> [1] TRUE 3:4 %allin% 1:3  # FALSE #> [1] FALSE"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-anyin-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple extension of %in%. — %anyin%","title":"A simple extension of %in%. — %anyin%","text":"simple extension %%.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-anyin-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple extension of %in%. — %anyin%","text":"","code":"x %anyin% vector"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-anyin-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple extension of %in%. — %anyin%","text":"x Numeric character vector. vector Numeric character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-anyin-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple extension of %in%. — %anyin%","text":"TRUE FALSE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-anyin-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple extension of %in%. — %anyin%","text":"","code":"3:4 %anyin% 1:3  # TRUE #> [1] TRUE 4:5 %anyin% 1:3  # FALSE #> [1] FALSE"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate computation. — %%COMPUTE%%","title":"Multivariate computation. — %%COMPUTE%%","text":"Easily compute multivariate sum, mean, scores. Reverse scoring can also easily implemented without saving extra variables. Alpha function uses similar method deal reverse scoring. Three options specify variables: var + items: common unique parts variable names (suggested). vars: character vector variable names (suggested). varrange: starting stopping positions variables (suggested).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate computation. — %%COMPUTE%%","text":"","code":"COUNT(data, var = NULL, items = NULL, vars = NULL, varrange = NULL, value = NA)  MODE(data, var = NULL, items = NULL, vars = NULL, varrange = NULL)  SUM(   data,   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   rev = NULL,   range = likert,   likert = NULL,   na.rm = TRUE )  .sum(   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   rev = NULL,   range = likert,   likert = NULL,   na.rm = TRUE )  MEAN(   data,   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   rev = NULL,   range = likert,   likert = NULL,   na.rm = TRUE )  .mean(   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   rev = NULL,   range = likert,   likert = NULL,   na.rm = TRUE )  STD(   data,   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   rev = NULL,   range = likert,   likert = NULL,   na.rm = TRUE )  CONSEC(   data,   var = NULL,   items = NULL,   vars = NULL,   varrange = NULL,   values = 0:9 )"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate computation. — %%COMPUTE%%","text":"data Data frame. var [Option 1] common part across variables. e.g., \"RSES\" items [Option 1] unique part across variables. e.g., 1:10 vars [Option 2] character vector specifying variables. e.g., c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\") varrange [Option 3] character string specifying positions (\"starting:stopping\") variables. e.g., \"A1:E5\" value [COUNT] value counted. rev [Optional] Variables need reversed. can (1) character vector specifying reverse-scoring variables (recommended), (2) numeric vector specifying item number reverse-scoring variables (recommended). range, likert [Optional] Range likert scale (e.g., 1:5, c(1, 5)). provided, automatically estimated given data (use carefully). na.rm Ignore missing values. Default TRUE. values [CONSEC] Values counted consecutive identical values. Default numbers (0:9).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate computation. — %%COMPUTE%%","text":"vector computed values.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Multivariate computation. — %%COMPUTE%%","text":"COUNT: Count certain value across variables. MODE: Compute mode across variables. SUM: Compute sum across variables. .sum: Tidy version SUM, can used add()/added() MEAN: Compute mean across variables. .mean: Tidy version MEAN, can used add()/added() STD: Compute standard deviation across variables. CONSEC: Compute consecutive identical digits across variables (especially useful detecting careless responding).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-grapes-COMPUTE-grapes-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate computation. — %%COMPUTE%%","text":"","code":"d = data.table(x1=1:5,                x4=c(2,2,5,4,5),                x3=c(3,2,NA,NA,5),                x2=c(4,4,NA,2,5),                x5=c(5,4,1,4,5)) d #>    x1 x4 x3 x2 x5 #> 1:  1  2  3  4  5 #> 2:  2  2  2  4  4 #> 3:  3  5 NA NA  1 #> 4:  4  4 NA  2  4 #> 5:  5  5  5  5  5 ## I deliberately set this order to show you ## the difference between \"vars\" and \"varrange\".  ## ====== Usage 1: data.table `:=` ====== ## d[, `:=`(   na = COUNT(d, \"x\", 1:5, value=NA),   n.2 = COUNT(d, \"x\", 1:5, value=2),   sum = SUM(d, \"x\", 1:5),   m1 = MEAN(d, \"x\", 1:5),   m2 = MEAN(d, vars=c(\"x1\", \"x4\")),   m3 = MEAN(d, varrange=\"x1:x2\", rev=\"x2\", range=1:5),   cons1 = CONSEC(d, \"x\", 1:5),   cons2 = CONSEC(d, varrange=\"x1:x5\") )] #>    x1 x4 x3 x2 x5 na n.2 sum  m1  m2 m3 cons1 cons2 #> 1:  1  2  3  4  5  0   1  15 3.0 1.5  2     0     0 #> 2:  2  2  2  4  4  0   3  14 2.8 2.0  2     2     3 #> 3:  3  5 NA NA  1  2   0   9 3.0 4.0  4     0     0 #> 4:  4  4 NA  2  4  1   1  14 3.5 4.0  4     2     2 #> 5:  5  5  5  5  5  0   0  25 5.0 5.0  4     5     5 d #>    x1 x4 x3 x2 x5 na n.2 sum  m1  m2 m3 cons1 cons2 #> 1:  1  2  3  4  5  0   1  15 3.0 1.5  2     0     0 #> 2:  2  2  2  4  4  0   3  14 2.8 2.0  2     2     3 #> 3:  3  5 NA NA  1  2   0   9 3.0 4.0  4     0     0 #> 4:  4  4 NA  2  4  1   1  14 3.5 4.0  4     2     2 #> 5:  5  5  5  5  5  0   0  25 5.0 5.0  4     5     5  ## ====== Usage 2: `add()` & `added()` ====== ## data = as.data.table(psych::bfi) added(data, {   gender = as.factor(gender)   education = as.factor(education)   E = .mean(\"E\", 1:5, rev=c(1,2), range=1:6)   A = .mean(\"A\", 1:5, rev=1, range=1:6)   C = .mean(\"C\", 1:5, rev=c(4,5), range=1:6)   N = .mean(\"N\", 1:5, range=1:6)   O = .mean(\"O\", 1:5, rev=c(2,5), range=1:6) }, drop=TRUE) #> √ Raw data has already been changed. Please check. data #>       gender education   E   A   C    N   O #>    1:      1      <NA> 3.8 4.0 2.8 2.80 3.0 #>    2:      2      <NA> 5.0 4.2 4.0 3.80 4.0 #>    3:      2      <NA> 4.2 3.8 4.0 3.60 4.8 #>    4:      2      <NA> 3.6 4.6 3.0 2.80 3.2 #>    5:      1      <NA> 4.8 4.0 4.4 3.20 3.6 #>   ---                                       #> 2796:      1         3 5.0 2.2 6.0 1.00 6.0 #> 2797:      1         4 4.2 4.2 3.2 2.75 4.8 #> 2798:      2         4 5.0 4.0 5.4 2.80 5.0 #> 2799:      1         4 4.6 2.8 4.2 4.20 5.2 #> 2800:      2         4 2.6 3.0 4.2 1.40 4.6"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-nonein-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple extension of %in%. — %nonein%","title":"A simple extension of %in%. — %nonein%","text":"simple extension %%.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-nonein-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple extension of %in%. — %nonein%","text":"","code":"x %nonein% vector"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-nonein-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple extension of %in%. — %nonein%","text":"x Numeric character vector. vector Numeric character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-nonein-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple extension of %in%. — %nonein%","text":"TRUE FALSE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-nonein-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple extension of %in%. — %nonein%","text":"","code":"3:4 %nonein% 1:3  # FALSE #> [1] FALSE 4:5 %nonein% 1:3  # TRUE #> [1] TRUE"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-notin-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"The opposite of %in%. — %notin%","title":"The opposite of %in%. — %notin%","text":"opposite %%.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-notin-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The opposite of %in%. — %notin%","text":"","code":"x %notin% vector"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-notin-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The opposite of %in%. — %notin%","text":"x Numeric character vector. vector Numeric character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-notin-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The opposite of %in%. — %notin%","text":"vector TRUE FALSE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-notin-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The opposite of %in%. — %notin%","text":"","code":"data = data.table(ID=1:10, X=sample(1:10, 10)) data #>     ID  X #>  1:  1  9 #>  2:  2  4 #>  3:  3  3 #>  4:  4  6 #>  5:  5  8 #>  6:  6  7 #>  7:  7  5 #>  8:  8  2 #>  9:  9  1 #> 10: 10 10 data[ID %notin% c(1, 3, 5, 7, 9)] #>    ID  X #> 1:  2  4 #> 2:  4  6 #> 3:  6  7 #> 4:  8  2 #> 5: 10 10"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-partin-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple extension of %in%. — %partin%","title":"A simple extension of %in%. — %partin%","text":"simple extension %%.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-partin-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple extension of %in%. — %partin%","text":"","code":"pattern %partin% vector"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-partin-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple extension of %in%. — %partin%","text":"pattern Character string containing regular expressions matched. vector Character vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-partin-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple extension of %in%. — %partin%","text":"TRUE FALSE.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-partin-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple extension of %in%. — %partin%","text":"","code":"\"Bei\" %partin% c(\"Beijing\", \"Shanghai\")  # TRUE #> [1] TRUE \"bei\" %partin% c(\"Beijing\", \"Shanghai\")  # FALSE #> [1] FALSE \"[aeiou]ng\" %partin% c(\"Beijing\", \"Shanghai\")  # TRUE #> [1] TRUE"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-pow-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste strings together. — %^%","title":"Paste strings together. — %^%","text":"Paste strings together. wrapper paste0(). %^%? typing % ^ pretty easy pressing Shift + 5 + 6 + 5.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-pow-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste strings together. — %^%","text":"","code":"x %^% y"},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-pow-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste strings together. — %^%","text":"x, y objects, usually numeric character string vector.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-pow-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste strings together. — %^%","text":"character string/vector pasted values.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/grapes-pow-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Paste strings together. — %^%","text":"","code":"\"He\" %^% \"llo\" #> [1] \"Hello\" \"X\" %^% 1:10 #>  [1] \"X1\"  \"X2\"  \"X3\"  \"X4\"  \"X5\"  \"X6\"  \"X7\"  \"X8\"  \"X9\"  \"X10\" \"Q\" %^% 1:5 %^% letters[1:5] #> [1] \"Q1a\" \"Q2b\" \"Q3c\" \"Q4d\" \"Q5e\""},{"path":"https://psychbruce.github.io/bruceR/reference/group_mean_center.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-mean centering. — group_mean_center","title":"Group-mean centering. — group_mean_center","text":"Compute group-mean centered variables. Usually used HLM level-1 predictors.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/group_mean_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group-mean centering. — group_mean_center","text":"","code":"group_mean_center(   data,   vars = setdiff(names(data), by),   by,   std = FALSE,   add.suffix = \"\",   add.group.mean = \"_mean\" )"},{"path":"https://psychbruce.github.io/bruceR/reference/group_mean_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-mean centering. — group_mean_center","text":"data Data object. vars Variable(s) centered. Grouping variable. std Standardized . Default FALSE. add.suffix suffix centered variable(s). Default \"\". may set \"_c\", \"_center\", etc. add.group.mean suffix variable name(s) group means. Default \"_mean\" (see Examples).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/group_mean_center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group-mean centering. — group_mean_center","text":"new data object containing centered variable(s).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/group_mean_center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-mean centering. — group_mean_center","text":"","code":"d = data.table(x=1:9, g=rep(1:3, each=3))  d.c = group_mean_center(d, \"x\", by=\"g\") d.c #>     x g x_mean #> 1: -1 1      2 #> 2:  0 1      2 #> 3:  1 1      2 #> 4: -1 2      5 #> 5:  0 2      5 #> 6:  1 2      5 #> 7: -1 3      8 #> 8:  0 3      8 #> 9:  1 3      8  d.c = group_mean_center(d, \"x\", by=\"g\", add.suffix=\"_c\") d.c #>    x g x_mean x_c #> 1: 1 1      2  -1 #> 2: 2 1      2   0 #> 3: 3 1      2   1 #> 4: 4 2      5  -1 #> 5: 5 2      5   0 #> 6: 6 2      5   1 #> 7: 7 3      8  -1 #> 8: 8 3      8   0 #> 9: 9 3      8   1"},{"path":"https://psychbruce.github.io/bruceR/reference/import.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","title":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","text":"Import data file, format automatically judged file extension. function inspired rio::import() several modifications. purpose avoid using lots read_xxx() functions code provide one tidy function data import. supports many file formats uses corresponding R functions: Plain text (.txt, .csv, .csv2, .tsv, .psv), using data.table::fread() Excel (.xls, .xlsx), using readxl::read_excel() SPSS (.sav), using foreign::read.spss();   failed, using haven::read_sav() instead Stata (.dta), using foreign::read.dta();   failed, using haven::read_dta() instead R objects (.rda, .rdata, .Rdata), using base::load() R serialized objects (.rds), using base::readRDS() Clipboard (Windows Mac OS), using clipr::read_clip_tbl() formats, using rio::import()","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/import.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","text":"","code":"import(   file,   sheet = NULL,   range = NULL,   encoding = NULL,   header = \"auto\",   setclass = as,   as = \"data.frame\" )"},{"path":"https://psychbruce.github.io/bruceR/reference/import.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","text":"file File name (extension). unspecified, data imported clipboard. sheet [Excel] Excel sheet name (sheet number). Default first sheet. Ignored sheet specified via range. range [Excel] Excel cell range. Default cells sheet. may specify range=\"A1:E100\" range=\"Sheet1!A1:E100\". encoding File encoding. Default NULL. Alternatives can \"UTF-8\", \"GBK\", \"CP936\", etc. find messy code Chinese text imported data, usually effective set encoding=\"UTF-8\". header first row contain column names (TRUE FALSE)? Default \"auto\". setclass, Class imported data. Default \"data.frame\". Ignored data file R object (.rds, .rda, .rdata, .Rdata). Alternatives can : data.frame: \"data.frame\", \"df\", \"DF\" data.table: \"data.table\", \"dt\", \"DT\" tbl_df: \"tibble\", \"tbl_df\", \"tbl\"","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/import.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","text":"data object (default class data.frame).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/import.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data from a file (TXT, CSV, Excel, SPSS, Stata, ...) or clipboard. — import","text":"","code":"if (FALSE) {    # Import data from system clipboard   data = import()  # read from clipboard (on Windows and Mac OS)    # If you have an Excel file named \"mydata.xlsx\"   export(airquality, file=\"mydata.xlsx\")    # Import data from a file   data = import(\"mydata.xlsx\")  # default: data.frame   data = import(\"mydata.xlsx\", as=\"data.table\") }"},{"path":"https://psychbruce.github.io/bruceR/reference/lavaan_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of lavaan model. — lavaan_summary","title":"Tidy report of lavaan model. — lavaan_summary","text":"Tidy report lavaan model.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/lavaan_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of lavaan model. — lavaan_summary","text":"","code":"lavaan_summary(   lavaan,   ci = c(\"raw\", \"boot\", \"bc.boot\", \"bca.boot\"),   nsim = 100,   seed = NULL,   digits = 3,   nsmall = digits,   print = TRUE,   covariance = FALSE,   file = NULL )"},{"path":"https://psychbruce.github.io/bruceR/reference/lavaan_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of lavaan model. — lavaan_summary","text":"lavaan Model object fitted lavaan. ci Method estimating standard error (SE) 95% confidence interval (CI). Default \"raw\" (standard approach lavaan). options: \"boot\" Percentile Bootstrap \"bc.boot\" Bias-Corrected Percentile Bootstrap \"bca.boot\" Bias-Corrected Accelerated (BCa) Percentile Bootstrap nsim Number simulation samples (bootstrap resampling) estimating SE 95% CI. formal analyses, nsim=1000 (larger) strongly suggested. seed Random seed obtaining reproducible results. Default NULL. digits, nsmall Number decimal places output. Default 3. print Print results. Default TRUE. covariance Print (co)variances. Default FALSE. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/lavaan_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of lavaan model. — lavaan_summary","text":"Invisibly return list results: fit Model fit indices. measure Latent variable measures. regression Regression paths. covariance Variances /covariances. effect Defined effect estimates.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/lavaan_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of lavaan model. — lavaan_summary","text":"","code":"## Simple Mediation: ## Solar.R (X) => Ozone (M) => Temp (Y)  # PROCESS(airquality, y=\"Temp\", x=\"Solar.R\", #         meds=\"Ozone\", ci=\"boot\", nsim=1000, seed=1)  model = \" Ozone ~ a*Solar.R Temp ~ c.*Solar.R + b*Ozone Indirect := a*b Direct := c. Total := c. + a*b \" lv = lavaan::sem(model=model, data=airquality) lavaan::summary(lv, fit.measure=TRUE, ci=TRUE, nd=3)  # raw output #> lavaan 0.6-11 ended normally after 1 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         5 #>                                                        #>                                                   Used       Total #>   Number of observations                           111         153 #>                                                                    #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0 #>  #> Model Test Baseline Model: #>  #>   Test statistic                                89.294 #>   Degrees of freedom                                 3 #>   P-value                                        0.000 #>  #> User Model versus Baseline Model: #>  #>   Comparative Fit Index (CFI)                    1.000 #>   Tucker-Lewis Index (TLI)                       1.000 #>  #> Loglikelihood and Information Criteria: #>  #>   Loglikelihood user model (H0)               -908.632 #>   Loglikelihood unrestricted model (H1)       -908.632 #>                                                        #>   Akaike (AIC)                                1827.265 #>   Bayesian (BIC)                              1840.812 #>   Sample-size adjusted Bayesian (BIC)         1825.011 #>  #> Root Mean Square Error of Approximation: #>  #>   RMSEA                                          0.000 #>   90 Percent confidence interval - lower         0.000 #>   90 Percent confidence interval - upper         0.000 #>   P-value RMSEA <= 0.05                             NA #>  #> Standardized Root Mean Square Residual: #>  #>   SRMR                                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>   Ozone ~                                                                #>     Solar.R    (a)    0.127    0.032    3.915    0.000    0.064    0.191 #>   Temp ~                                                                 #>     Solar.R   (c.)    0.006    0.008    0.800    0.424   -0.009    0.021 #>     Ozone      (b)    0.194    0.021    9.390    0.000    0.154    0.235 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>    .Ozone           964.164  129.421    7.450    0.000  710.504 1217.825 #>    .Temp             45.821    6.151    7.450    0.000   33.766   57.876 #>  #> Defined Parameters: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>     Indirect          0.025    0.007    3.614    0.000    0.011    0.038 #>     Direct            0.006    0.008    0.800    0.424   -0.009    0.021 #>     Total             0.031    0.009    3.242    0.001    0.012    0.049 #>  lavaan_summary(lv) #>  #> Fit Measures (lavaan): #> χ²(0, N = 111) = 0.000, p = 1.000     #> χ²/df = NaN (saturated model) #> AIC = 1827.265 (Akaike Information Criterion) #> BIC = 1840.812 (Bayesian Information Criterion) #> CFI = 1.000 (Comparative Fit Index) #> TLI = 1.000 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 1.000 (Normed Fit Index) #> IFI = 1.000 (Incremental Fit Index) #> GFI = 1.000 (Goodness-of-Fit Index) #> AGFI = 1.000 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.000, 90% CI [0.000, 0.000] (Root Mean Square Error of Approximation) #> SRMR = 0.000 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ─────────────────────────────────────────────────────────────────────────── #>                         Estimate    S.E.     z     p       LLCI  ULCI  Beta #> ─────────────────────────────────────────────────────────────────────────── #> Regression Paths:                                                           #>   Ozone <- Solar.R (a)     0.127 (0.032) 3.915 <.001 ***  0.064 0.191 0.348 #>   Temp <- Solar.R (c.)     0.006 (0.008) 0.800  .424     -0.009 0.021 0.058 #>   Temp <- Ozone (b)        0.194 (0.021) 9.390 <.001 ***  0.154 0.235 0.678 #> Defined Effects:                                                            #>   Indirect                 0.025 (0.007) 3.614 <.001 ***  0.011 0.038 0.236 #>   Direct                   0.006 (0.008) 0.800  .424     -0.009 0.021 0.058 #>   Total                    0.031 (0.009) 3.242  .001 **   0.012 0.049 0.294 #> ─────────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  # lavaan_summary(lv, ci=\"boot\", nsim=1000, seed=1)   ## Serial Multiple Mediation: ## Solar.R (X) => Ozone (M1) => Wind(M2) => Temp (Y)  # PROCESS(airquality, y=\"Temp\", x=\"Solar.R\", #         meds=c(\"Ozone\", \"Wind\"), #         med.type=\"serial\", ci=\"boot\", nsim=1000, seed=1)  model0 = \" Ozone ~ a1*Solar.R Wind ~ a2*Solar.R + d12*Ozone Temp ~ c.*Solar.R + b1*Ozone + b2*Wind Indirect_All := a1*b1 + a2*b2 + a1*d12*b2 Ind_X_M1_Y := a1*b1 Ind_X_M2_Y := a2*b2 Ind_X_M1_M2_Y := a1*d12*b2 Direct := c. Total := c. + a1*b1 + a2*b2 + a1*d12*b2 \" lv0 = lavaan::sem(model=model0, data=airquality) lavaan::summary(lv0, fit.measure=TRUE, ci=TRUE, nd=3)  # raw output #> lavaan 0.6-11 ended normally after 1 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         9 #>                                                        #>                                                   Used       Total #>   Number of observations                           111         153 #>                                                                    #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0 #>  #> Model Test Baseline Model: #>  #>   Test statistic                               144.974 #>   Degrees of freedom                                 6 #>   P-value                                        0.000 #>  #> User Model versus Baseline Model: #>  #>   Comparative Fit Index (CFI)                    1.000 #>   Tucker-Lewis Index (TLI)                       1.000 #>  #> Loglikelihood and Information Criteria: #>  #>   Loglikelihood user model (H0)              -1178.664 #>   Loglikelihood unrestricted model (H1)      -1178.664 #>                                                        #>   Akaike (AIC)                                2375.329 #>   Bayesian (BIC)                              2399.715 #>   Sample-size adjusted Bayesian (BIC)         2371.273 #>  #> Root Mean Square Error of Approximation: #>  #>   RMSEA                                          0.000 #>   90 Percent confidence interval - lower         0.000 #>   90 Percent confidence interval - upper         0.000 #>   P-value RMSEA <= 0.05                             NA #>  #> Standardized Root Mean Square Residual: #>  #>   SRMR                                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>   Ozone ~                                                                #>     Solar.R   (a1)    0.127    0.032    3.915    0.000    0.064    0.191 #>   Wind ~                                                                 #>     Solar.R   (a2)    0.004    0.003    1.234    0.217   -0.002    0.010 #>     Ozone    (d12)   -0.069    0.008   -8.134    0.000   -0.086   -0.052 #>   Temp ~                                                                 #>     Solar.R   (c.)    0.007    0.008    0.965    0.334   -0.007    0.022 #>     Ozone     (b1)    0.172    0.026    6.637    0.000    0.121    0.223 #>     Wind      (b2)   -0.323    0.229   -1.410    0.159   -0.772    0.126 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>    .Ozone           964.164  129.421    7.450    0.000  710.504 1217.825 #>    .Wind              7.732    1.038    7.450    0.000    5.698    9.766 #>    .Temp             45.014    6.042    7.450    0.000   33.172   56.857 #>  #> Defined Parameters: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>     Indirect_All      0.023    0.007    3.378    0.001    0.010    0.037 #>     Ind_X_M1_Y        0.022    0.006    3.372    0.001    0.009    0.035 #>     Ind_X_M2_Y       -0.001    0.001   -0.928    0.353   -0.004    0.001 #>     Ind_X_M1_M2_Y     0.003    0.002    1.309    0.190   -0.001    0.007 #>     Direct            0.007    0.008    0.965    0.334   -0.007    0.022 #>     Total             0.031    0.009    3.242    0.001    0.012    0.049 #>  lavaan_summary(lv0) #>  #> Fit Measures (lavaan): #> χ²(0, N = 111) = 0.000, p = 1.000     #> χ²/df = NaN (saturated model) #> AIC = 2375.329 (Akaike Information Criterion) #> BIC = 2399.715 (Bayesian Information Criterion) #> CFI = 1.000 (Comparative Fit Index) #> TLI = 1.000 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 1.000 (Normed Fit Index) #> IFI = 1.000 (Incremental Fit Index) #> GFI = 1.000 (Goodness-of-Fit Index) #> AGFI = 1.000 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.000, 90% CI [0.000, 0.000] (Root Mean Square Error of Approximation) #> SRMR = 0.000 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ─────────────────────────────────────────────────────────────────────────────── #>                          Estimate    S.E.      z     p       LLCI   ULCI   Beta #> ─────────────────────────────────────────────────────────────────────────────── #> Regression Paths:                                                               #>   Ozone <- Solar.R (a1)     0.127 (0.032)  3.915 <.001 ***  0.064  0.191  0.348 #>   Wind <- Solar.R (a2)      0.004 (0.003)  1.234  .217     -0.002  0.010  0.098 #>   Wind <- Ozone (d12)      -0.069 (0.008) -8.134 <.001 *** -0.086 -0.052 -0.647 #>   Temp <- Solar.R (c.)      0.007 (0.008)  0.965  .334     -0.007  0.022  0.070 #>   Temp <- Ozone (b1)        0.172 (0.026)  6.637 <.001 ***  0.121  0.223  0.600 #>   Temp <- Wind (b2)        -0.323 (0.229) -1.410  .159     -0.772  0.126 -0.121 #> Defined Effects:                                                                #>   Indirect_All              0.023 (0.007)  3.378 <.001 ***  0.010  0.037  0.224 #>   Ind_X_M1_Y                0.022 (0.006)  3.372 <.001 ***  0.009  0.035  0.209 #>   Ind_X_M2_Y               -0.001 (0.001) -0.928  .353     -0.004  0.001 -0.012 #>   Ind_X_M1_M2_Y             0.003 (0.002)  1.309  .190     -0.001  0.007  0.027 #>   Direct                    0.007 (0.008)  0.965  .334     -0.007  0.022  0.070 #>   Total                     0.031 (0.009)  3.242  .001 **   0.012  0.049  0.294 #> ─────────────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  # lavaan_summary(lv0, ci=\"boot\", nsim=1000, seed=1)  model1 = \" Ozone ~ a1*Solar.R Wind ~ d12*Ozone Temp ~ c.*Solar.R + b1*Ozone + b2*Wind Indirect_All := a1*b1 + a1*d12*b2 Ind_X_M1_Y := a1*b1 Ind_X_M1_M2_Y := a1*d12*b2 Direct := c. Total := c. + a1*b1 + a1*d12*b2 \" lv1 = lavaan::sem(model=model1, data=airquality) lavaan::summary(lv1, fit.measure=TRUE, ci=TRUE, nd=3)  # raw output #> lavaan 0.6-11 ended normally after 1 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         8 #>                                                        #>                                                   Used       Total #>   Number of observations                           111         153 #>                                                                    #> Model Test User Model: #>                                                        #>   Test statistic                                 1.512 #>   Degrees of freedom                                 1 #>   P-value (Chi-square)                           0.219 #>  #> Model Test Baseline Model: #>  #>   Test statistic                               144.974 #>   Degrees of freedom                                 6 #>   P-value                                        0.000 #>  #> User Model versus Baseline Model: #>  #>   Comparative Fit Index (CFI)                    0.996 #>   Tucker-Lewis Index (TLI)                       0.978 #>  #> Loglikelihood and Information Criteria: #>  #>   Loglikelihood user model (H0)              -1179.420 #>   Loglikelihood unrestricted model (H1)      -1178.664 #>                                                        #>   Akaike (AIC)                                2374.840 #>   Bayesian (BIC)                              2396.517 #>   Sample-size adjusted Bayesian (BIC)         2371.235 #>  #> Root Mean Square Error of Approximation: #>  #>   RMSEA                                          0.068 #>   90 Percent confidence interval - lower         0.000 #>   90 Percent confidence interval - upper         0.273 #>   P-value RMSEA <= 0.05                          0.281 #>  #> Standardized Root Mean Square Residual: #>  #>   SRMR                                           0.028 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>   Ozone ~                                                                #>     Solar.R   (a1)    0.127    0.032    3.915    0.000    0.064    0.191 #>   Wind ~                                                                 #>     Ozone    (d12)   -0.065    0.008   -8.164    0.000   -0.081   -0.050 #>   Temp ~                                                                 #>     Solar.R   (c.)    0.007    0.007    0.972    0.331   -0.007    0.022 #>     Ozone     (b1)    0.172    0.025    6.784    0.000    0.122    0.222 #>     Wind      (b2)   -0.323    0.227   -1.420    0.156   -0.769    0.123 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>    .Ozone           964.164  129.421    7.450    0.000  710.504 1217.825 #>    .Wind              7.838    1.052    7.450    0.000    5.776    9.900 #>    .Temp             45.014    6.042    7.450    0.000   33.172   56.857 #>  #> Defined Parameters: #>                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper #>     Indirect_All      0.025    0.007    3.611    0.000    0.011    0.038 #>     Ind_X_M1_Y        0.022    0.006    3.391    0.001    0.009    0.035 #>     Ind_X_M1_M2_Y     0.003    0.002    1.317    0.188   -0.001    0.007 #>     Direct            0.007    0.007    0.972    0.331   -0.007    0.022 #>     Total             0.032    0.009    3.380    0.001    0.013    0.050 #>  lavaan_summary(lv1) #>  #> Fit Measures (lavaan): #> χ²(1, N = 111) = 1.512, p = 0.219     #> χ²/df = 1.512 #> AIC = 2374.840 (Akaike Information Criterion) #> BIC = 2396.517 (Bayesian Information Criterion) #> CFI = 0.996 (Comparative Fit Index) #> TLI = 0.978 (Tucker-Lewis Index; Non-Normed Fit Index, NNFI) #> NFI = 0.990 (Normed Fit Index) #> IFI = 0.996 (Incremental Fit Index) #> GFI = 0.991 (Goodness-of-Fit Index) #> AGFI = 0.911 (Adjusted Goodness-of-Fit Index) #> RMSEA = 0.068, 90% CI [0.000, 0.273] (Root Mean Square Error of Approximation) #> SRMR = 0.028 (Standardized Root Mean Square Residual) #>  #> Model Estimates (lavaan): #> ─────────────────────────────────────────────────────────────────────────────── #>                          Estimate    S.E.      z     p       LLCI   ULCI   Beta #> ─────────────────────────────────────────────────────────────────────────────── #> Regression Paths:                                                               #>   Ozone <- Solar.R (a1)     0.127 (0.032)  3.915 <.001 ***  0.064  0.191  0.348 #>   Wind <- Ozone (d12)      -0.065 (0.008) -8.164 <.001 *** -0.081 -0.050 -0.612 #>   Temp <- Solar.R (c.)      0.007 (0.007)  0.972  .331     -0.007  0.022  0.070 #>   Temp <- Ozone (b1)        0.172 (0.025)  6.784 <.001 ***  0.122  0.222  0.600 #>   Temp <- Wind (b2)        -0.323 (0.227) -1.420  .156     -0.769  0.123 -0.120 #> Defined Effects:                                                                #>   Indirect_All              0.025 (0.007)  3.611 <.001 ***  0.011  0.038  0.235 #>   Ind_X_M1_Y                0.022 (0.006)  3.391 <.001 ***  0.009  0.035  0.209 #>   Ind_X_M1_M2_Y             0.003 (0.002)  1.317  .188     -0.001  0.007  0.026 #>   Direct                    0.007 (0.007)  0.972  .331     -0.007  0.022  0.070 #>   Total                     0.032 (0.009)  3.380 <.001 ***  0.013  0.050  0.304 #> ─────────────────────────────────────────────────────────────────────────────── #> Note. Raw (Standard) Confidence Interval (CI) and SE. #>  # lavaan_summary(lv1, ci=\"boot\", nsim=1000, seed=1)"},{"path":"https://psychbruce.github.io/bruceR/reference/med_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of mediation analysis. — med_summary","title":"Tidy report of mediation analysis. — med_summary","text":"Tidy report mediation analysis, performed using mediation package.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/med_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of mediation analysis. — med_summary","text":"","code":"med_summary(model, digits = 3, nsmall = digits, file = NULL)"},{"path":"https://psychbruce.github.io/bruceR/reference/med_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of mediation analysis. — med_summary","text":"model Mediation model built using mediation::mediate(). digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/med_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of mediation analysis. — med_summary","text":"Invisibly return data frame containing results.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/med_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of mediation analysis. — med_summary","text":"","code":"if (FALSE) {  library(mediation) # ?mediation::mediate  ## Example 1: OLS Regression ## Bias-corrected and accelerated (BCa) bootstrap confidence intervals  ## Hypothesis: Solar radiation -> Ozone -> Daily temperature lm.m = lm(Ozone ~ Solar.R + Month + Wind, data=airquality) lm.y = lm(Temp ~ Ozone + Solar.R + Month + Wind, data=airquality) set.seed(123)  # set a random seed for reproduction med = mediate(lm.m, lm.y,             treat=\"Solar.R\", mediator=\"Ozone\",             sims=1000, boot=TRUE, boot.ci.type=\"bca\") med_summary(med)  ## Example 2: Multilevel Linear Model (Linear Mixed Model) ## (models must be fit using \"lme4::lmer\" rather than \"lmerTest::lmer\") ## Monte Carlo simulation (quasi-Bayesian approximation) ## (bootstrap method is not applicable to \"lmer\" models)  ## Hypothesis: Crips -> Sweetness -> Preference (for carrots) data = lmerTest::carrots  # long-format data data = na.omit(data)  # omit missing values lmm.m = lme4::lmer(Sweetness ~ Crisp + Gender + Age + (1 | Consumer), data=data) lmm.y = lme4::lmer(Preference ~ Sweetness + Crisp + Gender + Age + (1 | Consumer), data=data) set.seed(123)  # set a random seed for reproduction med.lmm = mediate(lmm.m, lmm.y,                   treat=\"Crisp\", mediator=\"Sweetness\",                   sims=1000) med_summary(med.lmm) }"},{"path":"https://psychbruce.github.io/bruceR/reference/model_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy report of regression models. — model_summary","title":"Tidy report of regression models. — model_summary","text":"Tidy report regression models (model types supported). function uses: texreg::screenreg() texreg::htmlreg() MuMIn::std.coef() MuMIn::r.squaredGLMM() performance::r2_mcfadden() performance::r2_nagelkerke()","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/model_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy report of regression models. — model_summary","text":"","code":"model_summary(   model.list,   std = FALSE,   digits = 3,   nsmall = digits,   file = NULL,   check = TRUE,   zero = ifelse(std, FALSE, TRUE),   modify.se = NULL,   modify.head = NULL,   line = TRUE,   bold = 0,   ... )"},{"path":"https://psychbruce.github.io/bruceR/reference/model_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy report of regression models. — model_summary","text":"model.list single model list (various types ) models. types regression models supported! std Standardized coefficients? Default FALSE. applicable linear models linear mixed models. applicable generalized linear (mixed) models. digits, nsmall Number decimal places output. Default 3. file File name MS Word (.doc). check one model model.list, checks multicollinearity using performance::check_collinearity(). may turn setting check=FALSE. zero Display \"0\" \".\"? Default TRUE. modify.se Replace standard errors. Useful need replace raw SEs robust SEs. New SEs provided list numeric vectors. See usage texreg::screenreg(). modify.head Replace model names. line Lines look like true line (TRUE) === --- === (FALSE). relevant R Console output. bold p-value threshold coefficients formatted bold. ... arguments passed texreg::screenreg() texreg::htmlreg().","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/model_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy report of regression models. — model_summary","text":"Invisibly return output (character string).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/model_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy report of regression models. — model_summary","text":"","code":"#### Example 1: Linear Model #### lm1 = lm(Temp ~ Month + Day, data=airquality) lm2 = lm(Temp ~ Month + Day + Wind + Solar.R, data=airquality) model_summary(lm1) #>  #> Model Summary #>  #> ──────────────────────── #>              (1) Temp    #> ──────────────────────── #> (Intercept)   60.406 *** #>               (3.718)    #> Month          2.806 *** #>               (0.490)    #> Day           -0.136     #>               (0.078)    #> ──────────────────────── #> R^2            0.193     #> Adj. R^2       0.183     #> Num. obs.    153         #> ──────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> # Check for Multicollinearity #>  #> Low Correlation #>  #>   Term  VIF Increased SE Tolerance #>  Month 1.00         1.00      1.00 #>    Day 1.00         1.00      1.00 #>  model_summary(lm2) #>  #> Model Summary #>  #> ──────────────────────── #>              (1) Temp    #> ──────────────────────── #> (Intercept)   68.770 *** #>               (4.391)    #> Month          2.225 *** #>               (0.441)    #> Day           -0.084     #>               (0.070)    #> Wind          -1.003 *** #>               (0.176)    #> Solar.R        0.027 *** #>               (0.007)    #> ──────────────────────── #> R^2            0.387     #> Adj. R^2       0.369     #> Num. obs.    146         #> ──────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> # Check for Multicollinearity #>  #> Low Correlation #>  #>     Term  VIF Increased SE Tolerance #>    Month 1.03         1.02      0.97 #>      Day 1.02         1.01      0.98 #>     Wind 1.03         1.02      0.97 #>  Solar.R 1.03         1.02      0.97 #>  model_summary(list(lm1, lm2)) #>  #> Model Summary #>  #> ───────────────────────────────────── #>              (1) Temp     (2) Temp    #> ───────────────────────────────────── #> (Intercept)   60.406 ***   68.770 *** #>               (3.718)      (4.391)    #> Month          2.806 ***    2.225 *** #>               (0.490)      (0.441)    #> Day           -0.136       -0.084     #>               (0.078)      (0.070)    #> Wind                       -1.003 *** #>                            (0.176)    #> Solar.R                     0.027 *** #>                            (0.007)    #> ───────────────────────────────────── #> R^2            0.193        0.387     #> Adj. R^2       0.183        0.369     #> Num. obs.    153          146         #> ───────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(lm1, lm2), std=TRUE, digits=2) #>  #> Model Summary #>  #> ───────────────────────────────── #>            (1) Temp    (2) Temp   #> ───────────────────────────────── #> Month         .42 ***     .34 *** #>              (.07)       (.07)    #> Day          -.13        -.08     #>              (.07)       (.07)    #> Wind                     -.38 *** #>                          (.07)    #> Solar.R                   .27 *** #>                          (.07)    #> ───────────────────────────────── #> R^2           .19         .39     #> Adj. R^2      .18         .37     #> Num. obs.  153         146        #> ───────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(lm1, lm2), file=\"OLS Models.doc\") #> √ Table saved to '/tmp/RtmpKFkSfK/file3dd048afc62e/reference/OLS Models.doc' #>  unlink(\"OLS Models.doc\")  # delete file for code check  #### Example 2: Generalized Linear Model #### glm1 = glm(case ~ age + parity,            data=infert, family=binomial) glm2 = glm(case ~ age + parity + education + spontaneous + induced,            data=infert, family=binomial) model_summary(list(glm1, glm2))  # \"std\" is not applicable to glm #>  #> Model Summary #>  #> ─────────────────────────────────────── #>                   (1) case  (2) case    #> ─────────────────────────────────────── #> (Intercept)        -0.754    -1.149     #>                    (0.836)   (1.412)    #> age                 0.001     0.040     #>                    (0.026)   (0.031)    #> parity              0.015    -0.828 *** #>                    (0.108)   (0.196)    #> education6-11yrs             -1.044     #>                              (0.793)    #> education12+ yrs             -1.403     #>                              (0.834)    #> spontaneous                   2.046 *** #>                              (0.310)    #> induced                       1.289 *** #>                              (0.301)    #> ─────────────────────────────────────── #> McFadden's R^2      0.000     0.185     #> Nagelkerke's R^2    0.000     0.291     #> AIC               322.150   271.798     #> BIC               332.690   296.392     #> Num. obs.         248       248         #> ─────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(glm1, glm2), file=\"GLM Models.doc\") #> √ Table saved to '/tmp/RtmpKFkSfK/file3dd048afc62e/reference/GLM Models.doc' #>  unlink(\"GLM Models.doc\")  # delete file for code check  #### Example 3: Linear Mixed Model #### library(lmerTest) hlm1 = lmer(Reaction ~ (1 | Subject), data=sleepstudy) hlm2 = lmer(Reaction ~ Days + (1 | Subject), data=sleepstudy) hlm3 = lmer(Reaction ~ Days + (Days | Subject), data=sleepstudy) model_summary(list(hlm1, hlm2, hlm3)) #>  #> Model Summary #>  #> ─────────────────────────────────────────────────────────────────────── #>                                (1) Reaction  (2) Reaction  (3) Reaction #> ─────────────────────────────────────────────────────────────────────── #> (Intercept)                     298.508 ***   251.405 ***   251.405 *** #>                                  (9.050)       (9.747)       (6.825)    #> Days                                           10.467 ***    10.467 *** #>                                                (0.804)       (1.546)    #> ─────────────────────────────────────────────────────────────────────── #> Marginal R^2                      0.000         0.280         0.279     #> Conditional R^2                   0.395         0.704         0.799     #> AIC                            1910.327      1794.465      1755.628     #> BIC                            1919.905      1807.237      1774.786     #> Num. obs.                       180           180           180         #> Num. groups: Subject             18            18            18         #> Var: Subject (Intercept)       1278.338      1378.179       612.100     #> Var: Residual                  1958.865       960.457       654.940     #> Var: Subject Days                                            35.072     #> Cov: Subject (Intercept) Days                                 9.604     #> ─────────────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(hlm1, hlm2, hlm3), std=TRUE) #>  #> Model Summary #>  #> ─────────────────────────────────────────────────────────────────────── #>                                (1) Reaction  (2) Reaction  (3) Reaction #> ─────────────────────────────────────────────────────────────────────── #> Days                                             .535 ***      .535 *** #>                                                 (.041)        (.079)    #> ─────────────────────────────────────────────────────────────────────── #> Marginal R^2                       .000          .280          .279     #> Conditional R^2                    .395          .704          .799     #> AIC                            1910.327      1794.465      1755.628     #> BIC                            1919.905      1807.237      1774.786     #> Num. obs.                       180           180           180         #> Num. groups: Subject             18            18            18         #> Var: Subject (Intercept)       1278.338      1378.179       612.100     #> Var: Residual                  1958.865       960.457       654.940     #> Var: Subject Days                                            35.072     #> Cov: Subject (Intercept) Days                                 9.604     #> ─────────────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(hlm1, hlm2, hlm3), file=\"HLM Models.doc\") #> √ Table saved to '/tmp/RtmpKFkSfK/file3dd048afc62e/reference/HLM Models.doc' #>  unlink(\"HLM Models.doc\")  # delete file for code check  #### Example 4: Generalized Linear Mixed Model #### library(lmerTest) data.glmm = MASS::bacteria glmm1 = glmer(y ~ trt + week + (1 | ID), data=data.glmm, family=binomial) glmm2 = glmer(y ~ trt + week + hilo + (1 | ID), data=data.glmm, family=binomial) model_summary(list(glmm1, glmm2))  # \"std\" is not applicable to glmm #>  #> Model Summary #>  #> ───────────────────────────────────────────── #>                      (1) y        (2) y       #> ───────────────────────────────────────────── #> (Intercept)            3.144 ***    3.399 *** #>                       (0.622)      (0.736)    #> trtdrug               -1.320 *     -0.928     #>                       (0.642)      (0.802)    #> trtdrug+              -0.795       -1.061     #>                       (0.652)      (0.751)    #> week                  -0.144 **    -0.144 **  #>                       (0.051)      (0.051)    #> hilolo                             -0.656     #>                                    (0.876)    #> ───────────────────────────────────────────── #> AIC                  207.771      209.217     #> BIC                  224.739      229.579     #> Num. obs.            220          220         #> Num. groups: ID       50           50         #> Var: ID (Intercept)    1.314        1.254     #> ───────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(list(glmm1, glmm2), file=\"GLMM Models.doc\") #> √ Table saved to '/tmp/RtmpKFkSfK/file3dd048afc62e/reference/GLMM Models.doc' #>  unlink(\"GLMM Models.doc\")  # delete file for code check  #### Example 5: Multinomial Logistic Model #### library(nnet) d = airquality d$Month = as.factor(d$Month)  # Factor levels: 5, 6, 7, 8, 9 mn1 = multinom(Month ~ Temp, data=d, Hess=TRUE) #> # weights:  15 (8 variable) #> initial  value 246.244001  #> iter  10 value 196.357608 #> final  value 194.725454  #> converged mn2 = multinom(Month ~ Temp + Wind + Ozone, data=d, Hess=TRUE) #> # weights:  25 (16 variable) #> initial  value 186.694798  #> iter  10 value 168.210554 #> iter  20 value 139.276111 #> iter  30 value 137.478576 #> final  value 137.466340  #> converged model_summary(mn1) #>  #> Model Summary #>  #> ─────────────────────────────────────────────────────────────── #>              6            7            8            9           #> ─────────────────────────────────────────────────────────────── #> (Intercept)  -20.275 ***  -29.489 ***  -29.629 ***  -16.484 *** #>               (4.089)      (4.730)      (4.738)      (3.731)    #> Temp           0.280 ***    0.393 ***    0.395 ***    0.231 *** #>               (0.056)      (0.063)      (0.063)      (0.052)    #> ─────────────────────────────────────────────────────────────── #> AIC          405.451      405.451      405.451      405.451     #> BIC          429.694      429.694      429.694      429.694     #> Num. obs.    153          153          153          153         #> K              5            5            5            5         #> ─────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  model_summary(mn2) #>  #> Model Summary #>  #> ─────────────────────────────────────────────────────────────── #>              6            7            8            9           #> ─────────────────────────────────────────────────────────────── #> (Intercept)  -27.752 ***  -27.079 ***  -27.212 ***  -17.641 *** #>               (7.316)      (5.944)      (5.948)      (4.772)    #> Temp           0.346 ***    0.364 ***    0.363 ***    0.261 *** #>               (0.094)      (0.076)      (0.076)      (0.063)    #> Wind           0.223        0.027        0.040       -0.007     #>               (0.147)      (0.138)      (0.137)      (0.120)    #> Ozone         -0.039       -0.016       -0.014       -0.032     #>               (0.027)      (0.016)      (0.015)      (0.017)    #> ─────────────────────────────────────────────────────────────── #> AIC          306.933      306.933      306.933      306.933     #> BIC          350.990      350.990      350.990      350.990     #> Num. obs.    116          116          116          116         #> K              5            5            5            5         #> ─────────────────────────────────────────────────────────────── #> Note. * p < .05, ** p < .01, *** p < .001. #>  #> # Check for Multicollinearity #>  #> Low Correlation #>  #>   Term  VIF Increased SE Tolerance #>   Temp 2.84         1.68      0.35 #>   Wind 1.95         1.40      0.51 #>  Ozone 2.36         1.54      0.42 #>  model_summary(mn2, file=\"Multinomial Logistic Model.doc\") #> √ Table saved to '/tmp/RtmpKFkSfK/file3dd048afc62e/reference/Multinomial Logistic Model.doc' #>  unlink(\"Multinomial Logistic Model.doc\")  # delete file for code check"},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute p value. — p","title":"Compute p value. — p","text":"Compute p value.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute p value. — p","text":"","code":"p(   z = NULL,   t = NULL,   f = NULL,   r = NULL,   chi2 = NULL,   n = NULL,   df = NULL,   df1 = NULL,   df2 = NULL,   digits = 2,   nsmall = digits )  p.z(z)  p.t(t, df)  p.f(f, df1, df2)  p.r(r, n)  p.chi2(chi2, df)"},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute p value. — p","text":"z, t, f, r, chi2 z, t, F, r, \\(\\chi\\)^2 value. n, df, df1, df2 Sample size degree freedom. digits, nsmall Number decimal places output. Default 2.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute p value. — p","text":"p value statistics.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Compute p value. — p","text":"p.z: Two-tailed p value z. p.t: Two-tailed p value t. p.f: One-tailed p value F. (Note: F test one-tailed .) p.r: Two-tailed p value r. p.chi2: One-tailed p value \\(\\chi\\)^2. (Note: \\(\\chi\\)^2 test one-tailed .)","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute p value. — p","text":"","code":"p.z(1.96) #> [1] 0.04999579 p.t(2, 100) #> [1] 0.04821218 p.f(4, 1, 100) #> [1] 0.04821218 p.r(0.2, 100) #> [1] 0.04603629 p.chi2(3.84, 1) #> [1] 0.05004352  p(z=1.96) #> z = 1.96, p = 0.050 *   p(t=2, df=100) #> t(100) = 2.00, p = 0.048 *   p(f=4, df1=1, df2=100) #> F(1, 100) = 4.00, p = 0.048 *   p(r=0.2, n=100) #> r(98) = 0.20, p = 0.046 *   p(chi2=3.84, df=1) #> χ²(1) = 3.84, p = 0.050 ."},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_depend.html","id":null,"dir":"Reference","previous_headings":"","what":"Check dependencies of R packages. — pkg_depend","title":"Check dependencies of R packages. — pkg_depend","text":"Check dependencies R packages.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_depend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check dependencies of R packages. — pkg_depend","text":"","code":"pkg_depend(pkgs, excludes = NULL)"},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_depend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check dependencies of R packages. — pkg_depend","text":"pkgs Package(s). excludes [Optional] Package(s) dependencies excluded dependencies pkgs. Useful want see unique dependencies pkgs.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_depend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check dependencies of R packages. — pkg_depend","text":"character vector package names.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_install_suggested.html","id":null,"dir":"Reference","previous_headings":"","what":"Install suggested R packages. — pkg_install_suggested","title":"Install suggested R packages. — pkg_install_suggested","text":"Install suggested R packages.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_install_suggested.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install suggested R packages. — pkg_install_suggested","text":"","code":"pkg_install_suggested(by)"},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_install_suggested.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install suggested R packages. — pkg_install_suggested","text":"Suggested package?","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_install_suggested.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install suggested R packages. — pkg_install_suggested","text":"return value.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/pkg_install_suggested.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install suggested R packages. — pkg_install_suggested","text":"","code":"if (FALSE) {  pkg_install_suggested()  # install all packages suggested by me }"},{"path":"https://psychbruce.github.io/bruceR/reference/print_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a three-line table (to R Console and Microsoft Word). — print_table","title":"Print a three-line table (to R Console and Microsoft Word). — print_table","text":"basic function prints data frame three-line table either R Console Microsoft Word (.doc). used many functions bruceR (see ).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/print_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a three-line table (to R Console and Microsoft Word). — print_table","text":"","code":"print_table(   x,   digits = 3,   nsmalls = digits,   nspaces = 1,   row.names = TRUE,   col.names = TRUE,   title = \"\",   note = \"\",   append = \"\",   line = TRUE,   file = NULL,   file.align.head = \"auto\",   file.align.text = \"auto\" )"},{"path":"https://psychbruce.github.io/bruceR/reference/print_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a three-line table (to R Console and Microsoft Word). — print_table","text":"x Matrix, data.frame (data.table), model object (e.g., lm, glm, lmer, glmer, ...). digits, nsmalls Numeric vector specifying number decimal places output. Default 3. nspaces Number whitespaces columns. Default 1. row.names, col.names Print row/column names. Default TRUE (column names always printed). modify names, can use character vector length raw names. title Title text, inserted <p><\/p> (HTML code). note Note text, inserted <p><\/p> (HTML code). append contents, appended end (HTML code). line Lines looks like true line (TRUE) === --- === (FALSE). file File name MS Word (.doc). file.align.head, file.align.text Alignment table head table text: \"left\", \"right\", \"center\". Either one value character vector mixed values length table columns. Default alignment (set \"auto\"): left, right, right, ..., right.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/print_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a three-line table (to R Console and Microsoft Word). — print_table","text":"Invisibly return list data frame HTML code.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/print_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a three-line table (to R Console and Microsoft Word). — print_table","text":"","code":"print_table(data.frame(x=1)) #> ──────── #>        x #> ──────── #> 1  1.000 #> ────────  print_table(airquality, file=\"airquality.doc\") #> √ Table saved to \"/tmp/RtmpKFkSfK/file3dd048afc62e/reference/airquality.doc\" #>  unlink(\"airquality.doc\")  # delete file for code check  model = lm(Temp ~ Month + Day + Wind + Solar.R, data=airquality) print_table(model) #> ────────────────────────────────────────────── #>              Estimate    S.E.      t     p     #> ────────────────────────────────────────────── #> (Intercept)    68.770 (4.391) 15.662 <.001 *** #> Month           2.225 (0.441)  5.047 <.001 *** #> Day            -0.084 (0.070) -1.194  .234     #> Wind           -1.003 (0.176) -5.695 <.001 *** #> Solar.R         0.027 (0.007)  3.991 <.001 *** #> ────────────────────────────────────────────── print_table(model, file=\"model.doc\") #> √ Table saved to \"/tmp/RtmpKFkSfK/file3dd048afc62e/reference/model.doc\" #>  unlink(\"model.doc\")  # delete file for code check"},{"path":"https://psychbruce.github.io/bruceR/reference/regress.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression analysis. — regress","title":"Regression analysis. — regress","text":"NOTE: model_summary preferred.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/regress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression analysis. — regress","text":"","code":"regress(   formula,   data,   family = NULL,   digits = 3,   nsmall = digits,   robust = FALSE,   cluster = NULL,   test.rand = FALSE )"},{"path":"https://psychbruce.github.io/bruceR/reference/regress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression analysis. — regress","text":"formula Model formula. data Data frame. family [Optional] glm glmer (e.g., family=binomial fits logistic regression model). digits, nsmall Number decimal places output. Default 3. robust [lm glm] FALSE (default), TRUE (default \"HC1\"), \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". add table heteroskedasticity-robust standard errors (aka. Huber-White standard errors). details, see ?sandwich::vcovHC ?jtools::summ.lm. *** \"HC1\" default Stata, whereas \"HC3\" default suggested sandwich package. cluster [lm glm] Cluster-robust standard errors computed cluster set name input data's cluster variable vector clusters. test.rand [lmer glmer] TRUE FALSE (default). Test random effects (.e., variance components) using likelihood-ratio test (LRT), asymptotically chi-square distributed. large datasets, much time-consuming.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/regress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression analysis. — regress","text":"return value.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/regress.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression analysis. — regress","text":"","code":"if (FALSE) {    ## lm   regress(Temp ~ Month + Day + Wind + Solar.R, data=airquality, robust=TRUE)    ## glm   regress(case ~ age + parity + education + spontaneous + induced,           data=infert, family=binomial, robust=\"HC1\", cluster=\"stratum\")    ## lmer   library(lmerTest)   regress(Reaction ~ Days + (Days | Subject), data=sleepstudy)   regress(Preference ~ Sweetness + Gender + Age + Frequency +             (1 | Consumer), data=carrots)    ## glmer   library(lmerTest)   data.glmm = MASS::bacteria   regress(y ~ trt + week + (1 | ID), data=data.glmm, family=binomial)   regress(y ~ trt + week + hilo + (1 | ID), data=data.glmm, family=binomial) }"},{"path":"https://psychbruce.github.io/bruceR/reference/rep_char.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat a character string for many times and paste them up. — rep_char","title":"Repeat a character string for many times and paste them up. — rep_char","text":"Repeat character string many times paste .","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/rep_char.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat a character string for many times and paste them up. — rep_char","text":"","code":"rep_char(char, rep.times)"},{"path":"https://psychbruce.github.io/bruceR/reference/rep_char.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat a character string for many times and paste them up. — rep_char","text":"char Character string. rep.times Times repeat.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/rep_char.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat a character string for many times and paste them up. — rep_char","text":"Character string.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/rep_char.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeat a character string for many times and paste them up. — rep_char","text":"","code":"rep_char(\"a\", 5) #> [1] \"aaaaa\""},{"path":"https://psychbruce.github.io/bruceR/reference/scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"Min-max scaling (min-max normalization). — scaler","title":"Min-max scaling (min-max normalization). — scaler","text":"function resembles RESCALE() just equivalent RESCALE(var, =0:1).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Min-max scaling (min-max normalization). — scaler","text":"","code":"scaler(v, min = 0, max = 1)"},{"path":"https://psychbruce.github.io/bruceR/reference/scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Min-max scaling (min-max normalization). — scaler","text":"v Variable (numeric vector). min Minimum value (default 0). max Maximum value (default 1).","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Min-max scaling (min-max normalization). — scaler","text":"vector rescaled variable.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/scaler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Min-max scaling (min-max normalization). — scaler","text":"","code":"scaler(1:5) #> [1] 0.00 0.25 0.50 0.75 1.00 # the same: RESCALE(1:5, to=0:1)"},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set working directory to the path of currently opened file. — set.wd","title":"Set working directory to the path of currently opened file. — set.wd","text":"Set working directory path currently opened file (usually R script). can use function .R/.Rmd files R Console. RStudio (version >= 1.2) required running function.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set working directory to the path of currently opened file. — set.wd","text":"","code":"set.wd(path = NULL, ask = FALSE)  set_wd(path = NULL, ask = FALSE)"},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set working directory to the path of currently opened file. — set.wd","text":"path NULL (default) specific path. Default extract path currently opened file (usually .R .Rmd) using rstudioapi::getSourceEditorContext function. ask TRUE FALSE (default). TRUE, can select folder prompt dialog.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set working directory to the path of currently opened file. — set.wd","text":"Invisibly return path.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Set working directory to the path of currently opened file. — set.wd","text":"set.wd: Main function set_wd: alias set.wd ()","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/reference/set.wd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set working directory to the path of currently opened file. — set.wd","text":"","code":"if (FALSE) {    # RStudio (version >= 1.2) is required for running this function.   set.wd()  # set working directory to the path of the currently opened file   set.wd(\"~/\")  # set working directory to the home path   set.wd(\"../\")  # set working directory to the parent path   set.wd(ask=TRUE)  # select a folder with the prompt of a dialog }"},{"path":"https://psychbruce.github.io/bruceR/reference/show_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Show colors. — show_colors","title":"Show colors. — show_colors","text":"Show colors.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/show_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show colors. — show_colors","text":"","code":"show_colors(colors = see::social_colors())"},{"path":"https://psychbruce.github.io/bruceR/reference/show_colors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show colors. — show_colors","text":"colors Color names. e.g., \"red\" (R base color names) \"#FF0000\" (hex color names) see::social_colors() viridis::viridis_pal()(10) RColorBrewer::brewer.pal(name=\"Set1\", n=9) RColorBrewer::brewer.pal(name=\"Set2\", n=8) RColorBrewer::brewer.pal(name=\"Spectral\", n=11)","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/show_colors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show colors. — show_colors","text":"gg object.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/show_colors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show colors. — show_colors","text":"","code":"show_colors()  # default is to show see::social_colors()  show_colors(\"blue\")  # blue  show_colors(\"#0000FF\")  # blue (hex name)  show_colors(RGB(0, 0, 255))  # blue (RGB)  show_colors(see::pizza_colors())  # a specific palette"},{"path":"https://psychbruce.github.io/bruceR/reference/theme_bruce.html","id":null,"dir":"Reference","previous_headings":"","what":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","title":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","text":"nice ggplot2 theme scientific publication. uses ggtext::element_markdown() render Markdown/HTML formatted rich text. can use combination Markdown /HTML syntax (e.g., \"*y* = *x*<sup>2<\/sup>\") plot text title, function draws text elements rich text format. usage, see: ggtext::geom_richtext() ggtext::geom_textbox() ggtext::element_markdown() ggtext::element_textbox()","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/theme_bruce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","text":"","code":"theme_bruce(   markdown = FALSE,   base.size = 12,   line.size = 0.5,   border = \"black\",   bg = \"white\",   panel.bg = \"white\",   tag = \"bold\",   plot.title = \"bold\",   axis.title = \"plain\",   title.pos = 0.5,   subtitle.pos = 0.5,   caption.pos = 1,   font = NULL,   grid.x = \"\",   grid.y = \"\",   line.x = TRUE,   line.y = TRUE,   tick.x = TRUE,   tick.y = TRUE )"},{"path":"https://psychbruce.github.io/bruceR/reference/theme_bruce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","text":"markdown Use element_markdown() instead element_text(). Default FALSE. set TRUE, also use element_markdown() theme() (). base.size Basic font size. Default 12. line.size Line width. Default 0.5. border TRUE, FALSE, \"black\" (default). bg Background color whole plot. Default \"white\". can use colors choose pre-set color palettes: \"stata\", \"stata.grey\", \"solar\", \"wsj\", \"light\", \"dust\". see colors, can type: ggthemr::colour_plot(c(stata=\"#EAF2F3\", stata.grey=\"#E8E8E8\", solar=\"#FDF6E3\", wsj=\"#F8F2E4\", light=\"#F6F1EB\", dust=\"#FAF7F2\")) panel.bg Background color panel. Default \"white\". tag Font face tag. Choose \"plain\", \"italic\", \"bold\", \"bold.italic\". plot.title Font face title. Choose \"plain\", \"italic\", \"bold\", \"bold.italic\". axis.title Font face axis text. Choose \"plain\", \"italic\", \"bold\", \"bold.italic\". title.pos Title position (0~1). subtitle.pos Subtitle position (0~1). caption.pos Caption position (0~1). font Text font. applicable Windows system. grid.x FALSE, \"\" (default), color (e.g., \"grey90\") set color panel grid (x). grid.y FALSE, \"\" (default), color (e.g., \"grey90\") set color panel grid (y). line.x Draw x-axis line. Default TRUE. line.y Draw y-axis line. Default TRUE. tick.x Draw x-axis ticks. Default TRUE. tick.y Draw y-axis ticks. Default TRUE.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/theme_bruce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","text":"theme object used ggplot2.","code":""},{"path":"https://psychbruce.github.io/bruceR/reference/theme_bruce.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A nice ggplot2 theme that enables Markdown/HTML rich text. — theme_bruce","text":"","code":"## Example 1 (bivariate correlation) d = as.data.table(psych::bfi) added(d, {   E = .mean(\"E\", 1:5, rev=c(1,2), range=1:6)   O = .mean(\"O\", 1:5, rev=c(2,5), range=1:6) }) #> √ Raw data has already been changed. Please check. ggplot(data=d, aes(x=E, y=O)) +   geom_point(alpha=0.1) +   geom_smooth(method=\"loess\") +   labs(x=\"Extraversion<sub>Big 5<\/sub>\",        y=\"Openness<sub>Big 5<\/sub>\") +   theme_bruce(markdown=TRUE) #> `geom_smooth()` using formula 'y ~ x'   ## Example 2 (2x2 ANOVA) d = data.frame(X1 = factor(rep(1:3, each=2)),                X2 = factor(rep(1:2, 3)),                Y.mean = c(5, 3, 2, 7, 3, 6),                Y.se = rep(c(0.1, 0.2, 0.1), each=2)) ggplot(data=d, aes(x=X1, y=Y.mean, fill=X2)) +   geom_bar(position=\"dodge\", stat=\"identity\", width=0.6, show.legend=FALSE) +   geom_errorbar(aes(x=X1, ymin=Y.mean-Y.se, ymax=Y.mean+Y.se),                 width=0.1, color=\"black\", position=position_dodge(0.6)) +   scale_y_continuous(expand=expansion(add=0),                      limits=c(0,8), breaks=0:8) +   scale_fill_brewer(palette=\"Set1\") +   labs(x=\"Independent Variable (*X*)\",  # italic X        y=\"Dependent Variable (*Y*)\",  # italic Y        title=\"Demo Plot<sup>bruceR<\/sup>\") +   theme_bruce(markdown=TRUE, border=\"\")"},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-8-8","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.8.8 (in development)","text":"Moved necessary R packages (dependencies) “Suggests” “Imports”, dependencies automatically installed. Also added check dependencies library(bruceR).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-087-may-2022","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.7 (May 2022)","title":"bruceR 0.8.7 (May 2022)","text":"CRAN release: 2022-05-23","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-8-7","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.8.7 (May 2022)","text":"New functions add() added(): Enhanced functions designed create, modify, /delete variables. functions combine advantages := (data.table), mutate() (dplyr), transmute() (dplyr). See help page usage convenience. New functions .sum() .mean(): Tidy version SUM() MEAN() designed add() added(). See help page usage convenience.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-7","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.7 (May 2022)","text":"Improved warning information SUM(), MEAN(), EMMEANS().","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-086-apr-2022","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.6 (Apr 2022)","title":"bruceR 0.8.6 (Apr 2022)","text":"CRAN release: 2022-04-13","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-8-6","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.8.6 (Apr 2022)","text":"Rebuilt package homepage (https://psychbruce.github.io/bruceR/) pkgdown. Configuration specified _pkgdown.yml. Added R CMD check workflow GitHub, checks code push.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-6","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.6 (Apr 2022)","text":"Improved cc(). Now becomes much convenient! Added prompt message use long data MANOVA(): “Data aggregated mean (across items/trials) >=2 observations per subject cell. may use Linear Mixed Model analyze data, e.g., subjects items level-2 clusters.” Added center argument PROCESS() (default TRUE) users want turn automatic grand-mean centering. However, mean centering still highly suggested one aim obtain “main effect” rather “fixed effect” (note: fixed effect necessarily main effect). Added estimator argument CFA() (default \"ML\") users want use estimator (fixed issue #17).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-085-mar-2022","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.5 (Mar 2022)","title":"bruceR 0.8.5 (Mar 2022)","text":"CRAN release: 2022-03-02","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-8-5","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.8.5 (Mar 2022)","text":"New function cc(): Split string (separators) character vector (whitespace around separator trimmed). example, cc(\"1 , B 2 ; C 3 | D 4 \\t E 5\") produces vector c(\"1\", \"B 2\", \"C 3\", \"D 4\", \"E 5\"). default separators include , ; | \\n \\t. Users may also specify separator.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-5","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.5 (Mar 2022)","text":"Added guideline examples creating interaction plots using returned object MANOVA() EMMEANS(). can save returned object use emmeans::emmip() function create interaction plot (based fitted model formula specification). usage, please see help page emmeans::emmip(). returns object class ggplot, can easily modified saved using ggplot2 syntax. Added explanation automatic grand-mean centering PROCESS().","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-8-5","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.8.5 (Mar 2022)","text":"Users installed afex package see unusual error using EMMEANS() function (Error: $ operator invalid atomic vectors). now afex strong dependency bruceR, automatically installed installing bruceR. Improved debugging information EMMEANS() (model null). Fixed bug interaction tests PROCESS() setting mod.type=\"3-way\" multilevel models.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-083-jan-2022","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.3 (Jan 2022)","title":"bruceR 0.8.3 (Jan 2022)","text":"CRAN release: 2022-01-18","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-3","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.3 (Jan 2022)","text":"Improved print_table(). Changed symbol (better output R Markdown): ✔ (\\u2714) → √ (\\u221a).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-8-3","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.8.3 (Jan 2022)","text":"Fixed small bug direct effect output PROCESS() models without \"x-y\" mod.path (e.g., Model 7). Fixed small bug using set.wd() R Markdown file.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-082-dec-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.2 (Dec 2021)","title":"bruceR 0.8.2 (Dec 2021)","text":"CRAN release: 2021-12-12","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-2","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.2 (Dec 2021)","text":"Requiring R version 4.0+ . Added automatic check new version bruceR library(bruceR). Added univariate tests (F) multivariate tests (Pillai’s trace F) using phia::testInteractions() output EMMEANS(). tests produce identical results obtained SPSS GLM (/EMMEANS) syntax. Improved flexibility Freq(): Now vector data frame can used. example, users may specify either Freq(data$variable) Freq(data, \"variable\"). Improved output format GLM_summary() HLM_summary(). Deprecated two useless arguments HLM_summary(): level2.predictors vartypes. Packages lmerTest, mediation, interactions, lavaan now strong dependencies installed installing bruceR. also fixes error using PROCESS() without packages installed.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-8-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.8.2 (Dec 2021)","text":"Fixed potential bugs print_table(). Fixed bug VIF results GLM_summary() HLM_summary() one factor-type predictor >= 3 levels regression model. bugs two functions also fixed. Fixed bug interaction tests PROCESS() setting mod.path=\"\" testing multilevel moderated mediation effects. Fixed another bug CI output direct effects testing multilevel models.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-080-nov-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.8.0 (Nov 2021)","title":"bruceR 0.8.0 (Nov 2021)","text":"CRAN release: 2021-11-28","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.8.0 (Nov 2021)","text":"New function TTEST(): One-sample, independent-samples, paired-samples t-test. Multiple dependent/independent variables can tested simultaneously. also tests assumption homogeneity variance allows users determine whether variances equal . Cohen’s d 95% CI reported default (see Details Examples help page issue inconsistency results 95% CI Cohen’s d R packages). Bayes factor BF10 also supported. Key results can saved APA format MS Word. New functions import() / export(): Import/export data /file two tidy functions, relieving users burden remembering lots read_xxx() / write_xxx() functions. Many file formats supported (especially .txt, .csv, .tsv, .psv, .xls, .xlsx, .sav, .dta, .rda, .rdata, clipboard). Note two functions inspired rio::import() / rio::export() several modifications convenient use. Since version, package rio longer strong dependency bruceR loaded loading bruceR.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"major-changes-0-8-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bruceR 0.8.0 (Nov 2021)","text":"Improved MANOVA() EMMEANS(): Fixed several bugs. Modified help pages. Improved output tables. Now results printed using print_table(). Improved algorithm estimating Cohen’s d: Now uses Root Mean Square Error (RMSE) pooled SD estimate Cohen’s d. Although disagreement estimation pooled SD, EMMEANS() adopts reasonable approach. one uses MANOVA() EMMEANS() conduct t-test using TTEST() function, results identical. Indeed, estimation methods Cohen’s d t-tests acknowledged. computing pooled SD ANOVAs, uses (1) square root mean square error (MSE) -subjects designs (2) square root mean variance paired differences residuals repeated measures within-subjects mixed designs. situations, extracts lm object returned value MANOVA(). , mainly uses sigma() residuals() functions, respectively, estimates. source code, see R file GitHub. Thus, results Cohen’s d designs repeated measures now different bruceR old versions (< 0.8.0), indeed used inappropriate method compute pooled SD designs. Added arguments (1) ss.type MANOVA() specify either Type-II Type-III Sum Square; (2) aov.include MANOVA() model.type EMMEANS(), details, see help pages. Added warning messages wrong usage functions. observations uniquely identified user-defined long-format data, function takes averages across multiple observations case (thanks Xiangying Zou reporting infrequent bug related issue). Improved Alpha(): Now directly uses psych::alpha() psych::omega(), rather jmv::reliability(), perform reliability analysis. format result output changed improved. Improved EFA() (almost completely rewritten): Now directly uses psych::principal() psych::fa(), rather jmv::efa(), perform factor analysis (PCA EFA). format result output changed improved. MS Word output supported. wrapper function PCA() added: EFA(..., method=\"pca\"). Improved CFA() lavaan_summary(): Now CFA() uses lavaan::cfa(), rather jmv:cfa(), build model, uses lavaan_summary() present results. lavaan_summary(), many bugs fixed, format result table changed improved. functions now support saving table MS Word. Package dependencies: Much fewer strong dependencies, faster robust installation. Removed rio jmv dependencies. longer load rio psych library(bruceR).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-8-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.8.0 (Nov 2021)","text":"Added alias set_wd() set.wd(). Improved print_table(): Fixed issue incorrect length Chinese character output print_table(). -column blanks now 2 spaces (rather 1 space) clearer presentation table columns. Modified onloading welcome messages. General bug-fixes improvements.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-073-nov-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.7.3 (Nov 2021)","title":"bruceR 0.7.3 (Nov 2021)","text":"CRAN release: 2021-11-05","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-7-3","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.7.3 (Nov 2021)","text":"Added Word output lavaan_summary() granger_test().","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-072-jun-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.7.2 (Jun 2021)","title":"bruceR 0.7.2 (Jun 2021)","text":"CRAN release: 2021-06-21","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-7-2","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.7.2 (Jun 2021)","text":"Added digits parameter equivalent nsmall parameter relevant functions. Packages mediation, interactions, MuMIn, texreg now SUGGESTS rather IMPORTS.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-7-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.7.2 (Jun 2021)","text":"Fixed bug value ordering 3-way interaction (moderated moderation) PROCESS(). Fixed bug Word output Corr().","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-070-may-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.7.0 (May 2021)","title":"bruceR 0.7.0 (May 2021)","text":"CRAN release: 2021-05-28","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.7.0 (May 2021)","text":"New function PROCESS(): PROCESS mediation, moderation, conditional process (moderated mediation) analyses! function supports total 24 kinds SPSS PROCESS models (Hayes, 2018) also supports multilevel mediation/moderation analyses. Overall, supports frequently used types mediation, moderation, moderated moderation (3-way interaction), moderated mediation (conditional indirect effect) analyses (generalized) linear linear mixed models. Regression model summary effect estimates (simple slopes /indirect effects) printed elegant way. New function lavaan_summary(): Tidy report lavaan model.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.7.0 (May 2021)","text":"Improved many functions. Deprecated RANDBETWEEN() function.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.7.0 (May 2021)","text":"Fixed bug CRAN version 0.6.4 (problem newly emerging 2021-05-25).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-064-may-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.6.4 (May 2021)","title":"bruceR 0.6.4 (May 2021)","text":"CRAN release: 2021-05-13","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-6-4","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.6.4 (May 2021)","text":"Added Word output (.doc) print_table() functions using print_table() inside: Describe(), Freq(), Corr(), MANOVA(), med_summary(), granger_causality().","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-6-4","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.6.4 (May 2021)","text":"Added disclaimer Cohen’s d output documentation EMMEANS(): considerable disagreement compute Cohen’s d. Users take default output right results completely responsible setting “sd.pooled”.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-6-4","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.6.4 (May 2021)","text":"Fixed bugs model_summary(): (1) Model names NULL; (2) Multicollinearity check results NULL problems; (3) UTF-8 encoding problem WPS software (problem Microsoft Word).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-6-3","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.6.3 (Apr 2021)","text":"New function granger_causality(): Granger causality test (multivariate) based vector autoregression (VAR) model. function advanced general version function granger_test() (bivariate). Added logo (designed @Meijia Li)","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-062-apr-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.6.2 (Apr 2021)","title":"bruceR 0.6.2 (Apr 2021)","text":"CRAN release: 2021-04-11","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"major-changes-0-6-2","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bruceR 0.6.2 (Apr 2021)","text":"Improved set.wd(): Now uses rstudioapi::getSourceEditorContext() extract file path (even effective running R console), requires RStudio version >= 0.99.1111 longer encoding problems (see release note 0.6.1). Improved theme_bruce(): Now uses ggtext::element_markdown() render Markdown/HTML rich text format, can used plot text (e.g., titles). Improved EMMEANS(): Now results always identical SPSS (setting model=\"multivariate\" emmeans::joint_tests() emmeans::emmeans(), use lm mlm objects rather aov object perform tests). cases singular error matrix (.e., variables linearly dependent), results simple-effect F tests reported, estimated marginal means pairwise comparisons affected still reported. Note EMMEANS results old versions bruceR (version < 0.6.0) identical SPSS, version 0.6.0 deprecated parameter repair longer set model$aov=NULL, made results identical SPSS (particularly ANOVAs repeated measures). response user’s feedback, now 0.6.2 improved function makes results accurate .","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-6-2","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.6.2 (Apr 2021)","text":"Improved function links R documentation: \\code{\\link[package:function]{package::function()}}.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-6-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.6.2 (Apr 2021)","text":"Fixed bug CFA() (lavaan-style output).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-6-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.6.1 (Mar 2021)","text":"New function HLM_ICC_rWG(): Tidy report HLM indices “ICC(1)” (non-independence data), “ICC(2)” (reliability group means), “rWG”/“rWG(J)” (within-group agreement single-item/multi-item measures). New function Run(): Run code parsed text. New function show_colors(): Show multiple colors (palette) plot. New function %^%: Paste strings together (wrapper paste0()).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"major-changes-0-6-1","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bruceR 0.6.1 (Mar 2021)","text":"Improved set.wd(): Now converts extracted path string “UTF-8” “GBK” Windows system support paths including Chinese characters (otherwise, path become messy code cause error). Note problem exist Mac OS. addition, warning messages printed console user’s RStudio version lower required (RStudio version >= 1.4.843 required complete implementation function). Improved Alpha(): Now adds parameter varrange (keep SUM(), MEAN(), …) reports Cronbach’s α McDonald’s ω, detailed documentation. Three ways specify variable list (implemented functions SUM(), MEAN(), Alpha()): 1. var + items: use common unique parts variable names. (e.g., var=\"RSES\", items=1:10, rev=c(3, 5, 8, 9, 10)) 2. vars: directly define variable list. (e.g., vars=c(\"E1\", \"E2\", \"E3\", \"E4\", \"E5\"), rev=c(\"E1\", \"E2\")) 3. varrange: use start end positions variable list. (e.g., varrange=\"E1:E5\", rev=c(\"E1\", \"E2\"))","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-6-1","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.6.1 (Mar 2021)","text":"Added details package’s contents Description field.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-6-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.6.1 (Mar 2021)","text":"Fixed potential bug Corr() (relevant changes psych::corr.test() forthcoming release psych package).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-060-mar-2021","dir":"Changelog","previous_headings":"","what":"bruceR 0.6.0 (Mar 2021)","title":"bruceR 0.6.0 (Mar 2021)","text":"CRAN release: 2021-03-19","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"breaking-news-0-6-0","dir":"Changelog","previous_headings":"","what":"Breaking News","title":"bruceR 0.6.0 (Mar 2021)","text":"Formally published CRAN!!! Passed R CMD check Travis CI test: 0 errors √ | 0 warnings √ | 0 notes √","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"bruceR 0.6.0 (Mar 2021)","text":"New function model_summary(): Tidy report (single/multiple) regression models (console Word/HTML file; supporting types models; based texreg package). New function med_summary(): Tidy report (simple/moderated) mediation analyses (based mediation package). New function ccf_plot: Cross-correlation analysis (plotting ggplot2). New function granger_test: Granger test predictive causality (based lmtest::grangertest() function).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"major-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bruceR 0.6.0 (Mar 2021)","text":"Improved many major functions, especially set.wd(), Describe(), Corr(), MANOVA(), EMMEANS(). Tidy welcome messages library(bruceR). packages default loading (see details). Less packages default installation (can install suggested packages using pkg_install_suggested() function).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"minor-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"bruceR 0.6.0 (Mar 2021)","text":"Changed package title description bruceR: BRoadly Useful Convenient Efficient R functions BRing Users Concise Elegant R data analyses. Reorganized raw code files.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bruceR 0.6.0 (Mar 2021)","text":"Fixed bugs (errors, warnings, notes) conducting R CMD check. Fixed problems manual inspection CRAN team members.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"notes-0-6-0","dir":"Changelog","previous_headings":"","what":"Notes","title":"bruceR 0.6.0 (Mar 2021)","text":"Deprecated useless/defective functions (see details).","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-050-aug-2020","dir":"Changelog","previous_headings":"","what":"bruceR 0.5.0 (Aug 2020)","title":"bruceR 0.5.0 (Aug 2020)","text":"Requiring R version 4.0+. Improved many functions. Fixed many bugs.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-040-dec-2019","dir":"Changelog","previous_headings":"","what":"bruceR 0.4.0 (Dec 2019)","title":"bruceR 0.4.0 (Dec 2019)","text":"Added citation information. General bug-fixes improvements.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-030-oct-2019","dir":"Changelog","previous_headings":"","what":"bruceR 0.3.0 (Oct 2019)","title":"bruceR 0.3.0 (Oct 2019)","text":"New functions MANOVA() EMMEANS(): ANOVA, simple-effect analyses, multiple comparisons (based afex emmeans packages). General bug-fixes improvements.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-020-aug-2019","dir":"Changelog","previous_headings":"","what":"bruceR 0.2.0 (Aug 2019)","title":"bruceR 0.2.0 (Aug 2019)","text":"Added help pages. General bug-fixes improvements.","code":""},{"path":"https://psychbruce.github.io/bruceR/news/index.html","id":"brucer-010-jun-2019","dir":"Changelog","previous_headings":"","what":"bruceR 0.1.0 (Jun 2019)","title":"bruceR 0.1.0 (Jun 2019)","text":"Initial release GitHub.","code":""}]
